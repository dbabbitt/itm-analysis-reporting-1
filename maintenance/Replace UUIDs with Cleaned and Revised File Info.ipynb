{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18892a1-9d36-412b-9843-f6a4a52827d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60396754-b60d-46a9-99d7-6194fb50e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import (nu, osp, DataFrame, np, re, walk, to_numeric, to_datetime, nan, Series, display, notnull, concat, remove)\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2473e16a-3f0c-4050-9612-216160f7e6ef",
   "metadata": {},
   "source": [
    "\n",
    "# Replace UUIDs with Cleaned and Revised File Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6971d12-57c5-48d0-97a4-1fd8abeb97c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829277, 113)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all CSVs into one data frame\n",
    "if nu.pickle_exists('frvrs_logs_df'):\n",
    "    frvrs_logs_df = nu.load_object('frvrs_logs_df')\n",
    "    print(frvrs_logs_df.shape)\n",
    "    # df = frvrs_logs_df.sample(4).dropna(axis='columns', how='all')\n",
    "    # display(df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9b19da-88eb-4eff-887d-327b1fc205a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all deduped logs into one data frame\n",
    "if nu.pickle_exists('sub_directory_df'):\n",
    "    sub_directory_df = nu.load_object('sub_directory_df')\n",
    "else:\n",
    "    \n",
    "    # Iterate over the subdirectories, directories, and files in the logs folder\n",
    "    for sub_directory, directories_list, files_list in walk(nu.data_logs_folder):\n",
    "        if (sub_directory == f'{nu.data_logs_folder}\\\\Double runs removed'):\n",
    "    \n",
    "            # Create a data frame to store the data for the current subdirectory\n",
    "            sub_directory_df = DataFrame([])\n",
    "    \n",
    "            # Iterate over the files in the current subdirectory\n",
    "            for file_name in files_list:\n",
    "    \n",
    "                # If the file is a CSV file, merge it into the subdirectory data frame\n",
    "                if file_name.endswith('.csv'): sub_directory_df = fu.process_files(sub_directory_df, sub_directory, file_name)\n",
    "    \n",
    "    # Convert event time to a datetime\n",
    "    if ('event_time' in sub_directory_df.columns): sub_directory_df['event_time'] = to_datetime(sub_directory_df['event_time'], format='mixed')\n",
    "    \n",
    "    # Convert elapsed time to an integer\n",
    "    if ('action_tick' in sub_directory_df.columns):\n",
    "        sub_directory_df['action_tick'] = to_numeric(sub_directory_df['action_tick'], errors='coerce')\n",
    "        sub_directory_df['action_tick'] = sub_directory_df['action_tick'].astype('int64')\n",
    "    \n",
    "    sub_directory_df = sub_directory_df.reset_index(drop=True)\n",
    "    \n",
    "    # Remove numerically-named columns\n",
    "    columns_list = [x for x in sub_directory_df.columns if not re.search(r'\\d+', str(x))]\n",
    "    sub_directory_df = sub_directory_df[columns_list]\n",
    "    \n",
    "    # Convert 'TRUE' and 'FALSE' to boolean values\n",
    "    for cn in [\n",
    "        'injury_record_injury_treated_with_wrong_treatment', 'injury_record_injury_treated',\n",
    "        'injury_treated_injury_treated_with_wrong_treatment', 'injury_treated_injury_treated'\n",
    "    ]:\n",
    "        sub_directory_df[cn] = sub_directory_df[cn].map({'TRUE': True, 'FALSE': False, 'True': True, 'False': False})\n",
    "    \n",
    "    # Convert the nulls into NaNs\n",
    "    for cn in frvrs_logs_df.columns: frvrs_logs_df[cn] = frvrs_logs_df[cn].replace('null', nan)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b41ff9f-8655-4391-abba-cde36ef2aca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24969</th>\n",
       "      <th>28663</th>\n",
       "      <th>22629</th>\n",
       "      <th>7203</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>action_type</th>\n",
       "      <td>TOOL_HOVER</td>\n",
       "      <td>TOOL_HOVER</td>\n",
       "      <td>TOOL_HOVER</td>\n",
       "      <td>TOOL_HOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action_tick</th>\n",
       "      <td>782340</td>\n",
       "      <td>412856</td>\n",
       "      <td>627142</td>\n",
       "      <td>569178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_time</th>\n",
       "      <td>2022-03-16 12:28:00</td>\n",
       "      <td>2023-08-03 08:02:00</td>\n",
       "      <td>2022-03-16 11:14:00</td>\n",
       "      <td>2022-03-15 11:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_uuid</th>\n",
       "      <td>0b1d6253-9c4f-43b7-8217-6f0e486aabe7</td>\n",
       "      <td>ab1f8cd1-8d65-45da-b087-89b25ff46c66</td>\n",
       "      <td>0d3e0c62-db52-40f9-9ee8-7fc84a1dcbf2</td>\n",
       "      <td>22e2c9a3-b93f-4f7f-896a-ca188c78505b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_name</th>\n",
       "      <td>Double runs removed/22.03.16.1215r.csv</td>\n",
       "      <td>Double runs removed/23.08.03.0755r.csv</td>\n",
       "      <td>Double runs removed/22.03.16.1104r.csv</td>\n",
       "      <td>Double runs removed/22.03.15.1106r.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logger_version</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tool_hover_type</th>\n",
       "      <td>Hemostatic Gauze</td>\n",
       "      <td>Hemostatic Gauze</td>\n",
       "      <td>Gauze</td>\n",
       "      <td>Tourniquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tool_hover_count</th>\n",
       "      <td>1001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1006</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_scene_aborted</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scene_type</th>\n",
       "      <td>Triage</td>\n",
       "      <td>Triage</td>\n",
       "      <td>Triage</td>\n",
       "      <td>Triage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_a_one_triage_file</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       24969  \\\n",
       "action_type                                       TOOL_HOVER   \n",
       "action_tick                                          782340   \n",
       "event_time                               2022-03-16 12:28:00   \n",
       "session_uuid            0b1d6253-9c4f-43b7-8217-6f0e486aabe7   \n",
       "file_name             Double runs removed/22.03.16.1215r.csv   \n",
       "logger_version                                           1.0   \n",
       "tool_hover_type                             Hemostatic Gauze   \n",
       "tool_hover_count                                        1001   \n",
       "scene_id                                                0   \n",
       "is_scene_aborted                                       False   \n",
       "scene_type                                            Triage   \n",
       "is_a_one_triage_file                                    True   \n",
       "\n",
       "                                                       28663  \\\n",
       "action_type                                       TOOL_HOVER   \n",
       "action_tick                                          412856   \n",
       "event_time                               2023-08-03 08:02:00   \n",
       "session_uuid            ab1f8cd1-8d65-45da-b087-89b25ff46c66   \n",
       "file_name             Double runs removed/23.08.03.0755r.csv   \n",
       "logger_version                                           1.0   \n",
       "tool_hover_type                             Hemostatic Gauze   \n",
       "tool_hover_count                                        1000   \n",
       "scene_id                                                0   \n",
       "is_scene_aborted                                       False   \n",
       "scene_type                                            Triage   \n",
       "is_a_one_triage_file                                    True   \n",
       "\n",
       "                                                       22629  \\\n",
       "action_type                                       TOOL_HOVER   \n",
       "action_tick                                          627142   \n",
       "event_time                               2022-03-16 11:14:00   \n",
       "session_uuid            0d3e0c62-db52-40f9-9ee8-7fc84a1dcbf2   \n",
       "file_name             Double runs removed/22.03.16.1104r.csv   \n",
       "logger_version                                           1.0   \n",
       "tool_hover_type                                        Gauze   \n",
       "tool_hover_count                                        1006   \n",
       "scene_id                                                0   \n",
       "is_scene_aborted                                       False   \n",
       "scene_type                                            Triage   \n",
       "is_a_one_triage_file                                    True   \n",
       "\n",
       "                                                       7203   \n",
       "action_type                                       TOOL_HOVER  \n",
       "action_tick                                          569178  \n",
       "event_time                               2022-03-15 11:15:00  \n",
       "session_uuid            22e2c9a3-b93f-4f7f-896a-ca188c78505b  \n",
       "file_name             Double runs removed/22.03.15.1106r.csv  \n",
       "logger_version                                           1.0  \n",
       "tool_hover_type                                   Tourniquet  \n",
       "tool_hover_count                                         994  \n",
       "scene_id                                                0  \n",
       "is_scene_aborted                                       False  \n",
       "scene_type                                            Triage  \n",
       "is_a_one_triage_file                                    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(sub_directory_df.sample(min(4, sub_directory_df.shape[0])).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efad78a-0000-487d-a0d0-c79415e011b1",
   "metadata": {},
   "source": [
    "\n",
    "## Check for duplicate file ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f7d334-d060-46bf-ab58-9ef5f522c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter all the rows that have more than one unique value in the file_name column for each value in the session_uuid column\n",
    "mask_series = (sub_directory_df.groupby('session_uuid').file_name.transform(Series.nunique) > 1)\n",
    "assert sub_directory_df[mask_series].shape[0] == 0, \"You have duplicate files\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e97a4-6d1a-4b06-b39e-a752603b6db2",
   "metadata": {},
   "source": [
    "\n",
    "## Add new features according to your increasing domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8a4be1-98aa-4156-8bd4-fcad635e6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one patient ID column if possible\n",
    "new_column_name = 'patient_id'\n",
    "if (new_column_name not in sub_directory_df.columns):\n",
    "    columns_list= [\n",
    "        'patient_demoted_patient_id', 'patient_record_patient_id', 'injury_record_patient_id', 's_a_l_t_walk_if_can_patient_id',\n",
    "        's_a_l_t_walked_patient_id', 's_a_l_t_wave_if_can_patient_id', 's_a_l_t_waved_patient_id', 'patient_engaged_patient_id',\n",
    "        'pulse_taken_patient_id', 'injury_treated_patient_id', 'tool_applied_patient_id', 'tag_applied_patient_id',\n",
    "        'player_gaze_patient_id'\n",
    "    ]\n",
    "    sub_directory_df = nu.modalize_columns(sub_directory_df, columns_list, new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da3fadc5-ce09-498f-9d8f-7313e1099976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one location ID column if possible\n",
    "new_column_name = 'location_id'\n",
    "if (new_column_name not in sub_directory_df.columns):\n",
    "    columns_list= [\n",
    "        'teleport_location', 'patient_demoted_position', 'patient_record_position', 'injury_record_injury_injury_locator',\n",
    "        's_a_l_t_walk_if_can_sort_location', 's_a_l_t_walked_sort_location', 's_a_l_t_wave_if_can_sort_location',\n",
    "        's_a_l_t_waved_sort_location', 'patient_engaged_position', 'bag_access_location', 'injury_treated_injury_injury_locator',\n",
    "        'bag_closed_location', 'tag_discarded_location', 'tool_discarded_location', 'player_location_location',\n",
    "        'player_gaze_location'\n",
    "    ]\n",
    "    sub_directory_df = nu.modalize_columns(sub_directory_df, columns_list, new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467fd0d3-f672-4f8f-8742-2248219f61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one injury ID column if possible\n",
    "new_column_name = 'injury_id'\n",
    "if (new_column_name not in sub_directory_df.columns):\n",
    "    sub_directory_df = nu.modalize_columns(sub_directory_df, ['injury_record_id', 'injury_treated_id'], new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1820996-ddb7-4738-be1b-8d85412d3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a voice capture sentiment score\n",
    "new_column_name = 'voice_capture_sentiment_score'\n",
    "if (new_column_name not in sub_directory_df.columns):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    mask_series = sub_directory_df.voice_capture_message.isnull()\n",
    "    for row_index, row_series in sub_directory_df[~mask_series].iterrows():\n",
    "        voice_capture_message = '\\n' + row_series.voice_capture_message\n",
    "        sub_directory_df.loc[row_index, new_column_name] = sid.polarity_scores(voice_capture_message)['compound']\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb444887-9c81-439a-8b44-fa21ba89875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mask voice capture PII\n",
    "# OSU screened all of the **VOICE_COMMAND** and **VOICE_CAPTURE** lines and\n",
    "# replaced any names with either Max or Jane, regardless of whether the name was that of the responder.\n",
    "# But, just to make sure...\n",
    "columns_list = ['voice_command_command_description', 'voice_capture_message']\n",
    "if not sub_directory_df[columns_list].applymap(lambda x: '[PERSON]' in str(x), na_action='ignore').sum().sum():\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "    \n",
    "    mask_series = sub_directory_df.voice_command_command_description.isnull() & sub_directory_df.voice_capture_message.isnull()\n",
    "    df = sub_directory_df[~mask_series]\n",
    "    def mask_pii(srs):\n",
    "        for idx in columns_list:\n",
    "            new_text = srs[idx]\n",
    "            if notnull(new_text):\n",
    "                doc = nlp(new_text)\n",
    "                for entity in doc.ents:\n",
    "                    if entity.label_ == 'PERSON':\n",
    "                        new_text = re.sub('\\\\b' + entity.text + '\\\\b', '[PERSON]', new_text)\n",
    "                srs[idx] = new_text\n",
    "    \n",
    "        return srs\n",
    "    \n",
    "    for row_index, row_series in df.apply(mask_pii, axis='columns')[columns_list].iterrows():\n",
    "        for column_name, column_value in row_series.items():\n",
    "            if notnull(column_value):\n",
    "                sub_directory_df.loc[row_index, column_name] = column_value\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfe4f806-ceb8-434e-9abd-464ac4f9ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\DaveBabbitt\\Documents\\GitHub\\itm-analysis-reporting\\saves\\pkl\\sub_directory_df.pkl\n",
      "(28978, 113)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_scene_aborted</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>28978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count\n",
       "is_scene_aborted       \n",
       "False             28978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Any runs longer than that 16 minutes are probably an instance\n",
    "# of someone taking off the headset and setting it on the ground.\n",
    "# 1 second = 1,000 milliseconds; 1 minute = 60 seconds\n",
    "new_column_name = 'is_scene_aborted'\n",
    "if (new_column_name in sub_directory_df.columns): sub_directory_df = sub_directory_df.drop(columns=new_column_name)\n",
    "if (new_column_name not in sub_directory_df.columns) and nu.pickle_exists('time_to_engagement_df'):\n",
    "    sub_directory_df[new_column_name] = False\n",
    "\n",
    "    # Create the still patients data frame\n",
    "    time_to_engagement_df = nu.load_object('time_to_engagement_df')\n",
    "    mask_series = ~time_to_engagement_df.start_to_last_engagement.isnull()\n",
    "    min_start_to_engagement_df = time_to_engagement_df[mask_series].groupby(fu.scene_groupby_columns).min().reset_index(drop=False).sort_values('start_to_last_engagement')\n",
    "\n",
    "    # Filter it for overly-long runs\n",
    "    sixteen_minutes = 1_000 * 60 * 16\n",
    "    mask_series = (min_start_to_engagement_df.start_to_last_engagement > sixteen_minutes)\n",
    "    \n",
    "    # Get the run's entire history and mark it as aborted\n",
    "    for (session_uuid, scene_id), _ in min_start_to_engagement_df[mask_series].groupby(fu.scene_groupby_columns):\n",
    "        mask_series = True\n",
    "        for cn in fu.scene_groupby_columns: mask_series &= (sub_directory_df[cn] == eval(cn))\n",
    "        sub_directory_df.loc[mask_series, new_column_name] = True\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 111)\n",
    "    display(sub_directory_df.groupby('is_scene_aborted').size().to_frame().rename(columns={0: 'count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "202e677a-8bdf-4238-bf12-002274247e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if all the patient IDs in any run are some variant of Mike and designate those runs as \"Orientation\"\n",
    "if ('scene_type' not in sub_directory_df.columns): sub_directory_df['scene_type'] = 'Triage'\n",
    "column_value = 'Orientation'\n",
    "if (column_value not in sub_directory_df.scene_type.unique()):\n",
    "    \n",
    "    # Filter out those files from the dataset and mark them\n",
    "    base_mask_series = sub_directory_df.groupby(fu.scene_groupby_columns).patient_id.transform(lambda srs: all(srs.str.lower().str.contains('mike')))\n",
    "    sub_directory_df.loc[base_mask_series, 'scene_type'] = column_value\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eca2e87-d167-42c6-9901-fcb9d246e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a sample with a clear count of responders\n",
    "new_column_name = 'is_a_one_triage_file'\n",
    "if (new_column_name not in sub_directory_df.columns):\n",
    "    sub_directory_df[new_column_name] = False\n",
    "\n",
    "    # Create the triage count data frame\n",
    "    time_groups_dict = {}\n",
    "    mask_series = (sub_directory_df.scene_type == 'Triage') & (sub_directory_df.is_scene_aborted == False)\n",
    "    for (file_name), file_name_df in sub_directory_df[mask_series].groupby('file_name'):\n",
    "        actions_list = []\n",
    "        \n",
    "        # Add the scene type for this run\n",
    "        for (scene_id), scene_df in file_name_df.groupby('scene_id'):\n",
    "            scene_type = fu.get_scene_type(scene_df)\n",
    "            if len(scene_type) != 1: raise\n",
    "            else: scene_type = scene_type[0]\n",
    "            actions_list.append(scene_type)\n",
    "        \n",
    "        time_groups_dict[file_name] = actions_list\n",
    "    triage_count_df = DataFrame([{'file_name': k, 'triage_count': v.count('Triage')} for k, v in time_groups_dict.items()])\n",
    "\n",
    "    # Filter only those file which have only one triage run\n",
    "    mask_series = (triage_count_df.triage_count == 1)\n",
    "    file_names_list = triage_count_df[mask_series].file_name.tolist()\n",
    "    mask_series = sub_directory_df.file_name.isin(file_names_list)\n",
    "    sub_directory_df.loc[mask_series, new_column_name] = True\n",
    "    \n",
    "    nu.store_objects(sub_directory_df=sub_directory_df)\n",
    "    print(sub_directory_df.shape) # (28978, 113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb7f5176-b16a-4c1a-8c2a-d83511311bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cn in [\n",
    "    'player_gaze_distance_to_patient', 'player_gaze_direction_of_gaze', 'player_location_right_hand_location', 'player_location_left_hand_location',\n",
    "    'player_gaze_location', 'player_location_location', 'player_gaze_patient_id'\n",
    "]:\n",
    "    sub_directory_df[cn] = nan\n",
    "\n",
    "missing_columns = list(set(frvrs_logs_df.columns) - set(sub_directory_df.columns))\n",
    "if missing_columns: print(\"'(\" + '|'.join(missing_columns) + \")'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd441b65-a4d3-459d-96a2-402a74941461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disaster Day 2022/AS_1056.csv (1737, 113) (1371, 113)\n",
      "Disaster Day 2022/NEM_1053.csv (1046, 113) (719, 113)\n",
      "Disaster Day 2022/JH_1235.csv (1440, 113) (872, 113)\n",
      "Disaster Day 2022/CF_1117.csv (1518, 113) (1079, 113)\n",
      "Disaster Day 2022/EB_0128.csv (1875, 113) (1085, 113)\n",
      "Disaster Day 2022/JM_1119.csv (1054, 113) (882, 113)\n",
      "Disaster Day 2022/MM_1136.csv (1593, 113) (537, 113)\n",
      "Disaster Day 2022/RO_1152.csv (1168, 113) (645, 113)\n",
      "Disaster Day 2022/BC_1136.csv (1350, 113) (1133, 113)\n",
      "Disaster Day 2022/HL_1034.csv (1456, 113) (969, 113)\n",
      "Disaster Day 2022/RP_0853.csv (934, 113) (526, 113)\n",
      "Disaster Day 2022/AD_1154.csv (2883, 113) (1890, 113)\n",
      "Disaster Day 2022/MB_0927.csv (1194, 113) (789, 113)\n",
      "Disaster Day 2022/JL_1013.csv (5093, 113) (3095, 113)\n",
      "Disaster Day 2022/ES_0938.csv (1625, 113) (1065, 113)\n",
      "All CSV files renamed by date/12.01.22.1551.csv (420, 113) (404, 113)\n",
      "Disaster Day 2022/PA_132.csv (2251, 113) (1373, 113)\n",
      "Disaster Day 2022/TS_0900.csv (2252, 113) (1919, 113)\n",
      "All CSV files renamed by date/03.15.23.1220.csv (1222, 113) (1189, 113)\n",
      "DCEMS Round 2 only triage sessions/ab1f8cd1-8d65-45da-b087-89b25ff46c66.csv (797, 113) (794, 113)\n",
      "Disaster Day 2022/AF.csv (845, 113) (549, 113)\n",
      "Disaster Day 2022/ZJ_1210.csv (1088, 113) (446, 113)\n",
      "Disaster Day 2022/SB_1100.csv (733, 113) (634, 113)\n",
      "Disaster Day 2022/PR_0914.csv (794, 113) (540, 113)\n",
      "Disaster Day 2022/AK_938.csv (1661, 113) (1661, 113)\n",
      "Disaster Day 2022/KF_0856.csv (1708, 113) (525, 113)\n",
      "v.1.0/Clean Marty8.csv (1331, 113) (1262, 113)\n",
      "Disaster Day 2022/NIM_0837.csv (1296, 113) (1025, 113)\n",
      "Pickling to C:\\Users\\DaveBabbitt\\Documents\\GitHub\\itm-analysis-reporting\\saves\\pkl\\frvrs_logs_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace the old file rows with the new file rows\n",
    "for session_uuid, file_df in sub_directory_df.groupby('session_uuid'):\n",
    "\n",
    "    # Filter out the file from the main data frame\n",
    "    mask_series = (frvrs_logs_df.session_uuid == session_uuid)\n",
    "    # assert frvrs_logs_df[mask_series].shape[0] >= file_df.shape[0], f\"{session_uuid} seems sus\"\n",
    "\n",
    "    # Remove the old file\n",
    "    file_name = frvrs_logs_df[mask_series].file_name.unique().item()\n",
    "    file_path = osp.join(nu.data_logs_folder, file_name)\n",
    "    if osp.exists(file_path): remove(file_path)\n",
    "    print(file_name, frvrs_logs_df[mask_series].shape, file_df.shape)\n",
    "\n",
    "    # Remove the old file rows\n",
    "    frvrs_logs_df = frvrs_logs_df[~mask_series]\n",
    "    \n",
    "    # Append the data frame for the current file to the main data frame\n",
    "    frvrs_logs_df = concat([frvrs_logs_df, file_df], axis='index')\n",
    "\n",
    "# Convert event time to a datetime\n",
    "if ('event_time' in frvrs_logs_df.columns): frvrs_logs_df['event_time'] = to_datetime(frvrs_logs_df['event_time'], format='mixed')\n",
    "\n",
    "# Convert elapsed time to an integer\n",
    "if ('action_tick' in frvrs_logs_df.columns):\n",
    "    frvrs_logs_df['action_tick'] = to_numeric(frvrs_logs_df['action_tick'], errors='coerce')\n",
    "    frvrs_logs_df['action_tick'] = frvrs_logs_df['action_tick'].astype('int64')\n",
    "\n",
    "frvrs_logs_df = frvrs_logs_df.reset_index(drop=True)\n",
    "nu.store_objects(frvrs_logs_df=frvrs_logs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c204b7f2-6796-43ca-bf0b-ef2d0a820ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\DaveBabbitt\\Documents\\GitHub\\itm-analysis-reporting\\saves\\pkl\\frvrs_logs_df.pkl\n",
      "(829277, 113)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get rid of the path prefix\n",
    "path_prefix = 'Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/'\n",
    "frvrs_logs_df.file_name = frvrs_logs_df.file_name.map(lambda x: str(x).replace(path_prefix, ''))\n",
    "nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "print(frvrs_logs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fdca6-14e6-4316-b877-962ae131d232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.13)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
