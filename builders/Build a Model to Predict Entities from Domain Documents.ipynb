{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f303819c-dc03-46ab-a5fc-d1de4fe42714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88993e1-de14-424b-a21c-ca2308d8ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import (nu, re, np, DataFrame, isnan, concat, nan)\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704b6646-2aa6-40f0-8096-e4f644b8c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/deduped_lower_case_ners_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/domain_doc_ners_df.pkl.\n",
      "(302127, 16)\n",
      "(47269, 18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load documents\n",
    "data_frames_dict = nu.load_data_frames(deduped_lower_case_ners_df='deduped_lower_case_ners_df', domain_doc_ners_df='domain_doc_ners_df')\n",
    "domain_doc_ners_df = data_frames_dict['domain_doc_ners_df']\n",
    "print(domain_doc_ners_df.shape)\n",
    "deduped_lower_case_ners_df = data_frames_dict['deduped_lower_case_ners_df']\n",
    "print(deduped_lower_case_ners_df.shape)\n",
    "column_descriptions_df = nu.get_column_descriptions(deduped_lower_case_ners_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c52311-5909-477d-a708-dbb4a8133df1",
   "metadata": {},
   "source": [
    "\n",
    "# Build a Model to Predict Entities from Domain Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47488974-3e46-4d1e-bcfa-0f92ccbb37ed",
   "metadata": {},
   "source": [
    "\n",
    "## Build a model to predict *is_probe*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1bd13-2c99-40e8-9b99-d6ab18bad308",
   "metadata": {},
   "source": [
    "\n",
    "#### Create a data frame with all the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe5f2f9-9475-4b5e-b0c8-ea84665950ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = deduped_lower_case_ners_df.text_str.isnull()\n",
    "if mask_series.any():\n",
    "    deduped_lower_case_ners_df = deduped_lower_case_ners_df[~mask_series]\n",
    "    print(deduped_lower_case_ners_df.shape)\n",
    "    nu.store_objects(deduped_lower_case_ners_df=deduped_lower_case_ners_df)\n",
    "    nu.save_data_frames(deduped_lower_case_ners_df=deduped_lower_case_ners_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2807adc3-2d93-452c-9db2-6a59e03b70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_columns = ['ent_type', 'nlp_type', 'bert_entity']\n",
    "text_columns = ['ent_phrase', 'nlp_word', 'bert_word']\n",
    "\n",
    "# Get the person/date type mask\n",
    "type_values = ['PERSON', 'DATE', 'I-PER']\n",
    "base_mask_series = True\n",
    "for type_column in type_columns: base_mask_series &= ~domain_doc_ners_df[type_column].isin(type_values)\n",
    "\n",
    "# Get the null mask\n",
    "null_mask_series = False\n",
    "for text_column in text_columns: null_mask_series |= ~domain_doc_ners_df[text_column].isnull()\n",
    "\n",
    "# Get the non-person/date entities\n",
    "mask_series = base_mask_series & null_mask_series\n",
    "non_named_df = domain_doc_ners_df[mask_series]\n",
    "\n",
    "# Get the is_probe values from the old dataset\n",
    "def f(text_str):\n",
    "    mask_series = False\n",
    "    for text_column in text_columns: mask_series |= non_named_df[text_column].map(lambda x: str(x).lower() == text_str)\n",
    "    df = non_named_df[mask_series]\n",
    "    if df.is_probe.nunique() == 1: return df.iloc[0].is_probe\n",
    "    # elif df.shape[0] == 0: print(text_str); display(df); raise\n",
    "    elif df.is_probe.any():\n",
    "        domain_doc_ners_df.loc[df.index, 'is_probe'] = True\n",
    "        nu.store_objects(domain_doc_ners_df=domain_doc_ners_df)\n",
    "        nu.save_data_frames(domain_doc_ners_df=domain_doc_ners_df)\n",
    "        return True\n",
    "    else: print(text_str); display(df); raise\n",
    "\n",
    "if 'is_probe' not in deduped_lower_case_ners_df.columns:\n",
    "    deduped_lower_case_ners_df['is_probe'] = deduped_lower_case_ners_df.text_str.map(f)\n",
    "    print(deduped_lower_case_ners_df.shape)\n",
    "    nu.store_objects(deduped_lower_case_ners_df=deduped_lower_case_ners_df)\n",
    "    nu.save_data_frames(deduped_lower_case_ners_df=deduped_lower_case_ners_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd70820-5cb9-4363-aa07-09525352e353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>41206</th>\n",
       "      <th>42524</th>\n",
       "      <th>43370</th>\n",
       "      <th>43620</th>\n",
       "      <th>2415</th>\n",
       "      <th>7522</th>\n",
       "      <th>16639</th>\n",
       "      <th>13986</th>\n",
       "      <th>24440</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_str</th>\n",
       "      <td>geneva convention iii relative</td>\n",
       "      <td>quartermaster</td>\n",
       "      <td>1–18</td>\n",
       "      <td>existence of a war for purposes of applying th...</td>\n",
       "      <td>governmentally</td>\n",
       "      <td>misusing</td>\n",
       "      <td>metaethical</td>\n",
       "      <td>91–113</td>\n",
       "      <td>ashford da</td>\n",
       "      <td>drip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_phrase</th>\n",
       "      <td>Geneva Convention III Relative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXISTENCE OF A WAR FOR PURPOSES OF APPLYING TH...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashford DA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type</th>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_start</th>\n",
       "      <td>92815.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91891.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_end</th>\n",
       "      <td>92845.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38605.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91901.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_word</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1–18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>governmentally</td>\n",
       "      <td>NaN</td>\n",
       "      <td>metaethical</td>\n",
       "      <td>91–113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_type</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_pofs</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADV</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     2              41206     42524  \\\n",
       "text_str    geneva convention iii relative  quartermaster      1–18   \n",
       "ent_phrase  Geneva Convention III Relative            NaN       NaN   \n",
       "ent_type                       WORK_OF_ART            NaN       NaN   \n",
       "ent_start                          92815.0            NaN       NaN   \n",
       "ent_end                            92845.0            NaN       NaN   \n",
       "nlp_word                               NaN            NaN      1–18   \n",
       "nlp_tag                                NaN            NaN        CD   \n",
       "nlp_type                               NaN            NaN  CARDINAL   \n",
       "nlp_pofs                               NaN            NaN       NUM   \n",
       "is_probe                             False          False     False   \n",
       "\n",
       "                                                        43370           43620  \\\n",
       "text_str    existence of a war for purposes of applying th...  governmentally   \n",
       "ent_phrase  EXISTENCE OF A WAR FOR PURPOSES OF APPLYING TH...             NaN   \n",
       "ent_type                                          WORK_OF_ART             NaN   \n",
       "ent_start                                             38536.0             NaN   \n",
       "ent_end                                               38605.0             NaN   \n",
       "nlp_word                                                  NaN  governmentally   \n",
       "nlp_tag                                                   NaN              RB   \n",
       "nlp_type                                                  NaN             NaN   \n",
       "nlp_pofs                                                  NaN             ADV   \n",
       "is_probe                                                False           False   \n",
       "\n",
       "               2415         7522    16639       13986  24440  \n",
       "text_str    misusing  metaethical  91–113  ashford da   drip  \n",
       "ent_phrase       NaN          NaN     NaN  Ashford DA    NaN  \n",
       "ent_type         NaN          NaN     NaN         ORG    NaN  \n",
       "ent_start        NaN          NaN     NaN     91891.0    NaN  \n",
       "ent_end          NaN          NaN     NaN     91901.0    NaN  \n",
       "nlp_word         NaN  metaethical  91–113         NaN    NaN  \n",
       "nlp_tag          VBG           JJ     NNP         NaN    NaN  \n",
       "nlp_type         NaN          NaN     NaN         NaN    NaN  \n",
       "nlp_pofs        VERB          ADJ   PROPN         NaN    NaN  \n",
       "is_probe       False        False   False       False  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Display a sample of the data frame, dropping columns with all NaN values and transposing it\n",
    "display(deduped_lower_case_ners_df.sample(min(10, deduped_lower_case_ners_df.shape[0])).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd2382-a753-4352-9f42-52311c16657d",
   "metadata": {},
   "source": [
    "\n",
    "#### One-hot encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0337b3-bb40-421f-a004-70c208a9f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get rid of wierd tag categories\n",
    "if deduped_lower_case_ners_df.nlp_tag.isin([':', '.', \"''\", '_SP', ',', 'PRP$', '``', '$', '-LRB-', '-RRB-', 'WP$']).any():\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == ':')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'COLON'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == '.')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'FULL_STOP'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == \"''\")\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'DOUBLE_PRIME'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == '_SP')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'UNDERSCORE_SP'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == ',')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'COMMA'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == 'PRP$')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'PRP_DOLLAR_SIGN'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == '``')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'DOUBLE_BACKTICK'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == '$')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'DOLLAR_SIGN'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == '-LRB-')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'LEFT_ROUND_BRACKET'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == '-RRB-')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'RIGHT_ROUND_BRACKET'\n",
    "    mask_series = (deduped_lower_case_ners_df.nlp_tag == 'WP$')\n",
    "    deduped_lower_case_ners_df.loc[mask_series, 'nlp_tag'] = 'WP_DOLLAR_SIGN'\n",
    "    nu.store_objects(deduped_lower_case_ners_df=deduped_lower_case_ners_df)\n",
    "    nu.save_data_frames(deduped_lower_case_ners_df=deduped_lower_case_ners_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6906be-a681-421f-8ec0-9ca86e0a8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert deduped_lower_case_ners_df.columns[deduped_lower_case_ners_df.columns.duplicated(keep=False)].shape[0] == 0, \"You've got duped columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4a9d4f5-0ee1-4608-abe3-eab3a9c011a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert len(\n",
    "    [cn for cn in deduped_lower_case_ners_df.nlp_tag.unique() if re.search('[^A-Z_]+', str(cn)) and not isnan(cn)]\n",
    ") == 0, \"You've got wierd tags, still\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6d0629-b0d7-4d1f-8cf6-70af6f2f32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = pd.get_dummies(deduped_lower_case_ners_df[['nlp_tag']], dummy_na=True).columns\n",
    "assert columns_list[columns_list.duplicated(keep=False)].shape[0] == 0, \"You've got duplicated dummy columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb777eac-dc24-4ac4-b838-4694ba6bc059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the supervised learning and group by columns\n",
    "input_features = [\n",
    "    'ent_type', 'nlp_tag', 'nlp_type', 'nlp_pofs', 'bert_entity'\n",
    "    ]\n",
    "target_variable = 'is_probe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fff551d-e08a-4e88-9e1b-037abd0a420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ent_type_nan', 'nlp_tag_nan', 'nlp_type_nan', 'nlp_pofs_nan', 'bert_entity_nan']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28492</th>\n",
       "      <th>28666</th>\n",
       "      <th>1792</th>\n",
       "      <th>32391</th>\n",
       "      <th>41890</th>\n",
       "      <th>43872</th>\n",
       "      <th>45233</th>\n",
       "      <th>35945</th>\n",
       "      <th>19700</th>\n",
       "      <th>2302</th>\n",
       "      <th>360</th>\n",
       "      <th>18687</th>\n",
       "      <th>3510</th>\n",
       "      <th>38403</th>\n",
       "      <th>36201</th>\n",
       "      <th>29428</th>\n",
       "      <th>4515</th>\n",
       "      <th>39324</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ent_type_percent</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_time</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_work_of_art</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_pofs_cconj</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_jj</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_left_round_bracket</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_nan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_nfp</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_vb</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_wp_dollar_sign</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_type_time</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_type_work_of_art</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           28492 28666 1792  32391 41890 43872 45233 35945  \\\n",
       "ent_type_percent               0     0     0     0     0     0     0     0   \n",
       "ent_type_time                  0     0     0     0     0     0     0     0   \n",
       "ent_type_work_of_art           0     0     0     0     0     0     0     0   \n",
       "nlp_pofs_cconj                 0     0     0     0     0     0     0     0   \n",
       "nlp_tag_jj                     1     0     0     0     0     0     0     0   \n",
       "nlp_tag_left_round_bracket     0     0     0     0     0     0     0     0   \n",
       "nlp_tag_nan                    0     0     1     1     1     0     1     0   \n",
       "nlp_tag_nfp                    0     0     0     0     0     0     0     0   \n",
       "nlp_tag_vb                     0     1     0     0     0     0     0     0   \n",
       "nlp_tag_wp_dollar_sign         0     0     0     0     0     0     0     0   \n",
       "nlp_type_time                  0     0     0     0     0     0     0     0   \n",
       "nlp_type_work_of_art           0     0     0     0     0     0     0     0   \n",
       "\n",
       "                           19700 2302  360   18687 3510  38403 36201 29428  \\\n",
       "ent_type_percent               0     0     0     0     0     0     0     0   \n",
       "ent_type_time                  0     0     0     0     0     0     0     0   \n",
       "ent_type_work_of_art           0     0     0     0     0     0     0     0   \n",
       "nlp_pofs_cconj                 0     0     0     0     0     0     0     0   \n",
       "nlp_tag_jj                     0     0     0     0     0     0     1     0   \n",
       "nlp_tag_left_round_bracket     0     0     0     0     0     0     0     0   \n",
       "nlp_tag_nan                    0     1     1     0     1     0     0     1   \n",
       "nlp_tag_nfp                    0     0     0     0     0     0     0     0   \n",
       "nlp_tag_vb                     0     0     0     0     0     1     0     0   \n",
       "nlp_tag_wp_dollar_sign         0     0     0     0     0     0     0     0   \n",
       "nlp_type_time                  0     0     0     0     0     0     0     0   \n",
       "nlp_type_work_of_art           0     0     0     0     0     0     0     0   \n",
       "\n",
       "                           4515  39324  \n",
       "ent_type_percent               0     0  \n",
       "ent_type_time                  0     0  \n",
       "ent_type_work_of_art           0     0  \n",
       "nlp_pofs_cconj                 0     0  \n",
       "nlp_tag_jj                     1     0  \n",
       "nlp_tag_left_round_bracket     0     0  \n",
       "nlp_tag_nan                    0     1  \n",
       "nlp_tag_nfp                    0     0  \n",
       "nlp_tag_vb                     0     0  \n",
       "nlp_tag_wp_dollar_sign         0     0  \n",
       "nlp_type_time                  0     0  \n",
       "nlp_type_work_of_art           0     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# One-hot encode the input features columns in the one-hot encode data frame\n",
    "if nu.pickle_exists('one_hot_encode_df'): one_hot_encode_df = nu.load_object('one_hot_encode_df')\n",
    "else:\n",
    "    ascii_regex = re.compile('[^a-z0-9]+')\n",
    "    one_hot_encode_df = nu.one_hot_encode(deduped_lower_case_ners_df, input_features)\n",
    "    one_hot_encode_df = one_hot_encode_df.rename(columns={cn: ascii_regex.sub('_', cn.lower()).strip('_') for cn in one_hot_encode_df.columns})\n",
    "    \n",
    "    # Remove the columns with nulls in them\n",
    "    columns_list = sorted(set(one_hot_encode_df.columns) - set(one_hot_encode_df.dropna(axis='columns', how='any').columns))\n",
    "    one_hot_encode_df = one_hot_encode_df.drop(columns=columns_list)\n",
    "    assert one_hot_encode_df.shape == one_hot_encode_df.dropna(axis='index', how='any').shape, \"You don't understand how one-hot encoding works\"\n",
    "    \n",
    "    nu.store_objects(one_hot_encode_df=one_hot_encode_df, verbose=False)\n",
    "columns_list = [cn for cn in one_hot_encode_df.columns if any(map(lambda x: cn.endswith(x), ['_null', '_nan']))]\n",
    "print(columns_list)\n",
    "df = one_hot_encode_df.sample(min(18, one_hot_encode_df.shape[0])).dropna(axis='columns', how='all').T\n",
    "display(df.sample(min(12, df.shape[0])).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "575a493f-6b8f-4ceb-af7e-ee8399033064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verify no duplicate columns\n",
    "assert one_hot_encode_df.columns[one_hot_encode_df.columns.duplicated(keep=False)].shape[0] == 0, \"One hot has duplicate columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6f3813b-27a4-4c7c-ad34-f8e99e99607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_entity_i_loc', 'bert_entity_i_misc', 'bert_entity_i_org', 'bert_entity_nan', 'ent_type_cardinal', 'ent_type_event', 'ent_type_fac', 'ent_type_gpe', 'ent_type_law', 'ent_type_loc', 'ent_type_money', 'ent_type_nan', 'ent_type_norp', 'ent_type_org', 'ent_type_percent', 'ent_type_product', 'ent_type_quantity', 'ent_type_time', 'ent_type_work_of_art', 'nlp_pofs_adj', 'nlp_pofs_adp', 'nlp_pofs_adv', 'nlp_pofs_aux', 'nlp_pofs_cconj', 'nlp_pofs_det', 'nlp_pofs_intj', 'nlp_pofs_nan', 'nlp_pofs_noun', 'nlp_pofs_num', 'nlp_pofs_part', 'nlp_pofs_pron', 'nlp_pofs_propn', 'nlp_pofs_punct', 'nlp_pofs_sconj', 'nlp_pofs_space', 'nlp_pofs_sym', 'nlp_pofs_verb', 'nlp_pofs_x', 'nlp_tag_add', 'nlp_tag_cc', 'nlp_tag_cd', 'nlp_tag_colon', 'nlp_tag_comma', 'nlp_tag_dollar_sign', 'nlp_tag_double_backtick', 'nlp_tag_double_prime', 'nlp_tag_dt', 'nlp_tag_full_stop', 'nlp_tag_fw', 'nlp_tag_hyph', 'nlp_tag_in', 'nlp_tag_jj', 'nlp_tag_jjr', 'nlp_tag_jjs', 'nlp_tag_left_round_bracket', 'nlp_tag_ls', 'nlp_tag_md', 'nlp_tag_nan', 'nlp_tag_nfp', 'nlp_tag_nn', 'nlp_tag_nnp', 'nlp_tag_nnps', 'nlp_tag_nns', 'nlp_tag_pos', 'nlp_tag_prp', 'nlp_tag_prp_dollar_sign', 'nlp_tag_rb', 'nlp_tag_rbr', 'nlp_tag_right_round_bracket', 'nlp_tag_rp', 'nlp_tag_sym', 'nlp_tag_to', 'nlp_tag_uh', 'nlp_tag_underscore_sp', 'nlp_tag_vb', 'nlp_tag_vbd', 'nlp_tag_vbg', 'nlp_tag_vbn', 'nlp_tag_vbp', 'nlp_tag_vbz', 'nlp_tag_wdt', 'nlp_tag_wp', 'nlp_tag_wp_dollar_sign', 'nlp_tag_wrb', 'nlp_tag_xx', 'nlp_type_cardinal', 'nlp_type_event', 'nlp_type_fac', 'nlp_type_gpe', 'nlp_type_language', 'nlp_type_law', 'nlp_type_loc', 'nlp_type_money', 'nlp_type_nan', 'nlp_type_norp', 'nlp_type_ordinal', 'nlp_type_org', 'nlp_type_percent', 'nlp_type_product', 'nlp_type_quantity', 'nlp_type_time', 'nlp_type_work_of_art']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dropped_columns = ['text_str', 'is_probe', 'lr_is_probe', 'rf_is_probe', 'hgb_is_probe']\n",
    "sorted(set(one_hot_encode_df.columns) - set(dropped_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e26f101-f817-4243-b041-621ab2988274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>count_blanks</th>\n",
       "      <th>count_uniques</th>\n",
       "      <th>count_zeroes</th>\n",
       "      <th>has_dates</th>\n",
       "      <th>min_value</th>\n",
       "      <th>max_value</th>\n",
       "      <th>only_integers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ent_type_cardinal</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ent_type_nan</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nlp_tag_cd</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nlp_tag_double_prime</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nlp_tag_nns</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>nlp_tag_prp_dollar_sign</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>nlp_tag_sym</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>nlp_tag_vbz</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>nlp_type_quantity</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>nlp_pofs_adv</td>\n",
       "      <td>uint8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column_name  dtype  count_blanks  count_uniques  count_zeroes  \\\n",
       "2         ent_type_cardinal  uint8             0              1            20   \n",
       "16             ent_type_nan  uint8             0              2             4   \n",
       "19               nlp_tag_cd  uint8             0              2            18   \n",
       "24     nlp_tag_double_prime  uint8             0              1            20   \n",
       "40              nlp_tag_nns  uint8             0              1            20   \n",
       "43  nlp_tag_prp_dollar_sign  uint8             0              1            20   \n",
       "48              nlp_tag_sym  uint8             0              1            20   \n",
       "57              nlp_tag_vbz  uint8             0              1            20   \n",
       "77        nlp_type_quantity  uint8             0              1            20   \n",
       "83             nlp_pofs_adv  uint8             0              2            19   \n",
       "\n",
       "    has_dates min_value max_value only_integers  \n",
       "2        True         0         0          True  \n",
       "16       True         0         1          True  \n",
       "19       True         0         1          True  \n",
       "24       True         0         0          True  \n",
       "40       True         0         0          True  \n",
       "43       True         0         0          True  \n",
       "48       True         0         0          True  \n",
       "57       True         0         0          True  \n",
       "77       True         0         0          True  \n",
       "83       True         0         1          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Analyze the input features\n",
    "if nu.pickle_exists('one_hot_column_descriptions_df'): one_hot_column_descriptions_df = nu.load_object('one_hot_column_descriptions_df')\n",
    "else:\n",
    "    one_hot_column_descriptions_df = nu.get_column_descriptions(one_hot_encode_df.sample(min(20, one_hot_encode_df.shape[0])))\n",
    "    nu.store_objects(one_hot_column_descriptions_df=one_hot_column_descriptions_df, verbose=False)\n",
    "    \n",
    "display(one_hot_column_descriptions_df.sample(min(10, one_hot_column_descriptions_df.shape[0])).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bac5e-031b-43e2-a81a-ffe2e6ee0551",
   "metadata": {},
   "source": [
    "\n",
    "#### Train a classifier on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "133d8740-5942-4a7f-af82-300b9eca020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a classifier on the data frame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "df = one_hot_encode_df.dropna(axis='columns', how='all').dropna(axis='index', how='any')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[cn for cn in dropped_columns if cn in df.columns]),\n",
    "    df.is_probe,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert the uint8 features to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c67b27a5-4746-4199-8eaa-de5a7b34dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a random forest classifier\n",
    "# The model is biased towards the majority class (False) and struggles to identify the minority class (True)\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced')\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "rf_accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "# Calculate the feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a data frame to store the feature names and feature importances\n",
    "feature_importances_df = DataFrame()\n",
    "feature_importances_df['feature_name'] = df.drop(columns=[cn for cn in dropped_columns if cn in df.columns]).columns\n",
    "feature_importances_df['feature_importance'] = feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e6af298-eedc-499f-aebf-64d6d9beb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a Logistic Regression (aka logit, MaxEnt) classifier\n",
    "# The model is biased towards the majority class (False) and struggles to identify the minority class (True)\n",
    "lr_classifier = LogisticRegression(class_weight='balanced')\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = lr_classifier.predict(X_test)\n",
    "lr_accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "# Get the coefficients of the logistic regression model\n",
    "feature_coefficients = lr_classifier.coef_[0]\n",
    "\n",
    "# Create a data frame to store the feature names and feature coefficients\n",
    "feature_coefficients_df = DataFrame()\n",
    "feature_coefficients_df['feature_name'] = df.drop(columns=[cn for cn in dropped_columns if cn in df.columns]).columns\n",
    "feature_coefficients_df['feature_coefficient'] = feature_coefficients\n",
    "feature_coefficients_df['absolute_coefficient'] = feature_coefficients_df.feature_coefficient.map(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b0197a1-3a45-4e17-849d-219ab5fdd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a Histogram-based Gradient Boosting classifier with balanced class weights\n",
    "# minority_class_mask_series = (y_train == True)\n",
    "# minority_class_weight = 1\n",
    "# majority_class_weight = 0.1\n",
    "# sample_weight=np.where(minority_class_mask_series, minority_class_weight, majority_class_weight)\n",
    "hgb_classifier = HistGradientBoostingClassifier()\n",
    "hgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = hgb_classifier.predict(X_test)\n",
    "hgb_accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "# Calculate the feature importances using the Permutation Importance algorithm\n",
    "from sklearn.inspection import permutation_importance\n",
    "hgb_permutation_importances = permutation_importance(hgb_classifier, X_test, y_test)\n",
    "\n",
    "# Create a data frame to store the feature names and feature coefficients\n",
    "hgb_permutation_importances_df = DataFrame()\n",
    "hgb_permutation_importances_df['feature_name'] = df.drop(columns=[cn for cn in dropped_columns if cn in df.columns]).columns\n",
    "for fn in dir(hgb_permutation_importances):\n",
    "    if (fn == 'importances'): continue\n",
    "    else: hgb_permutation_importances_df[fn] = eval(f'hgb_permutation_importances.{fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcfa2d5a-e02b-4a47-bb83-6ec11fdd31d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(hgb_classifier.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebc83438-4828-4891-b8de-6868e6d80038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ent_type_cardinal', 'ent_type_event', 'ent_type_fac',\n",
       "       'ent_type_gpe', 'ent_type_law', 'ent_type_loc', 'ent_type_money',\n",
       "       'ent_type_norp', 'ent_type_org', 'ent_type_percent',\n",
       "       'ent_type_product', 'ent_type_quantity', 'ent_type_time',\n",
       "       'ent_type_work_of_art', 'ent_type_nan', 'nlp_tag_add',\n",
       "       'nlp_tag_cc', 'nlp_tag_cd', 'nlp_tag_colon', 'nlp_tag_comma',\n",
       "       'nlp_tag_dollar_sign', 'nlp_tag_double_backtick',\n",
       "       'nlp_tag_double_prime', 'nlp_tag_dt', 'nlp_tag_full_stop',\n",
       "       'nlp_tag_fw', 'nlp_tag_hyph', 'nlp_tag_in', 'nlp_tag_jj',\n",
       "       'nlp_tag_jjr', 'nlp_tag_jjs', 'nlp_tag_left_round_bracket',\n",
       "       'nlp_tag_ls', 'nlp_tag_md', 'nlp_tag_nfp', 'nlp_tag_nn',\n",
       "       'nlp_tag_nnp', 'nlp_tag_nnps', 'nlp_tag_nns', 'nlp_tag_pos',\n",
       "       'nlp_tag_prp', 'nlp_tag_prp_dollar_sign', 'nlp_tag_rb',\n",
       "       'nlp_tag_rbr', 'nlp_tag_right_round_bracket', 'nlp_tag_rp',\n",
       "       'nlp_tag_sym', 'nlp_tag_to', 'nlp_tag_uh', 'nlp_tag_underscore_sp',\n",
       "       'nlp_tag_vb', 'nlp_tag_vbd', 'nlp_tag_vbg', 'nlp_tag_vbn',\n",
       "       'nlp_tag_vbp', 'nlp_tag_vbz', 'nlp_tag_wdt', 'nlp_tag_wp',\n",
       "       'nlp_tag_wp_dollar_sign', 'nlp_tag_wrb', 'nlp_tag_xx',\n",
       "       'nlp_tag_nan', 'nlp_type_cardinal', 'nlp_type_event',\n",
       "       'nlp_type_fac', 'nlp_type_gpe', 'nlp_type_language',\n",
       "       'nlp_type_law', 'nlp_type_loc', 'nlp_type_money', 'nlp_type_norp',\n",
       "       'nlp_type_ordinal', 'nlp_type_org', 'nlp_type_percent',\n",
       "       'nlp_type_product', 'nlp_type_quantity', 'nlp_type_time',\n",
       "       'nlp_type_work_of_art', 'nlp_type_nan', 'nlp_pofs_adj',\n",
       "       'nlp_pofs_adp', 'nlp_pofs_adv', 'nlp_pofs_aux', 'nlp_pofs_cconj',\n",
       "       'nlp_pofs_det', 'nlp_pofs_intj', 'nlp_pofs_noun', 'nlp_pofs_num',\n",
       "       'nlp_pofs_part', 'nlp_pofs_pron', 'nlp_pofs_propn',\n",
       "       'nlp_pofs_punct', 'nlp_pofs_sconj', 'nlp_pofs_space',\n",
       "       'nlp_pofs_sym', 'nlp_pofs_verb', 'nlp_pofs_x', 'nlp_pofs_nan',\n",
       "       'bert_entity_i_loc', 'bert_entity_i_misc', 'bert_entity_i_org',\n",
       "       'bert_entity_nan'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(hgb_classifier.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08e35285-fd04-4ef5-bf5f-071408815e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(hgb_classifier.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77949afb-da59-4eb1-b8bd-45d5bdedb962",
   "metadata": {},
   "source": [
    "\n",
    "#### Evaluate the accuracies and importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07e30eae-8db2-4261-99fa-112b34abe46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 0.6769334912844813\n",
      "LR Accuracy: 0.6637332882044339\n",
      "HGB Accuracy: 0.9974614994076832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>nlp_pofs_nan</td>\n",
       "      <td>0.160031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>nlp_tag_nan</td>\n",
       "      <td>0.133636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ent_type_nan</td>\n",
       "      <td>0.085094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ent_type_org</td>\n",
       "      <td>0.054013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ent_type_cardinal</td>\n",
       "      <td>0.042695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>nlp_pofs_propn</td>\n",
       "      <td>0.038689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>nlp_pofs_verb</td>\n",
       "      <td>0.036264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>nlp_type_nan</td>\n",
       "      <td>0.030506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ent_type_product</td>\n",
       "      <td>0.029586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nlp_tag_nn</td>\n",
       "      <td>0.025412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  feature_importance\n",
       "97       nlp_pofs_nan            0.160031\n",
       "61        nlp_tag_nan            0.133636\n",
       "14       ent_type_nan            0.085094\n",
       "8        ent_type_org            0.054013\n",
       "0   ent_type_cardinal            0.042695\n",
       "90     nlp_pofs_propn            0.038689\n",
       "95      nlp_pofs_verb            0.036264\n",
       "78       nlp_type_nan            0.030506\n",
       "10   ent_type_product            0.029586\n",
       "35         nlp_tag_nn            0.025412"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>nlp_tag_vb</td>\n",
       "      <td>4.507981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>nlp_tag_xx</td>\n",
       "      <td>4.292139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ent_type_cardinal</td>\n",
       "      <td>-3.458741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ent_type_product</td>\n",
       "      <td>3.195832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>nlp_type_gpe</td>\n",
       "      <td>3.120390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>nlp_type_cardinal</td>\n",
       "      <td>-3.116546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ent_type_law</td>\n",
       "      <td>-3.024457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ent_type_loc</td>\n",
       "      <td>2.957711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ent_type_fac</td>\n",
       "      <td>2.904268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>nlp_pofs_nan</td>\n",
       "      <td>2.806724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  feature_coefficient\n",
       "50         nlp_tag_vb             4.507981\n",
       "60         nlp_tag_xx             4.292139\n",
       "0   ent_type_cardinal            -3.458741\n",
       "10   ent_type_product             3.195832\n",
       "65       nlp_type_gpe             3.120390\n",
       "62  nlp_type_cardinal            -3.116546\n",
       "4        ent_type_law            -3.024457\n",
       "5        ent_type_loc             2.957711\n",
       "2        ent_type_fac             2.904268\n",
       "97       nlp_pofs_nan             2.806724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importances_mean</th>\n",
       "      <th>importances_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ent_type_cardinal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>nlp_type_fac</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>nlp_type_product</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>nlp_type_percent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>nlp_type_org</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>nlp_type_ordinal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>nlp_type_norp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>nlp_type_money</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>nlp_type_loc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>nlp_type_law</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importances_mean  importances_std\n",
       "0   ent_type_cardinal               0.0              0.0\n",
       "64       nlp_type_fac               0.0              0.0\n",
       "74   nlp_type_product               0.0              0.0\n",
       "73   nlp_type_percent               0.0              0.0\n",
       "72       nlp_type_org               0.0              0.0\n",
       "71   nlp_type_ordinal               0.0              0.0\n",
       "70      nlp_type_norp               0.0              0.0\n",
       "69     nlp_type_money               0.0              0.0\n",
       "68       nlp_type_loc               0.0              0.0\n",
       "67       nlp_type_law               0.0              0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Print the accuracies\n",
    "print('RF Accuracy:', rf_accuracy)\n",
    "print('LR Accuracy:', lr_accuracy)\n",
    "print('HGB Accuracy:', hgb_accuracy)\n",
    "\n",
    "# Display the feature importances data frame\n",
    "display(feature_importances_df.sort_values('feature_importance', ascending=False).head(10))\n",
    "\n",
    "# Display the feature coefficients data frame\n",
    "columns_list = ['feature_name', 'feature_coefficient']\n",
    "display(feature_coefficients_df.sort_values('absolute_coefficient', ascending=False)[columns_list].head(10))\n",
    "\n",
    "# Display the permutation importances data frame\n",
    "columns_list = ['feature_name', 'importances_mean']\n",
    "df = hgb_permutation_importances_df.drop(columns_list, axis='columns')\n",
    "max_importance = df.max().max()\n",
    "columns_list += df.columns[df.eq(max_importance).any()].tolist()[:7-len(columns_list)]\n",
    "display(hgb_permutation_importances_df.sort_values('importances_mean', ascending=False)[columns_list].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7950a-a29a-4a66-869d-ae6eb5a21e18",
   "metadata": {},
   "source": [
    "\n",
    "#### Perform a sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee33f3d5-9778-4c85-bfae-8456908b9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39412\n",
      "(1, 107)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39412</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_str</th>\n",
       "      <td>code of ethics for nurses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_work_of_art</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag_nan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_type_nan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_pofs_nan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_nan</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_is_probe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_is_probe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hgb_is_probe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          39412\n",
       "text_str              code of ethics for nurses\n",
       "ent_type_work_of_art                          1\n",
       "nlp_tag_nan                                   1\n",
       "nlp_type_nan                                  1\n",
       "nlp_pofs_nan                                  1\n",
       "bert_entity_nan                               1\n",
       "lr_is_probe                                 NaN\n",
       "rf_is_probe                                 NaN\n",
       "hgb_is_probe                                NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Display the one-hot encoded sample\n",
    "input_encode_df = one_hot_encode_df.sample(1)\n",
    "input_encode_idx = input_encode_df.index.tolist()[0]\n",
    "print(input_encode_idx)\n",
    "print(input_encode_df.shape)\n",
    "mask_series = (input_encode_df.T[input_encode_idx] == 0)\n",
    "df = input_encode_df.T[~mask_series]\n",
    "enc_idx_list = df.index.tolist()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae92427f-d245-487e-a32a-a5a336c2bf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>39412</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_probe</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_type</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_str</th>\n",
       "      <td>code of ethics for nurses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type</th>\n",
       "      <td>WORK_OF_ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_is_probe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hgb_is_probe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_tag</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_is_probe</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp_pofs</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  39412\n",
       "is_probe                          False\n",
       "nlp_type                            NaN\n",
       "text_str      code of ethics for nurses\n",
       "ent_type                    WORK_OF_ART\n",
       "lr_is_probe                         NaN\n",
       "bert_entity                         NaN\n",
       "hgb_is_probe                        NaN\n",
       "nlp_tag                             NaN\n",
       "rf_is_probe                         NaN\n",
       "nlp_pofs                            NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Display the NERs sample\n",
    "mask_series = (deduped_lower_case_ners_df.index == input_encode_idx)\n",
    "df = deduped_lower_case_ners_df[mask_series]\n",
    "print(df.shape)\n",
    "cn_set = set()\n",
    "for cn in deduped_lower_case_ners_df.columns:\n",
    "    for enc_idx in enc_idx_list:\n",
    "        if enc_idx.startswith(cn): cn_set.add(cn)\n",
    "columns_list = ['is_probe'] + list(cn_set)\n",
    "display(df[columns_list].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51a42c47-50e1-434e-a61b-adc38cd25dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the input features to a NumPy array\n",
    "input_features_array = np.array(input_encode_df.drop(columns=dropped_columns).values)\n",
    "actual_is_probe = input_encode_df.is_probe.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb09dbd8-d660-40c7-afd1-71396207a9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: predicted: True, actual: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the LR is probe\n",
    "predicted_is_probe = sorted(\n",
    "    [(c, p) for c, p in zip(lr_classifier.classes_, lr_classifier.predict_proba(input_features_array)[0])], key=lambda x: x[1], reverse=True\n",
    ")[0][0]\n",
    "print(f'LR: predicted: {predicted_is_probe}, actual: {actual_is_probe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "44e6e809-af17-41c0-a224-a9cc281342bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: predicted: True, actual: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the RF is probe\n",
    "predicted_is_probe = sorted(\n",
    "    [(c, p) for c, p in zip(rf_classifier.classes_, rf_classifier.predict_proba(input_features_array)[0])], key=lambda x: x[1], reverse=True\n",
    ")[0][0]\n",
    "print(f'RF: predicted: {predicted_is_probe}, actual: {actual_is_probe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ed145e9-2a3d-44a9-80fe-aeb2cd7c63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGB: predicted: False, actual: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the HGB is probe\n",
    "predicted_is_probe = sorted(\n",
    "    [(c, p) for c, p in zip(hgb_classifier.classes_, hgb_classifier.predict_proba(input_features_array)[0])], key=lambda x: x[1], reverse=True\n",
    ")[0][0]\n",
    "print(f'HGB: predicted: {predicted_is_probe}, actual: {actual_is_probe}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "769bfcba-6ea3-42bf-948c-15fe3fb1ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the predicted columns\n",
    "one_hot_encode_df['lr_is_probe'] = nan\n",
    "one_hot_encode_df['rf_is_probe'] = nan\n",
    "one_hot_encode_df['hgb_is_probe'] = nan\n",
    "for input_encode_idx, input_encode_series in one_hot_encode_df.iterrows():\n",
    "    \n",
    "    # Convert the input features to a NumPy array\n",
    "    input_features_array = np.array(input_encode_series.drop(index=dropped_columns).values).reshape(1, -1)\n",
    "    actual_is_probe = input_encode_series.is_probe\n",
    "    # assert deduped_lower_case_ners_df.loc[input_encode_idx, 'is_probe'] == actual_is_probe, \"You don't understand how dataframes work\"\n",
    "    \n",
    "    # Predict the LR is probe\n",
    "    lr_is_probe = sorted(\n",
    "        [(c, p) for c, p in zip(lr_classifier.classes_, lr_classifier.predict_proba(input_features_array)[0])], key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[0][0]\n",
    "    one_hot_encode_df.loc[input_encode_idx, 'lr_is_probe'] = lr_is_probe\n",
    "    \n",
    "    # Predict the RF is probe\n",
    "    rf_is_probe = sorted(\n",
    "        [(c, p) for c, p in zip(rf_classifier.classes_, rf_classifier.predict_proba(input_features_array)[0])], key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[0][0]\n",
    "    one_hot_encode_df.loc[input_encode_idx, 'rf_is_probe'] = rf_is_probe\n",
    "    \n",
    "    # Predict the HGB is probe\n",
    "    hgb_is_probe = sorted(\n",
    "        [(c, p) for c, p in zip(hgb_classifier.classes_, hgb_classifier.predict_proba(input_features_array)[0])], key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[0][0]\n",
    "    one_hot_encode_df.loc[input_encode_idx, 'hgb_is_probe'] = hgb_is_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef8b4ed7-b9a5-4145-b9a8-02813ed6e27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/one_hot_encode_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/one_hot_encode_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nu.store_objects(one_hot_encode_df=one_hot_encode_df)\n",
    "nu.save_data_frames(one_hot_encode_df=one_hot_encode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a7152d7-423f-4c43-a627-139868839d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_entity_i_loc', 'bert_entity_i_misc', 'bert_entity_i_org', 'bert_entity_nan', 'ent_type_cardinal', 'ent_type_event', 'ent_type_fac', 'ent_type_gpe', 'ent_type_law', 'ent_type_loc', 'ent_type_money', 'ent_type_nan', 'ent_type_norp', 'ent_type_org', 'ent_type_percent', 'ent_type_product', 'ent_type_quantity', 'ent_type_time', 'ent_type_work_of_art', 'hgb_is_probe', 'is_probe', 'lr_is_probe', 'nlp_pofs_adj', 'nlp_pofs_adp', 'nlp_pofs_adv', 'nlp_pofs_aux', 'nlp_pofs_cconj', 'nlp_pofs_det', 'nlp_pofs_intj', 'nlp_pofs_nan', 'nlp_pofs_noun', 'nlp_pofs_num', 'nlp_pofs_part', 'nlp_pofs_pron', 'nlp_pofs_propn', 'nlp_pofs_punct', 'nlp_pofs_sconj', 'nlp_pofs_space', 'nlp_pofs_sym', 'nlp_pofs_verb', 'nlp_pofs_x', 'nlp_tag_add', 'nlp_tag_cc', 'nlp_tag_cd', 'nlp_tag_colon', 'nlp_tag_comma', 'nlp_tag_dollar_sign', 'nlp_tag_double_backtick', 'nlp_tag_double_prime', 'nlp_tag_dt', 'nlp_tag_full_stop', 'nlp_tag_fw', 'nlp_tag_hyph', 'nlp_tag_in', 'nlp_tag_jj', 'nlp_tag_jjr', 'nlp_tag_jjs', 'nlp_tag_left_round_bracket', 'nlp_tag_ls', 'nlp_tag_md', 'nlp_tag_nan', 'nlp_tag_nfp', 'nlp_tag_nn', 'nlp_tag_nnp', 'nlp_tag_nnps', 'nlp_tag_nns', 'nlp_tag_pos', 'nlp_tag_prp', 'nlp_tag_prp_dollar_sign', 'nlp_tag_rb', 'nlp_tag_rbr', 'nlp_tag_right_round_bracket', 'nlp_tag_rp', 'nlp_tag_sym', 'nlp_tag_to', 'nlp_tag_uh', 'nlp_tag_underscore_sp', 'nlp_tag_vb', 'nlp_tag_vbd', 'nlp_tag_vbg', 'nlp_tag_vbn', 'nlp_tag_vbp', 'nlp_tag_vbz', 'nlp_tag_wdt', 'nlp_tag_wp', 'nlp_tag_wp_dollar_sign', 'nlp_tag_wrb', 'nlp_tag_xx', 'nlp_type_cardinal', 'nlp_type_event', 'nlp_type_fac', 'nlp_type_gpe', 'nlp_type_language', 'nlp_type_law', 'nlp_type_loc', 'nlp_type_money', 'nlp_type_nan', 'nlp_type_norp', 'nlp_type_ordinal', 'nlp_type_org', 'nlp_type_percent', 'nlp_type_product', 'nlp_type_quantity', 'nlp_type_time', 'nlp_type_work_of_art', 'rf_is_probe', 'text_str']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted(one_hot_encode_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fc02e51-dd45-4f0d-aa90-506e9a34fbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot_encode_df.is_probe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3013031d-be30-4fa9-b0cd-e358e93c8f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([True, False], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot_encode_df.lr_is_probe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdd18c67-b265-4aa5-b700-7e75662a71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([True, False], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot_encode_df.rf_is_probe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de9f3d31-e075-43cf-bc93-a2a8f8b7065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot_encode_df.hgb_is_probe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca130961-8cb4-4cb7-bb3a-9d22af0b2c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>43210</th>\n",
       "      <th>40183</th>\n",
       "      <th>37002</th>\n",
       "      <th>273</th>\n",
       "      <th>3089</th>\n",
       "      <th>2818</th>\n",
       "      <th>8690</th>\n",
       "      <th>14115</th>\n",
       "      <th>5805</th>\n",
       "      <th>40594</th>\n",
       "      <th>46089</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_str</th>\n",
       "      <td>a person responsible for his or her subordinates</td>\n",
       "      <td>m carey &amp; sons</td>\n",
       "      <td>refining</td>\n",
       "      <td>early</td>\n",
       "      <td>—united states</td>\n",
       "      <td>reactive skin decontamination lotion</td>\n",
       "      <td>washington, dc\\n</td>\n",
       "      <td>the un general assembly</td>\n",
       "      <td>rome statute party</td>\n",
       "      <td>university of california at san francisco</td>\n",
       "      <td>perform descriptive epidemiology \\ninformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_cardinal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_event</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_fac</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_i_org</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_nan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_is_probe</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_is_probe</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hgb_is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              43210  \\\n",
       "text_str           a person responsible for his or her subordinates   \n",
       "is_probe                                                      False   \n",
       "ent_type_cardinal                                                 0   \n",
       "ent_type_event                                                    0   \n",
       "ent_type_fac                                                      0   \n",
       "...                                                             ...   \n",
       "bert_entity_i_org                                                 0   \n",
       "bert_entity_nan                                                   1   \n",
       "lr_is_probe                                                    True   \n",
       "rf_is_probe                                                    True   \n",
       "hgb_is_probe                                                  False   \n",
       "\n",
       "                            40183     37002  273             3089   \\\n",
       "text_str           m carey & sons  refining  early  —united states   \n",
       "is_probe                    False     False  False           False   \n",
       "ent_type_cardinal               0         0      0               0   \n",
       "ent_type_event                  0         0      0               0   \n",
       "ent_type_fac                    0         0      0               0   \n",
       "...                           ...       ...    ...             ...   \n",
       "bert_entity_i_org               0         0      0               0   \n",
       "bert_entity_nan                 1         1      1               1   \n",
       "lr_is_probe                  True      True   True            True   \n",
       "rf_is_probe                  True      True   True           False   \n",
       "hgb_is_probe                False     False  False           False   \n",
       "\n",
       "                                                  2818              8690   \\\n",
       "text_str           reactive skin decontamination lotion  washington, dc\\n   \n",
       "is_probe                                          False             False   \n",
       "ent_type_cardinal                                     0                 0   \n",
       "ent_type_event                                        0                 0   \n",
       "ent_type_fac                                          0                 0   \n",
       "...                                                 ...               ...   \n",
       "bert_entity_i_org                                     0                 0   \n",
       "bert_entity_nan                                       1                 1   \n",
       "lr_is_probe                                        True              True   \n",
       "rf_is_probe                                        True             False   \n",
       "hgb_is_probe                                      False             False   \n",
       "\n",
       "                                     14115               5805   \\\n",
       "text_str           the un general assembly  rome statute party   \n",
       "is_probe                             False               False   \n",
       "ent_type_cardinal                        0                   0   \n",
       "ent_type_event                           0                   0   \n",
       "ent_type_fac                             0                   0   \n",
       "...                                    ...                 ...   \n",
       "bert_entity_i_org                        0                   0   \n",
       "bert_entity_nan                          1                   1   \n",
       "lr_is_probe                           True                True   \n",
       "rf_is_probe                           True                True   \n",
       "hgb_is_probe                         False               False   \n",
       "\n",
       "                                                       40594  \\\n",
       "text_str           university of california at san francisco   \n",
       "is_probe                                               False   \n",
       "ent_type_cardinal                                          0   \n",
       "ent_type_event                                             0   \n",
       "ent_type_fac                                               0   \n",
       "...                                                      ...   \n",
       "bert_entity_i_org                                          0   \n",
       "bert_entity_nan                                            1   \n",
       "lr_is_probe                                             True   \n",
       "rf_is_probe                                             True   \n",
       "hgb_is_probe                                           False   \n",
       "\n",
       "                                                            46089  \n",
       "text_str           perform descriptive epidemiology \\ninformation  \n",
       "is_probe                                                    False  \n",
       "ent_type_cardinal                                               0  \n",
       "ent_type_event                                                  0  \n",
       "ent_type_fac                                                    0  \n",
       "...                                                           ...  \n",
       "bert_entity_i_org                                               0  \n",
       "bert_entity_nan                                                 1  \n",
       "lr_is_probe                                                  True  \n",
       "rf_is_probe                                                  True  \n",
       "hgb_is_probe                                                False  \n",
       "\n",
       "[107 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mask_series = False\n",
    "for cn in ['lr_is_probe', 'rf_is_probe', 'hgb_is_probe']:\n",
    "    mask_series = ~one_hot_encode_df.is_probe.isnull() & ~one_hot_encode_df[cn].isnull()\n",
    "    mask_series &= (one_hot_encode_df[cn] != one_hot_encode_df.is_probe)\n",
    "    df = one_hot_encode_df[mask_series]\n",
    "    if df.shape[0]:\n",
    "        display(df.sample(min(11, df.shape[0])).dropna(axis='columns', how='all').T)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71dd64dd-0451-4e9f-8012-cf40773d45ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>135</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>204</th>\n",
       "      <th>2317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_str</th>\n",
       "      <td>washington, dc: \\ngovernment printing office</td>\n",
       "      <td>needleless</td>\n",
       "      <td>1959;59(1):1–9</td>\n",
       "      <td>healing</td>\n",
       "      <td>current resources - yes\\nimmediate\\nlikely</td>\n",
       "      <td>pneumatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_cardinal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_event</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_fac</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_i_org</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_nan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_is_probe</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hgb_is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           24          135   \\\n",
       "text_str           washington, dc: \\ngovernment printing office  needleless   \n",
       "is_probe                                                  False        True   \n",
       "ent_type_cardinal                                             0           0   \n",
       "ent_type_event                                                0           0   \n",
       "ent_type_fac                                                  0           0   \n",
       "...                                                         ...         ...   \n",
       "bert_entity_i_org                                             0           0   \n",
       "bert_entity_nan                                               1           1   \n",
       "lr_is_probe                                                True       False   \n",
       "rf_is_probe                                               False       False   \n",
       "hgb_is_probe                                              False       False   \n",
       "\n",
       "                             3        0     \\\n",
       "text_str           1959;59(1):1–9  healing   \n",
       "is_probe                    False    False   \n",
       "ent_type_cardinal               0        0   \n",
       "ent_type_event                  0        0   \n",
       "ent_type_fac                    0        0   \n",
       "...                           ...      ...   \n",
       "bert_entity_i_org               0        0   \n",
       "bert_entity_nan                 1        1   \n",
       "lr_is_probe                 False     True   \n",
       "rf_is_probe                 False     True   \n",
       "hgb_is_probe                False    False   \n",
       "\n",
       "                                                         204        2317  \n",
       "text_str           current resources - yes\\nimmediate\\nlikely  pneumatic  \n",
       "is_probe                                                 True       True  \n",
       "ent_type_cardinal                                           0          0  \n",
       "ent_type_event                                              0          0  \n",
       "ent_type_fac                                                0          0  \n",
       "...                                                       ...        ...  \n",
       "bert_entity_i_org                                           0          0  \n",
       "bert_entity_nan                                             1          1  \n",
       "lr_is_probe                                              True       True  \n",
       "rf_is_probe                                              True      False  \n",
       "hgb_is_probe                                            False      False  \n",
       "\n",
       "[107 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "columns_list = ['is_probe', 'lr_is_probe', 'rf_is_probe', 'hgb_is_probe']\n",
    "df = one_hot_encode_df.drop_duplicates(subset=columns_list)\n",
    "if df.shape[0]: display(df.sample(min(14, df.shape[0])).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50bc61b1-fe62-4a44-a6a3-26ac825f0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1356</th>\n",
       "      <th>24539</th>\n",
       "      <th>23304</th>\n",
       "      <th>613</th>\n",
       "      <th>14278</th>\n",
       "      <th>26249</th>\n",
       "      <th>19057</th>\n",
       "      <th>37614</th>\n",
       "      <th>6783</th>\n",
       "      <th>14332</th>\n",
       "      <th>27780</th>\n",
       "      <th>31455</th>\n",
       "      <th>23691</th>\n",
       "      <th>20539</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_str</th>\n",
       "      <td>1983–1984</td>\n",
       "      <td>uniformed services \\nuniversity of health scie...</td>\n",
       "      <td>the emancipation proclamation</td>\n",
       "      <td>”1(p33</td>\n",
       "      <td>malaria</td>\n",
       "      <td>concise</td>\n",
       "      <td>insertion</td>\n",
       "      <td>boston marathon</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>largest</td>\n",
       "      <td>− reassess</td>\n",
       "      <td>the international committee of the red\\nfig</td>\n",
       "      <td>el al45</td>\n",
       "      <td>hastings cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_cardinal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_event</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_type_fac</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_i_org</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert_entity_nan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_is_probe</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_is_probe</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hgb_is_probe</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1356   \\\n",
       "text_str           1983–1984   \n",
       "is_probe               False   \n",
       "ent_type_cardinal          0   \n",
       "ent_type_event             0   \n",
       "ent_type_fac               0   \n",
       "...                      ...   \n",
       "bert_entity_i_org          0   \n",
       "bert_entity_nan            1   \n",
       "lr_is_probe             True   \n",
       "rf_is_probe             True   \n",
       "hgb_is_probe           False   \n",
       "\n",
       "                                                               24539  \\\n",
       "text_str           uniformed services \\nuniversity of health scie...   \n",
       "is_probe                                                       False   \n",
       "ent_type_cardinal                                                  0   \n",
       "ent_type_event                                                     0   \n",
       "ent_type_fac                                                       0   \n",
       "...                                                              ...   \n",
       "bert_entity_i_org                                                  0   \n",
       "bert_entity_nan                                                    1   \n",
       "lr_is_probe                                                     True   \n",
       "rf_is_probe                                                     True   \n",
       "hgb_is_probe                                                   False   \n",
       "\n",
       "                                           23304   613      14278    26249  \\\n",
       "text_str           the emancipation proclamation  ”1(p33  malaria  concise   \n",
       "is_probe                                   False   False    False    False   \n",
       "ent_type_cardinal                              0       0        0        0   \n",
       "ent_type_event                                 0       0        0        0   \n",
       "ent_type_fac                                   0       0        0        0   \n",
       "...                                          ...     ...      ...      ...   \n",
       "bert_entity_i_org                              0       0        0        0   \n",
       "bert_entity_nan                                1       1        1        1   \n",
       "lr_is_probe                                 True    True     True     True   \n",
       "rf_is_probe                                 True    True     True     True   \n",
       "hgb_is_probe                               False   False    False    False   \n",
       "\n",
       "                       19057            37614       6783     14332  \\\n",
       "text_str           insertion  boston marathon  algorithms  largest   \n",
       "is_probe               False            False       False    False   \n",
       "ent_type_cardinal          0                0           0        0   \n",
       "ent_type_event             0                0           0        0   \n",
       "ent_type_fac               0                0           0        0   \n",
       "...                      ...              ...         ...      ...   \n",
       "bert_entity_i_org          0                0           0        0   \n",
       "bert_entity_nan            1                1           1        1   \n",
       "lr_is_probe             True             True        True     True   \n",
       "rf_is_probe             True             True        True     True   \n",
       "hgb_is_probe           False            False       False    False   \n",
       "\n",
       "                        27780                                        31455  \\\n",
       "text_str           − reassess  the international committee of the red\\nfig   \n",
       "is_probe                False                                        False   \n",
       "ent_type_cardinal           0                                            0   \n",
       "ent_type_event              0                                            0   \n",
       "ent_type_fac                0                                            0   \n",
       "...                       ...                                          ...   \n",
       "bert_entity_i_org           0                                            0   \n",
       "bert_entity_nan             1                                            1   \n",
       "lr_is_probe              True                                         True   \n",
       "rf_is_probe              True                                         True   \n",
       "hgb_is_probe            False                                        False   \n",
       "\n",
       "                     23691          20539  \n",
       "text_str           el al45  hastings cent  \n",
       "is_probe             False          False  \n",
       "ent_type_cardinal        0              0  \n",
       "ent_type_event           0              0  \n",
       "ent_type_fac             0              0  \n",
       "...                    ...            ...  \n",
       "bert_entity_i_org        0              0  \n",
       "bert_entity_nan          1              1  \n",
       "lr_is_probe           True           True  \n",
       "rf_is_probe          False           True  \n",
       "hgb_is_probe         False          False  \n",
       "\n",
       "[107 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mask_series = False\n",
    "for cn in ['lr_is_probe', 'rf_is_probe', 'hgb_is_probe']: mask_series |= (one_hot_encode_df[cn] == True)\n",
    "mask_series &= (one_hot_encode_df.is_probe == False)\n",
    "df = one_hot_encode_df[mask_series]\n",
    "if df.shape[0]:\n",
    "    print(len(df.text_str.tolist()))\n",
    "    display(df.sample(min(14, df.shape[0])).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60feb8-90ad-4cf6-9f35-3c39d3197acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2b76e-f140-4063-b6f2-7fb669284cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
