{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d88d0-ee28-42bf-b2df-28ef5f83333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the notebook\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46f8e2-a5c3-4fbb-9ec6-462e63b4d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import (np, sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "980de863-810c-4778-ad68-defd870c247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define convergence threshold\n",
    "threshold = 0.001\n",
    "\n",
    "# Initialize item logits and scores\n",
    "item_logits = np.array([correct_stills_logodds, correct_walkers_logodds, correct_wave_logodds, correct_walk_logodds])\n",
    "columns_list = ['is_stills_visited_first', 'is_walkers_visited_last', 'is_wave_command_issued', 'is_walk_command_issued']\n",
    "assert len(item_logits) == len(columns_list), 'The item logits need to be the same count as the number of columns in scores'\n",
    "df = item_logits_df[columns_list]\n",
    "assert df.applymap(lambda x: x not in [0, 1]).sum().sum() == 0, \"You have nulls in your data\"\n",
    "scores = df.values\n",
    "\n",
    "# Find the minimum and maximum values\n",
    "# min_value = np.min(item_logits)\n",
    "# max_value = np.max(item_logits)\n",
    "\n",
    "# Normalize the values\n",
    "# item_logits = (item_logits - min_value) / (max_value - min_value)\n",
    "\n",
    "# Define the number of iterations\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f76dd-2930-4bb8-9352-ce3ba1d23bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "class RaschModel:\n",
    "    def __init__(self, num_items, num_scenes, scores, item_logits):\n",
    "        self.num_items = num_items\n",
    "        self.num_scenes = num_scenes\n",
    "        self.scores = scores\n",
    "        self.item_logits = item_logits\n",
    "        \n",
    "    def fit(self, iterations, convergence_threshold=0.001):\n",
    "        person_estimates = np.random.normal(0, 1, size=self.num_scenes)\n",
    "        print('person_estimates', person_estimates.shape)\n",
    "        updated_item_logits = self.item_logits.copy()\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            \n",
    "            print('updated_item_logits', updated_item_logits.shape, updated_item_logits)\n",
    "            try:\n",
    "                print('person_estimates', person_estimates.shape, person_estimates)\n",
    "                logits = person_estimates + updated_item_logits\n",
    "            except:\n",
    "                print('person_estimates[:, np.newaxis]', person_estimates[:, np.newaxis].shape, person_estimates[:, np.newaxis])\n",
    "                logits = person_estimates[:, np.newaxis] + updated_item_logits\n",
    "            print('logits', logits.shape, logits)\n",
    "            \n",
    "            logits_int = logits.astype(int)\n",
    "            print('logits_int', logits_int.shape, logits_int)\n",
    "            \n",
    "            print('self.scores', self.scores.shape, self.scores)\n",
    "            predicted_scores = bernoulli.pmf(self.scores, logits_int)\n",
    "            print('predicted_scores', predicted_scores.shape, predicted_scores)\n",
    "            \n",
    "            # Update person estimates using MLE for bernoulli distribution\n",
    "            person_estimates = np.log(predicted_scores / (1 - predicted_scores))\n",
    "            print('person_estimates', person_estimates.shape, person_estimates)\n",
    "            \n",
    "            # Update item logits based on current person estimates\n",
    "            updated_item_logits = np.mean(logits, axis=0)\n",
    "            print()\n",
    "            print('updated_item_logits', updated_item_logits.shape)\n",
    "            \n",
    "            # Check for convergence\n",
    "            print('self.item_logits', self.item_logits.shape)\n",
    "            max_diff = np.max(np.abs(updated_item_logits - self.item_logits))\n",
    "            print('updated_item_logits - self.item_logits', updated_item_logits - self.item_logits)\n",
    "            print('np.abs(updated_item_logits - self.item_logits)', np.abs(updated_item_logits - self.item_logits))\n",
    "            print('max_diff', max_diff)\n",
    "            print('convergence_threshold', convergence_threshold)\n",
    "            if (max_diff <= convergence_threshold): break\n",
    "\n",
    "        self.person_estimates = person_estimates\n",
    "        self.updated_item_logits = updated_item_logits\n",
    "\n",
    "    def predict(self, new_scores):\n",
    "        new_logits = self.person_estimates[:, np.newaxis] + self.updated_item_logits\n",
    "        new_logits_int = new_logits.astype(int)\n",
    "        return bernoulli.pmf(new_scores, new_logits_int)\n",
    "\n",
    "# Example usage\n",
    "num_items = 4\n",
    "num_scenes = 10\n",
    "scores = np.random.randint(0, 2, size=(num_scenes, num_items))\n",
    "item_logits = np.random.randn(num_items)\n",
    "\n",
    "model = RaschModel(num_items, num_scenes, scores, item_logits)\n",
    "model.fit(iterations=1000)\n",
    "\n",
    "person_estimates = model.person_estimates\n",
    "updated_item_logits = model.updated_item_logits\n",
    "\n",
    "# Predict scores for new data\n",
    "new_scores = np.array([[1, 0, 1, 0]])\n",
    "predicted_probabilities = model.predict(new_scores)\n",
    "\n",
    "print('Person estimates:', person_estimates)\n",
    "print('Updated item logits:', updated_item_logits)\n",
    "print('Predicted probabilities:', predicted_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8c0ab85-8bea-4705-8188-1b9df90593fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### Use Pystan to estimate the item logits iteratively for each scene within a calibration process\n",
    "def analyze_data(item_logits, scores):\n",
    "    \"\"\"\n",
    "    Performs Rasch analysis using pystan and updates item logits.\n",
    "\n",
    "    Args:\n",
    "        item_logits: Current item logits for each scene.\n",
    "        scores: Scores for each participant on each scene (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "        person_estimates: Estimated ability levels for each participant.\n",
    "        updated_item_logits: Updated item logits for each scene.\n",
    "    \"\"\"\n",
    "\n",
    "    # Stan model code to define the Rasch model (you may need to adjust this based on your specific Rasch model)\n",
    "    stan_code = \"\"\"\n",
    "    data {\n",
    "        int<lower=0> num_items;  // Number of items (tasks)\n",
    "        int<lower=0> num_scenes; // Number of participants (scenes)\n",
    "        matrix[num_scenes, num_items] scores; // Observed responses (0 or 1)\n",
    "        vector[num_items] item_logits; // Item logits\n",
    "    }\n",
    "    \n",
    "    parameters {\n",
    "        vector[num_scenes] person_estimates; // Person abilities\n",
    "    }\n",
    "    \n",
    "    model {\n",
    "        // Rasch model likelihood\n",
    "        for (i in 1:num_scenes) {\n",
    "            vector[num_items] logits = item_logits + person_estimates[i];\n",
    "            int logits_int[num_items];\n",
    "            for (j in 1:num_items) {\n",
    "                logits_int[j] = round(logits[j]);\n",
    "            }\n",
    "            scores[i] ~ bernoulli_logit(logits_int);\n",
    "        }\n",
    "        \n",
    "        // Prior on person abilities\n",
    "        person_estimates ~ normal(0, 1);\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare data for Stan model\n",
    "    data = {\n",
    "        'num_items': len(item_logits),\n",
    "        'num_scenes': len(scores),\n",
    "        'scores': scores,\n",
    "        'item_logits': item_logits,\n",
    "    }\n",
    "    \n",
    "    # Compile the Stan model\n",
    "    sm = pystan.StanModel(model_code=stan_code)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Fit the model with the current item logits\n",
    "    try: fit = sm.sampling(data=data, init={'beta': item_logits}, iter=1000)\n",
    "    except ValueError as e:\n",
    "        print(str(e).strip())\n",
    "        try: fit = sm.sampling(data=data, init='random', iter=1000)\n",
    "        \n",
    "        # Fit the model to the data\n",
    "        except ValueError as e:\n",
    "            print(str(e).strip())\n",
    "            fit = sm.sampling(data=data, iter=1000, chains=4)\n",
    "    \n",
    "    # Extract person estimates and updated item logits\n",
    "    person_estimates = fit['person_estimates']\n",
    "    updated_item_logits = item_logits + fit['item_logits']\n",
    "    \n",
    "    return person_estimates, updated_item_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbcab8b8-7d0a-4179-972a-392dd9c3db6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to parse Stan model 'anon_model_ea35b30a6caf220bd69ab2b9f858089b'. Error message:\nSYNTAX ERROR, MESSAGE(S) FROM PARSER:\nNo matches for: \n\n  int(real)\n\nFunction int not found.\n error in 'unknown file name' at line 19, column 46\n  -------------------------------------------------\n    17:             int logits_int[num_items];\n    18:             for (j in 1:num_items) {\n    19:                 logits_int[j] = int(logits[j]);\n                                                     ^\n    20:             }\n  -------------------------------------------------\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Perform Rasch analysis using the current item logits\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# (This can be done using specialized software or libraries)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     person_estimates, updated_item_logits \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Check for convergence\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mabs\u001b[39m(updated_item_logits \u001b[38;5;241m-\u001b[39m item_logits)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n",
      "Cell \u001b[0;32mIn[30], line 53\u001b[0m, in \u001b[0;36manalyze_data\u001b[0;34m(item_logits, scores)\u001b[0m\n\u001b[1;32m     45\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(item_logits),\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_scenes\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(scores),\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m: scores,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_logits\u001b[39m\u001b[38;5;124m'\u001b[39m: item_logits,\n\u001b[1;32m     50\u001b[0m }\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Compile the Stan model\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m sm \u001b[38;5;241m=\u001b[39m \u001b[43mpystan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStanModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstan_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Fit the model with the current item logits\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama_index/lib/python3.9/site-packages/pystan/model.py:230\u001b[0m, in \u001b[0;36mStanModel.__init__\u001b[0;34m(self, file, charset, model_name, model_code, stanc_ret, include_paths, boost_lib, eigen_lib, verbose, obfuscate_model_name, extra_compile_args, allow_undefined, include_dirs, includes)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, charset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manon_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m              model_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stanc_ret\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, include_paths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    225\u001b[0m              boost_lib\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eigen_lib\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m              obfuscate_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extra_compile_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    227\u001b[0m              allow_undefined\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, include_dirs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, includes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stanc_ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m         stanc_ret \u001b[38;5;241m=\u001b[39m \u001b[43mpystan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstanc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcharset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcharset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mmodel_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43minclude_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mobfuscate_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobfuscate_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mallow_undefined\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_undefined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stanc_ret, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstanc_ret must be an object returned by stanc.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama_index/lib/python3.9/site-packages/pystan/api.py:169\u001b[0m, in \u001b[0;36mstanc\u001b[0;34m(file, charset, model_code, model_name, include_paths, verbose, obfuscate_model_name, allow_undefined)\u001b[0m\n\u001b[1;32m    167\u001b[0m         msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    168\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse Stan model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Error message:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_name, msg)\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# SUCCESS_RC is 0\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully parsed Stan model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_name))\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to parse Stan model 'anon_model_ea35b30a6caf220bd69ab2b9f858089b'. Error message:\nSYNTAX ERROR, MESSAGE(S) FROM PARSER:\nNo matches for: \n\n  int(real)\n\nFunction int not found.\n error in 'unknown file name' at line 19, column 46\n  -------------------------------------------------\n    17:             int logits_int[num_items];\n    18:             for (j in 1:num_items) {\n    19:                 logits_int[j] = int(logits[j]);\n                                                     ^\n    20:             }\n  -------------------------------------------------\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _ in range(iterations):\n",
    "    \n",
    "    # Perform Rasch analysis using the current item logits\n",
    "    # (This can be done using specialized software or libraries)\n",
    "    person_estimates, updated_item_logits = analyze_data(item_logits, scores)\n",
    "    \n",
    "    # Check for convergence\n",
    "    if max(abs(updated_item_logits - item_logits)) <= threshold:\n",
    "        break\n",
    "    \n",
    "    # Update item logits for the next iteration\n",
    "    item_logits = updated_item_logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.13)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
