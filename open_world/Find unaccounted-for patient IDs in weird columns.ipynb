{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3626480e-7e39-44bd-9e6a-2a8d26565ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f09e164-f476-48f1-8744-d1e98397f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load libraries\n",
    "from FRVRS import (nu, fu, osp, re, listdir, walk, DataFrame, nan, concat, Series, display, csv)\n",
    "from pandas import get_dummies\n",
    "from re import split, search, sub, MULTILINE\n",
    "from scipy.stats import f_oneway, ttest_ind, kruskal, norm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d986cf-911f-4aba-b20c-b56597008845",
   "metadata": {},
   "source": [
    "\n",
    "# Find unaccounted-for patient IDs in weird columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee53393-3fd9-406f-9439-8f2acb819439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze the non-patients to see if there are typos of Jennifer's patients\n",
    "patients_set = set(fu.ow_patients_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b62db4e-7c3d-4cd4-996a-3bb108fe746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "rows_list = []\n",
    "for id_prefix in patients_set:\n",
    "    prefix_regex = re.compile(',' + id_prefix)\n",
    "    for dir_name in listdir(logs_path):\n",
    "        logs_folder = osp.join(logs_path, dir_name)\n",
    "        for sub_directory, directories_list, files_list in walk(logs_folder):\n",
    "            for file_name in files_list:\n",
    "                if file_name.endswith('.csv'):\n",
    "                    file_path = osp.join(sub_directory, file_name)\n",
    "                    with open(file_path, 'r') as f_input:\n",
    "                        for line_str in f_input:\n",
    "                            if prefix_regex.search(line_str):\n",
    "                                row_dict = {'id_prefix': id_prefix, 'file_path': file_path, 'line_str': line_str}\n",
    "                                nonroot_regex = re.compile(',' + id_prefix + ',')\n",
    "                                if nonroot_regex.search(line_str):\n",
    "                                    row_dict['is_nonroot'] = True\n",
    "                                else:\n",
    "                                    row_dict['is_nonroot'] = False\n",
    "                                root_regex = re.compile(',' + id_prefix + ' Root,')\n",
    "                                if root_regex.search(line_str):\n",
    "                                    row_dict['has_root_suffix'] = True\n",
    "                                else:\n",
    "                                    row_dict['has_root_suffix'] = False\n",
    "                                rows_list.append(row_dict)\n",
    "root_prefix_df = DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a874c077-3494-4711-bac5-9df52dca1235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@Jacob Audick @Kaitlyn Choy For the CSV logs in @Brian Pippin (TA3/CACI)'s Human_Sim_Metrics_Data_4-12-2024, for @Jennifer McVay (TA3/CACI)'s list of characters within each CSV (n the ITM BBAI Exploratory analysis email on March 25th), we have the following alternate spellings:\n",
      "\n",
      "\"Civilian 1 Female\": 17 instances\n",
      "\"Civilian 1 Female Root\": 259 instances\n",
      "\"Marine 1 Male\": 7 instances\n",
      "\"Marine 1 Male Root\": 674 instances\n",
      "\"Marine 2 Male\": 9 instances\n",
      "\"Marine 2 Male Root\": 391 instances\n",
      "\"Marine 3 Male\": 25 instances\n",
      "\"Marine 3 Male Root\": 522 instances\n",
      "\"Marine 4 Male\": 7 instances\n",
      "\"Marine 4 Male Root\": 791 instances\n",
      "\"Navy Soldier 1 Male\": 4 instances\n",
      "\"Navy Soldier 1 Male Root\": 483 instances\n",
      "\"Navy Soldier 2 Male\": 11 instances\n",
      "\"Navy Soldier 2 Male Root\": 467 instances\n",
      "\"Navy Soldier 3 Male\": 3 instances\n",
      "\"Navy Soldier 3 Male Root\": 480 instances\n",
      "\"Navy Soldier 4 Female\": 10 instances\n",
      "\"Navy Soldier 4 Female Root\": 2553 instances\n",
      "\"Open World Civilian 1 Male\": 11 instances\n",
      "\"Open World Civilian 1 Male Root\": 417 instances\n",
      "\"Open World Civilian 2 Female\": 2 instances\n",
      "\"Open World Civilian 2 Female Root\": 415 instances\n",
      "\"Open World Marine 1 Female\": 8 instances\n",
      "\"Open World Marine 1 Female Root\": 4506 instances\n",
      "\"Open World Marine 1 Male\": 9 instances\n",
      "\"Open World Marine 1 Male Root\": 429 instances\n",
      "\"Open World Marine 2 Female\": 3 instances\n",
      "\"Open World Marine 2 Female Root\": 429 instances\n",
      "\"Open World Marine 2 Male\": 16 instances\n",
      "\"Open World Marine 2 Male Root\": 385 instances\n",
      "\"Open World Marine 3 Male\": 5 instances\n",
      "\"Open World Marine 3 Male Root\": 205 instances\n",
      "\"Open World Marine 4 Male\": 3 instances\n",
      "\"Open World Marine 4 Male Root\": 266 instances\n",
      "\n",
      "Should we trust both the \"Root\" suffix and the non-root spelling as among the list of characters?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(\n",
    "    \"\\n@Jacob Audick @Kaitlyn Choy For the CSV logs in @Brian Pippin (TA3/CACI)'s Human_Sim_Metrics_Data_4-12-2024,\"\n",
    "    \" for @Jennifer McVay (TA3/CACI)'s list of characters within each CSV\"\n",
    "    \" (n the ITM BBAI Exploratory analysis email on March 25th), we have the following alternate spellings:\\n\"\n",
    ")\n",
    "for index_tuple, row_series in root_prefix_df.groupby(\n",
    "    ['id_prefix', 'has_root_suffix']\n",
    ").size().to_frame().rename(columns={0: 'line_count'}).iterrows():\n",
    "    id_prefix, has_root_suffix = index_tuple\n",
    "    line_count = row_series.line_count\n",
    "    if has_root_suffix:\n",
    "        print(f'\"{id_prefix} Root\": {line_count} instances')\n",
    "    else:\n",
    "        print(f'\"{id_prefix}\": {line_count} instances')\n",
    "print('\\nShould we trust both the \"Root\" suffix and the non-root spelling as among the list of characters?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85fb854-36e8-4c3b-9b1d-391589d0d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get all the Open World logs into one data frame\n",
      "(158663, 111)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024202</th>\n",
       "      <td>11231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024211</th>\n",
       "      <td>10888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024209</th>\n",
       "      <td>10503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024224</th>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024218</th>\n",
       "      <td>10261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                record_count\n",
       "participant_id              \n",
       "2024202                11231\n",
       "2024211                10888\n",
       "2024209                10503\n",
       "2024224                10365\n",
       "2024218                10261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>62716</th>\n",
       "      <th>77340</th>\n",
       "      <th>34596</th>\n",
       "      <th>48571</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>player_gaze_direction_of_gaze</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.4, 0.9, 0.4)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_location_location</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(-12.9, 1.5, 1.3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_scene_aborted</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_uuid</th>\n",
       "      <td>385032e9-9801-4dcf-a841-b3703a0d9acd</td>\n",
       "      <td>499179ba-3138-4bae-918e-ffc7fb943760</td>\n",
       "      <td>1995e7ef-ef02-4fc1-b1ab-f137dbf69d48</td>\n",
       "      <td>37a554ee-fc49-4730-819c-2d97727bb0b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_gaze_patient_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient V Root</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              62716  \\\n",
       "player_gaze_direction_of_gaze                                   NaN   \n",
       "player_location_location                                        NaN   \n",
       "is_scene_aborted                                              False   \n",
       "session_uuid                   385032e9-9801-4dcf-a841-b3703a0d9acd   \n",
       "player_gaze_patient_id                                          NaN   \n",
       "\n",
       "                                                              77340  \\\n",
       "player_gaze_direction_of_gaze                                   NaN   \n",
       "player_location_location                          (-12.9, 1.5, 1.3)   \n",
       "is_scene_aborted                                              False   \n",
       "session_uuid                   499179ba-3138-4bae-918e-ffc7fb943760   \n",
       "player_gaze_patient_id                                          NaN   \n",
       "\n",
       "                                                              34596  \\\n",
       "player_gaze_direction_of_gaze                       (0.4, 0.9, 0.4)   \n",
       "player_location_location                                        NaN   \n",
       "is_scene_aborted                                              False   \n",
       "session_uuid                   1995e7ef-ef02-4fc1-b1ab-f137dbf69d48   \n",
       "player_gaze_patient_id                               Patient V Root   \n",
       "\n",
       "                                                              48571  \n",
       "player_gaze_direction_of_gaze                                   NaN  \n",
       "player_location_location                                        NaN  \n",
       "is_scene_aborted                                              False  \n",
       "session_uuid                   37a554ee-fc49-4730-819c-2d97727bb0b7  \n",
       "player_gaze_patient_id                                          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# In the zip there are 51 folders, (51 JSON, 51 CSV).\n",
    "# All the files are named appropriated in the folder/CSV/json UUID_ParticipantID.\n",
    "# Some of the internal Participants IDs might be off because the moderator forgot to enter a Participant ID or didn't enter\n",
    "# the Participant ID correctly so we needed to figure out which participant it was.\n",
    "# So only utilize the UUID and Participant ID that is on the file name to identify and ignore the internal Participant IDs.\n",
    "print(\"\\nGet all the Open World logs into one data frame\")\n",
    "csv_stats_df = DataFrame([])\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "for dir_name in listdir(logs_path):\n",
    "    \n",
    "    # Add the CSVs to the data frame\n",
    "    folder_path = osp.join(logs_path, dir_name)\n",
    "    df = fu.concatonate_logs(logs_folder=folder_path, verbose=True)\n",
    "    \n",
    "    session_uuid, participant_id = dir_name.split('_')\n",
    "    df['session_uuid'] = session_uuid\n",
    "    df['participant_id'] = int(participant_id)\n",
    "    \n",
    "    # Remove numerically-named columns\n",
    "    columns_list = [x for x in df.columns if not search(r'\\d+', str(x))]\n",
    "    df = df[columns_list]\n",
    "    \n",
    "    # Convert 'TRUE' and 'FALSE' to boolean values\n",
    "    for cn in fu.boolean_columns_list:\n",
    "        df[cn] = df[cn].map({'TRUE': True, 'FALSE': False, 'True': True, 'False': False})\n",
    "    \n",
    "    # Convert the nulls into NaNs\n",
    "    for cn in df.columns: df[cn] = df[cn].replace(['null', 'nan'], nan)\n",
    "    \n",
    "    # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "    csv_stats_df = concat([csv_stats_df, df], axis='index')\n",
    "\n",
    "csv_stats_df = csv_stats_df.reset_index(drop=True).drop_duplicates()\n",
    "csv_stats_df['csv_file_name'] = csv_stats_df.csv_file_subpath.map(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "# Check for proper ingestion (duplicate file ingestion, et al)\n",
    "assert len(csv_stats_df.columns) > 4, \"Nothing ingested\"\n",
    "assert csv_stats_df.participant_id.nunique() == 26, f\"Participant count should be 26, it's {csv_stats_df.participant_id.nunique()} instead\"\n",
    "\n",
    "# Check that all the rows that have more than one unique value in the file_name column for each value in the session_uuid column\n",
    "mask_series = (csv_stats_df.groupby('session_uuid').csv_file_subpath.transform(Series.nunique) > 1)\n",
    "assert not mask_series.any(), \"You have duplicate files\"\n",
    "\n",
    "# Show what the datset looks like\n",
    "print(csv_stats_df.shape)\n",
    "display(csv_stats_df.groupby('participant_id').size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))\n",
    "display(csv_stats_df.sample(4).dropna(axis='columns', how='all').T.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ea4709-6d84-4614-8262-b0f0bbcb65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the patients lists\n",
    "patients_regex = re.compile(r',(' + '|'.join(patients_set) + r')\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf5d739-081e-4963-bbe1-9fd9a818b149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add all mentions of TA3 patients to its own CSV file\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "directories_list = listdir(logs_path)\n",
    "output_file_path = osp.join(fu.saves_folder, 'csv', 'desert_jungle_submarine_urban_patients.csv')\n",
    "with open(output_file_path, mode='w', encoding=nu.encoding_type) as f: print('', file=f)\n",
    "with open(output_file_path, mode='a', encoding=nu.encoding_type) as f_output:\n",
    "    for dir_name in directories_list:\n",
    "        folder_path = osp.join(logs_path, dir_name)\n",
    "        for sub_directory, directories_list, files_list in walk(folder_path):\n",
    "            \n",
    "            # Iterate over the files in the current subdirectory\n",
    "            for file_name in files_list:\n",
    "                \n",
    "                # If the file is a CSV file, merge it into the subdirectory data frame\n",
    "                if file_name.endswith('.csv'):\n",
    "                    \n",
    "                    # Construct the full path to the file\n",
    "                    file_path = osp.join(sub_directory, file_name)\n",
    "                    \n",
    "                    # Read CSV file\n",
    "                    with open(file_path, 'r') as f_input:\n",
    "                        for line_str in f_input:\n",
    "                            if patients_regex.search(line_str):\n",
    "                                print(line_str, end='', file=f_output)\n",
    "\n",
    "# Read CSV file using a CSV reader\n",
    "rows_list = []\n",
    "with open(osp.abspath(output_file_path), 'r', encoding=nu.encoding_type) as f:\n",
    "    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for values_list in reader:\n",
    "        rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "file_df = DataFrame(rows_list).dropna(axis='columns', how='all').dropna(axis='index', how='all')\n",
    "\n",
    "# Show the columns that have the patient's names in them\n",
    "patients_regex = re.compile(r'\\b(' + '|'.join(patients_set) + r')\\b')\n",
    "for column_name in range(19):\n",
    "    if any(map(lambda x: patients_regex.search(str(x)), file_df[column_name].tolist())):\n",
    "        print(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206d0b6d-e131-4674-84a7-6304311ae490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open World Marine 1 Female Root</th>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient V Root</th>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient U Root</th>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient X Root</th>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient U Root</th>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 record_count\n",
       "patient_id                                   \n",
       "Open World Marine 1 Female Root          2313\n",
       "Patient V Root                           2052\n",
       "Patient U Root                           1900\n",
       "Patient X Root                           1003\n",
       "patient U Root                            992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Modalize separate patient ID columns into one\n",
    "new_column_name = 'patient_id'\n",
    "patient_id_columns_list = sorted(set(fu.patient_id_columns_list).intersection(set(csv_stats_df.columns)))\n",
    "csv_stats_df = nu.modalize_columns(csv_stats_df, patient_id_columns_list, new_column_name)\n",
    "display(csv_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35b8296-c991-470e-b887-81e6758d613f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tool_applied_row_shape', 'tool_applied_patient_id', 'tool_applied_type', 'tool_applied_attachment_point', 'tool_applied_tool_location', 'tool_applied_data', 'tag_applied_patient_id', 'tag_applied_type']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the name of the row_dict.shape column\n",
    "[cn for cn in csv_stats_df.columns if 'applied' in cn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0094e9-dc18-4de0-b264-3f708eec95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAG_ACCESS', 'BAG_CLOSED', 'BUTTON_CLICKED', 'PLAYER_LOCATION', 'SESSION_END', 'SESSION_START', 'SP_O2_TAKEN', 'TAG_DISCARDED', 'TAG_SELECTED', 'TELEPORT', 'TOOL_DISCARDED', 'TOOL_HOVER', 'TOOL_SELECTED', 'TRIAGE_LEVEL_WALK_IF_CAN', 'TRIAGE_LEVEL_WAVED', 'TRIAGE_LEVEL_WAVE_IF_CAN', 'VOICE_CAPTURE', 'VOICE_COMMAND']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show all action types that make no mention of a patient and those that sometimes do\n",
    "mask_series = csv_stats_df.patient_id.isnull()\n",
    "action_types_list = sorted(csv_stats_df[mask_series].action_type.unique())\n",
    "print(action_types_list)\n",
    "for action_type in action_types_list:\n",
    "    mask_series = (csv_stats_df.action_type == action_type) & ~csv_stats_df.patient_id.isnull()\n",
    "    if mask_series.any():\n",
    "        print(action_type)\n",
    "        mask_series = (csv_stats_df.action_type == action_type) & csv_stats_df.patient_id.isnull()\n",
    "        df = csv_stats_df[mask_series]\n",
    "        print(\n",
    "            f'When you are applying a tool ({action_type}) of these types you are not recording a patient ID in the logs:'\n",
    "            f' {nu.conjunctify_nouns(sorted(df.tool_applied_type.unique()))}'\n",
    "        )\n",
    "        break\n",
    "        display(df.sample(min(df.shape[0], 4)).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9116bd4-94e3-4701-9300-b319ae6c916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add all mentions of each metrics type to its own CSV file\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "for metrics_type in fu.known_mcivr_metrics:\n",
    "    output_file_path = osp.join(fu.saves_folder, 'csv', f'{metrics_type}.csv')\n",
    "    with open(output_file_path, mode='w', encoding=nu.encoding_type) as f: print('', file=f)\n",
    "    for dir_name in listdir(logs_path):\n",
    "        folder_path = osp.join(logs_path, dir_name)\n",
    "        for sub_directory, directories_list, files_list in walk(folder_path):\n",
    "            \n",
    "            # Iterate over the files in the current subdirectory\n",
    "            for file_name in files_list:\n",
    "                \n",
    "                # If the file is a CSV file, merge it into the subdirectory data frame\n",
    "                if file_name.endswith('.csv'):\n",
    "                    \n",
    "                    # Construct the full path to the file\n",
    "                    file_path = osp.join(sub_directory, file_name)\n",
    "                    # if (metrics_type != 'BAG_ACCESS'): print(file_path)\n",
    "                    \n",
    "                    # Read CSV file\n",
    "                    with open(file_path, 'r') as f_input:\n",
    "                        for line_str in f_input:\n",
    "                            if re.search(f'^{metrics_type},', line_str):\n",
    "                                \n",
    "                                # Add all mentions of each metrics type to its own CSV file\n",
    "                                with open(output_file_path, mode='a', encoding=nu.encoding_type) as f_output:\n",
    "                                    print(line_str, end='', file=f_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5400813f-a2f8-47bb-bb70-8b291e65d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            df.loc[row_index, 'injury_record_patient_id'] = row_series[5] # patientId\n",
      "            df.loc[row_index, 'injury_treated_patient_id'] = row_series[5] # patientId\n",
      "            df.loc[row_index, 'patient_demoted_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'patient_engaged_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'breathing_checked_patient_id'] = row_series[5] # patientId\n",
      "            df.loc[row_index, 'patient_record_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'pulse_taken_patient_id'] = row_series[5] # patientId\n",
      "            df.loc[row_index, 'sp_o2_taken_patient_id'] = row_series[5] # patientId\n",
      "            df.loc[row_index, 'triage_level_walked_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'triage_level_walk_if_can_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'triage_level_waved_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'triage_level_wave_if_can_patient_id'] = row_series[6] # patientId\n",
      "            df.loc[row_index, 'tag_applied_patient_id'] = row_series[4] # patientId\n",
      "            df.loc[row_index, 'tool_applied_patient_id'] = row_series[4] # patientId\n",
      "            df.loc[row_index, 'player_gaze_patient_id'] = row_series[5] # patientId\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show the columns that have the patient's names in them for each metrics type\n",
    "print()\n",
    "for metrics_type in fu.known_mcivr_metrics:\n",
    "    \n",
    "    # Read CSV file using a CSV reader\n",
    "    output_file_path = osp.join(fu.saves_folder, 'csv', f'{metrics_type}.csv')\n",
    "    if osp.isfile(output_file_path):\n",
    "        rows_list = []\n",
    "        with open(osp.abspath(output_file_path), 'r', encoding=nu.encoding_type) as f:\n",
    "            reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "            for values_list in reader:\n",
    "                rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "        file_df = DataFrame(rows_list).dropna(axis='columns', how='all').dropna(axis='index', how='all')\n",
    "        # print(metrics_type, file_df.shape)\n",
    "        \n",
    "        # Show the columns that have the patient's names in them\n",
    "        patients_regex = re.compile(r'\\b(' + '|'.join(patients_set) + r')\\b')\n",
    "        column_names_list = []\n",
    "        for column_name in range(19):\n",
    "            if (column_name in file_df.columns) and any(map(lambda x: patients_regex.search(str(x)), file_df[column_name].tolist())):\n",
    "                column_names_list.append(column_name-1)\n",
    "        if column_names_list:\n",
    "            # print(metrics_type, column_names_list)\n",
    "            print(f\"            df.loc[row_index, '{metrics_type.lower()}_patient_id'] = row_series{column_names_list} # patientId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6a979cc-75aa-48a2-8101-dd82a4e768f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simplify the contingencies in TOOL_APPLIED\n",
    "metrics_type = 'TOOL_APPLIED'\n",
    "output_file_path = osp.join(fu.saves_folder, 'csv', f'{metrics_type}.csv')\n",
    "if osp.isfile(output_file_path):\n",
    "    rows_list = []\n",
    "    with open(osp.abspath(output_file_path), 'r', encoding=nu.encoding_type) as f:\n",
    "        reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        for values_list in reader:\n",
    "            rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "        file_df = DataFrame(rows_list).dropna(axis='columns', how='all').dropna(axis='index', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ebf0e5-f017-47a9-9905-52819716059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Okay, as far as TOOL_APPLIED goes, I'm assuming that:\n",
      "These are all examples of patientId: Adept Shooter Root, Adept Victim Root, Civilian 1, Civilian 1 Female, Civilian 1 Female Root, Civilian 1 Root, Desert Level Core, Local Soldier 1, Local Soldier 1 Root, Marine 1 Male, Marine 1 Male Root, Marine 2 Male, Marine 2 Male Root, Marine 3 Male, Marine 3 Male Root, Marine 4 Male, Marine 4 Male Root, Navy Soldier 1 Male, Navy Soldier 1 Male Root, Navy Soldier 2 Male, Navy Soldier 2 Male Root, Navy Soldier 3 Male, Navy Soldier 3 Male Root, Navy Soldier 4 Female, Navy Soldier 4 Female Root, Open World Civilian 1 Male, Open World Civilian 1 Male Root, Open World Civilian 2 Female, Open World Civilian 2 Female Root, Open World Marine 1 Female, Open World Marine 1 Female Root, Open World Marine 1 Male, Open World Marine 1 Male Root, Open World Marine 2 Female, Open World Marine 2 Female Root, Open World Marine 2 Male, Open World Marine 2 Male Root, Open World Marine 3 Male, Open World Marine 3 Male Root, Open World Marine 4 Male, Open World Marine 4 Male Root, Patient U, Patient U Root, Patient V, Patient V Root, Patient W, Patient W Root, Patient X, Patient X Root, Player, Simulation Root, Submarine Level Core, US Soldier 1, US Soldier 1 Root, Urban Level Core, bystander Root, electrician, electrician Root, patient U, patient U Root, patient V Root, patient W, patient W Root, patient X, and patient X Root\n",
      "These are all examples of type: Burn_Dressing, Gauze_Dressing, Gauze_Pack, IV_Blood, IV_Saline, Naso, Needle, Pain_Meds, Pulse_Oximeter, SAM_Splint, and Tourniquet\n",
      "These are all examples of attachmentPoint: Bag_Body, BodyCollider, Burn Dressing Icon, Gauze_Icon, Ground, House_09(Clone), IV Blood Bag Icon, Jaw, LChest_Breathe1, LeftArm, LeftForeArm, LeftLeg, LeftToeBase, LeftUpLeg, Orange_tag(Clone), PulseOximeterAttachPoint, RChest_Breathe1, Red_tag(Clone), Red_tag_SALT_TCCC, RightArm, RightForeArm, RightLeg, RightToeBase, RightUpLeg, SM_Stairs2_LOD1, SM_Stairs2_LOD3, Sidewalk_01 (63), Splint_Icon, Tourniquet_Icon, TriagKitRoot_Shaped, hemostatic gauze and packet, pool(Clone), skinCollider_BodyCollideLOD, skinCollider_BodyGar_LOD, skinCollider_BodyLOD, skinCollider_BodyNudeLOD, skinCollider_Body_LOD, trumpet_full, and tubeGuide\n",
      "These are all examples of toolLocation: Burn_Dressing(Clone), Gauze_Dressing(Clone), Gauze_Pack(Clone), IV_Blood_Bag(Clone), IV_Saline_Bag(Clone), LeftForeArm, LeftToeBase, Pulse_Oximeter, RightForeArm, RightToeBase, cath_needle, null, tor_ring (1), and trumpet_container\n",
      "These are all examples of data: Burn_Dressing(Clone), Gauze_Dressing(Clone), Gauze_Pack(Clone), LeftArm, LeftForeArm, Naso_Airway(Clone), PainMedsAttachPoint, Pulse_Oximeter(Clone), RightArm, RightForeArm, SplintAttachPointLL, SplintAttachPointLS, SplintAttachPointRL, SplintAttachPointRS, left_chest, null, right_chest, and tourniquet(Clone)\n",
      "Is this correct?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write out a statement you can show to the developers\n",
    "print(f\"\"\"\\nOkay, as far as {metrics_type} goes, I'm assuming that:\"\"\")\n",
    "for i, list_name in zip(range(5, 13), ['patientId', 'type', 'attachmentPoint', 'toolLocation', 'data']):\n",
    "    parts_list = re.split('([A-Z]+)', list_name, 0)\n",
    "    if len(parts_list) > 1:\n",
    "        column_suffix = parts_list[0] + '_' + ''.join(parts_list[1:]).lower()\n",
    "    else:\n",
    "        column_suffix = parts_list[0]\n",
    "    mask_series = ~file_df[i].isnull()\n",
    "    list_str = nu.conjunctify_nouns(sorted([str(x).replace(' (UnityEngine.GameObject)', '') for x in file_df[mask_series][i].unique()]))\n",
    "    print(f'These are all examples of {list_name}: {list_str}')\n",
    "    # print(f\"            df.loc[row_index, 'tool_applied_{column_suffix}'] = row_series[{i-1}] # {list_name}\")\n",
    "print('Is this correct?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99703734-c0e6-49a1-90c7-e7e05a3d1dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
