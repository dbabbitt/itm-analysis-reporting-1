{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1341223-5c53-4423-9118-0a502cd2b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up notebook\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join('..', 'py') not in sys.path): sys.path.insert(1, osp.join('..', 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df1a687-f72f-4765-b68d-fe154761a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load libraries\n",
    "from FRVRS import (nu, fu, display, osp, listdir, DataFrame, Index, concat, re)\n",
    "from datetime import date, timedelta\n",
    "from pandas import get_dummies\n",
    "from re import split, search, sub, MULTILINE\n",
    "from scipy.stats import f_oneway, ttest_ind, kruskal, norm\n",
    "import itertools\n",
    "from matplotlib import colors as colors, pyplot as plt\n",
    "import os\n",
    "\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163ee110-4921-474e-884b-907bd36007c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pickle exists for 20240521truncated_csv_stats_df - attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/20240521truncated_csv_stats_df.csv.\n",
      "(158663, 117)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    **{'verbose': True, '20240521truncated_csv_stats_df': ''}\n",
    ")\n",
    "csv_stats_df = data_frames_dict['20240521truncated_csv_stats_df'].copy()\n",
    "print(csv_stats_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b52b98-b35b-4664-91e2-ddafbbab4885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_layout</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Desert</th>\n",
       "      <td>40678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle</th>\n",
       "      <td>25582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submarine</th>\n",
       "      <td>50198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urban</th>\n",
       "      <td>42150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  record_count\n",
       "encounter_layout              \n",
       "Desert                   40678\n",
       "Jungle                   25582\n",
       "Submarine                50198\n",
       "Urban                    42150\n",
       "NaN                         55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add the sim environment column\n",
    "new_column_name = 'encounter_layout'\n",
    "encounter_layouts_list = ['Desert', 'Jungle', 'Submarine', 'Urban']\n",
    "for (session_uuid, scene_id), scene_df in csv_stats_df.groupby(fu.scene_groupby_columns):\n",
    "    mask_series = ~scene_df.patient_id.isnull()\n",
    "    spl = sorted(scene_df[mask_series].patient_id.unique())\n",
    "    for env_str in encounter_layouts_list:\n",
    "\n",
    "        # Assume no Unity suffix\n",
    "        patients_list = eval(f'fu.{env_str.lower()}_patients_list')\n",
    "        if all(map(lambda p: p in spl, patients_list)):\n",
    "            \n",
    "            csv_stats_df.loc[scene_df.index, new_column_name] = env_str\n",
    "display(csv_stats_df.groupby([new_column_name], dropna=False).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b32534-c3f8-4eab-8005-c1956b16faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_stats_df\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df_name in dir():\n",
    "    if df_name.endswith('_df'):\n",
    "        if 'encounter_layout' in eval(f'{df_name}.columns'):\n",
    "            print(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d70e0756-7380-41d3-9b6a-7105e041051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35520    Desert\n",
       "35521    Desert\n",
       "35522    Desert\n",
       "35523    Desert\n",
       "35524    Desert\n",
       "          ...  \n",
       "35592    Desert\n",
       "35593    Desert\n",
       "35594    Desert\n",
       "35595    Desert\n",
       "35597    Desert\n",
       "Name: encounter_layout, Length: 72, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask_series = ~session_df.encounter_layout.isnull()\n",
    "session_df[mask_series].encounter_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22111a58-3cd8-4dcd-bd13-5abd9148785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8.131, 0, -28.682)\n",
      "[(0.3, 0.0, -7.3)]\n",
      "(0.3, 0.0, -7.3)\n",
      "22.770913134962328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(base_point)\n",
    "print(neighbors_list)\n",
    "print(nearest_neighbor)\n",
    "print(euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892da058-dfb3-40aa-93dd-afd7a92dfc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_tick</th>\n",
       "      <th>location_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>encounter_layout</th>\n",
       "      <th>session_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35563</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1369817</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35564</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1370395</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35565</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1372069</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35566</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1377061</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35567</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1378242</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35568</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1382824</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35582</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1443694</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35583</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1451294</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35585</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1461607</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>TELEPORT</td>\n",
       "      <td>1497960</td>\n",
       "      <td>(0.3, 0.0, -7.3)</td>\n",
       "      <td>2024201</td>\n",
       "      <td>Desert</td>\n",
       "      <td>23081f6e-875e-44f5-8bd0-edc3905f5c2c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      action_type  action_tick       location_id  participant_id  \\\n",
       "35563    TELEPORT      1369817  (0.3, 0.0, -7.3)         2024201   \n",
       "35564    TELEPORT      1370395  (0.3, 0.0, -7.3)         2024201   \n",
       "35565    TELEPORT      1372069  (0.3, 0.0, -7.3)         2024201   \n",
       "35566    TELEPORT      1377061  (0.3, 0.0, -7.3)         2024201   \n",
       "35567    TELEPORT      1378242  (0.3, 0.0, -7.3)         2024201   \n",
       "35568    TELEPORT      1382824  (0.3, 0.0, -7.3)         2024201   \n",
       "35582    TELEPORT      1443694  (0.3, 0.0, -7.3)         2024201   \n",
       "35583    TELEPORT      1451294  (0.3, 0.0, -7.3)         2024201   \n",
       "35585    TELEPORT      1461607  (0.3, 0.0, -7.3)         2024201   \n",
       "35597    TELEPORT      1497960  (0.3, 0.0, -7.3)         2024201   \n",
       "\n",
       "      encounter_layout                          session_uuid  \n",
       "35563           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35564           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35565           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35566           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35567           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35568           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35582           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35583           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35585           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  \n",
       "35597           Desert  23081f6e-875e-44f5-8bd0-edc3905f5c2c  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "columns_list = ['action_type', 'action_tick', 'location_id', 'participant_id', 'encounter_layout', 'session_uuid']\n",
    "session_df[mask_series][columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b42f3d-cea5-4fe7-80c8-733d465fd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all the Open World JSON Stats into one data frame\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "directories_list = listdir(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e58513-1c14-4ae9-9f82-bb766e912bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_stats_df = DataFrame([])\n",
    "for dir_name in directories_list:\n",
    "    \n",
    "    # Add the JSONs to the data frame\n",
    "    folder_path = osp.join(logs_path, dir_name)\n",
    "    \n",
    "    # Iterate over the files in the current subdirectory\n",
    "    for file_name in listdir(folder_path):\n",
    "        \n",
    "        # If the file is a JSON file\n",
    "        if file_name.endswith('.json'):\n",
    "            \n",
    "            # Create a data frame from the flattened dictionary\n",
    "            json_path = osp.join(folder_path, file_name)\n",
    "            with open(json_path, 'r') as f: file_json = json.load(f)\n",
    "            row_dict = {\n",
    "                'json_file_subpath': folder_path,\n",
    "                'json_file_name': file_name\n",
    "            }\n",
    "            flattened_json_dict = nu.get_flattened_dictionary(file_json, row_dict=row_dict, key_prefix='')\n",
    "            \n",
    "            # You've got to clean the Session IDs\n",
    "            session_uuid, participant_id = dir_name.split('_')\n",
    "            flattened_json_dict['session_uuid'] = session_uuid\n",
    "            flattened_json_dict['participant_id'] = int(participant_id)\n",
    "            df = DataFrame(flattened_json_dict, index=Index([0]))\n",
    "            \n",
    "            # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "            json_stats_df = concat([json_stats_df, df], axis='index')\n",
    "            \n",
    "json_stats_df = json_stats_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6d72a-6e96-4635-be46-099740aec1ad",
   "metadata": {},
   "source": [
    "\n",
    "### Drop boring columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6c750-1e92-4440-8108-79d91eea964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for proper ingestion (duplicate file ingestion, et al)\n",
    "assert len(json_stats_df.columns) > 4, \"Nothing ingested\"\n",
    "assert json_stats_df.participant_id.nunique() == 26, f\"Participant count should be 26, it's {json_stats_df.participant_id.nunique()} instead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4abc9-e6a2-49f5-90d5-c1a71a3d96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the json stats dataset\n",
    "nu.save_data_frames(**{f'{today.year}{today.month:02d}{today.day:02d}json_stats_df': json_stats_df}, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df46ce-ba21-49fd-bdf0-2d1c56fd71c7",
   "metadata": {},
   "source": [
    "\n",
    "### Get the nearest neighbor location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315660a3-e9ea-4e64-9924-cc19bbf4afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_action_tick_by_position(csv_stats_df, json_stats_df, participant_id, session_uuid, include_y=False):\n",
    "    on_columns = ['participant_id', 'session_uuid']\n",
    "    \n",
    "    # Get the location (CSV) mask\n",
    "    location_columns = on_columns + ['player_location_location']\n",
    "    assert set(location_columns).issubset(\n",
    "        set(csv_stats_df.columns)\n",
    "    ), f\"csv_stats_df is missing these location columns: {set(location_columns).difference(set(csv_stats_df.columns))}\"\n",
    "    location_mask_series = ~csv_stats_df.player_location_location.isnull()\n",
    "    assert location_mask_series.any(), f\"You don't have any player location data in csv_stats_df\"\n",
    "    location_session_mask = (csv_stats_df.participant_id == participant_id) & (csv_stats_df.session_uuid == session_uuid)\n",
    "    assert location_session_mask.any(), f\"You don't have any CSV data for participant #{participant_id} session #{session_uuid}\"\n",
    "    location_mask_series &= location_session_mask\n",
    "    assert location_mask_series.any(), f\"You don't have any player location data for participant #{participant_id} session #{session_uuid}\"\n",
    "    \n",
    "    # Get the position (JSON) mask\n",
    "    position_prefix_str = 'configData_playerData_startPosition_'\n",
    "    if include_y:\n",
    "        xyz_list = ['x', 'y', 'z']\n",
    "    else:\n",
    "        xyz_list = ['x', 'z']\n",
    "    position_columns = on_columns + [f'{position_prefix_str}{d}' for d in xyz_list]\n",
    "    assert set(position_columns).issubset(\n",
    "        set(json_stats_df.columns)\n",
    "    ), f\"json_stats_df is missing these columns: {set(position_columns).difference(set(json_stats_df.columns))}\"\n",
    "    position_session_mask = (json_stats_df.participant_id == participant_id) & (json_stats_df.session_uuid == session_uuid)\n",
    "    assert position_session_mask.any(), f\"You don't have any JSON data for participant #{participant_id} session #{session_uuid}\"\n",
    "    \n",
    "    # Get the base point (JSON)\n",
    "    mask_series = False\n",
    "    mask_series |= json_stats_df.configData_narrative_narrativeSections11_teleportPointsToActivate.isin(['Freeform'])\n",
    "    mask_series |= json_stats_df.configData_narrative_narrativeSections12_teleportPointsToActivate.isin(['Freeform'])\n",
    "    mask_series |= json_stats_df.configData_narrative_narrativeSections13_teleportPointsToActivate.isin(['Freeform'])\n",
    "    df = json_stats_df[position_session_mask]\n",
    "    position_x = df[mask_series][f'{position_prefix_str}x'].squeeze()\n",
    "    if include_y:\n",
    "        position_y = df[mask_series][f'{position_prefix_str}y'].squeeze()\n",
    "    position_z = df[mask_series][f'{position_prefix_str}z'].squeeze()\n",
    "    if include_y:\n",
    "        base_point = (position_x, position_y, position_z)\n",
    "    else:\n",
    "        base_point = (position_x, position_z)\n",
    "    \n",
    "    # Create the left side of the merge\n",
    "    csv_locations_df = csv_stats_df[location_mask_series][location_columns]\n",
    "    for i, d in enumerate(xyz_list):\n",
    "        csv_locations_df[f'location_{d}'] = csv_locations_df.player_location_location.map(lambda coord_str: eval(coord_str)[i])\n",
    "    csv_locations_df = csv_locations_df.drop(columns=['player_location_location']).drop_duplicates()\n",
    "    \n",
    "    # Get the right side of the merge\n",
    "    mask_series = ~json_stats_df[f'{position_prefix_str}x'].isnull()\n",
    "    if include_y:\n",
    "        mask_series &= ~json_stats_df[f'{position_prefix_str}y'].isnull()\n",
    "    mask_series &= ~json_stats_df[f'{position_prefix_str}z'].isnull()\n",
    "    assert set(position_columns).issubset(\n",
    "        set(json_stats_df.columns)\n",
    "    ), f\"You're missing {set(position_columns).intersection(set(json_stats_df.columns))} as position columns\"\n",
    "    prefix_str = 'configData_playerData_startP'\n",
    "    json_positions_df = json_stats_df[mask_series][position_columns].rename(\n",
    "        columns={cn: cn.replace(prefix_str, 'p') for cn in position_columns if cn.startswith(prefix_str)}\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    # Merge the two coordinate datasets\n",
    "    on_columns = sorted(set(csv_locations_df.columns).intersection(set(json_positions_df.columns)))\n",
    "    print(csv_locations_df.shape)\n",
    "    print(json_positions_df.shape)\n",
    "    merge_df = csv_locations_df.merge(json_positions_df, on=on_columns, how='inner').drop_duplicates()\n",
    "    print(merge_df.shape)\n",
    "    \n",
    "    # Get the neighbors list\n",
    "    neighbors_list = [(x, y, z) for (x, y, z), _ in csv_locations_df.groupby(['location_x', 'location_y', 'location_z'])]\n",
    "    nearest_neighbor = nu.get_nearest_neighbor(base_point, neighbors_list)\n",
    "    euclidean_distance = nu.get_euclidean_distance(base_point, nearest_neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a790c6db-b30e-42e6-9e4a-2a72fa1c0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_json_df = DataFrame([])\n",
    "folder_path = osp.join(fu.data_folder, 'json')\n",
    "\n",
    "# Iterate over the files in the current subdirectory\n",
    "for file_name in listdir(folder_path):\n",
    "    \n",
    "    # If the file is a JSON file\n",
    "    if file_name.endswith('.json'):\n",
    "        \n",
    "        # Create a data frame from the flattened dictionary\n",
    "        json_path = osp.join(folder_path, file_name)\n",
    "        with open(json_path, 'r') as f: file_json = json.load(f)\n",
    "        row_dict = {\n",
    "            'json_file_name': file_name\n",
    "        }\n",
    "        flattened_json_dict = nu.get_flattened_dictionary(file_json, row_dict=row_dict, key_prefix='')\n",
    "        df = DataFrame(flattened_json_dict, index=Index([0]))\n",
    "        \n",
    "        # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "        eval_json_df = concat([eval_json_df, df], axis='index')\n",
    "        \n",
    "eval_json_df = eval_json_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5dc53-d0f1-4125-baf2-e893c94673ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_json_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9425a-ca98-4478-8e28-3f2d13195d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the teleport columns\n",
    "mask_series = eval_json_df.columns.map(lambda cn: '_playerTeleportation_teleportPosition_' in cn)\n",
    "teleport_columns = eval_json_df.columns[mask_series]\n",
    "if len(teleport_columns) > 2:\n",
    "    for column_name in sorted(teleport_columns):\n",
    "        print(column_name)\n",
    "elif len(teleport_columns):\n",
    "    display(eval_json_df[teleport_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43269b87-87fb-4f03-a530-87329b5f661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the teleport columns\n",
    "mask_series = eval_json_df.columns.map(lambda cn: 'teleportPointsToActivate' in cn)\n",
    "teleport_columns = eval_json_df.columns[mask_series]\n",
    "if len(teleport_columns) > 2:\n",
    "    for column_name in sorted(teleport_columns):\n",
    "        print(column_name)\n",
    "elif len(teleport_columns):\n",
    "    display(eval_json_df[teleport_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b60296-110f-4b1b-bbcf-261065fea505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all the teleport point names\n",
    "for i in range(14):\n",
    "    column_name = f'narrative_narrativeSections{i:02d}_teleportPointsToActivate'\n",
    "    if column_name in eval_json_df:\n",
    "        mask_series = ~eval_json_df[column_name].isnull()\n",
    "        print( column_name, sorted(eval_json_df[mask_series][column_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344089d8-edea-4cf9-94dc-dfd59cfb7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for (participant_id, session_uuid), session_df in csv_stats_df.groupby(['participant_id', 'session_uuid']):\n",
    "    mask_series = (session_df.action_type == 'TELEPORT') & ~session_df.location_id.isnull()\n",
    "    neighbors_list = [eval(location_id) for location_id in session_df[mask_series].location_id]\n",
    "    nearest_neighbor = nu.get_nearest_neighbor(base_point, neighbors_list)\n",
    "    euclidean_distance = nu.get_euclidean_distance(base_point, nearest_neighbor)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473bc55-8abf-4d72-8d4d-dd9f0f7da01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b308fdd-abc2-488a-b0e5-28e9fc727947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = session_df.location_id.isin([str(nearest_neighbor)])\n",
    "df = session_df[mask_series]\n",
    "print(sorted(df.action_tick.unique()))\n",
    "print(sorted(df.action_type.unique()))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b475a-c007-42b6-bf28-27650fd8d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Submarine: (0.02, 0, -13.5)\n",
    "# Urban: (13.126, 0, 21.61)\n",
    "# Jungle: (0.7, 0, 5.45)\n",
    "# Desert: (8.131, 0, -28.682)\n",
    "activate_columns = eval_json_df.columns[eval_json_df.columns.map(\n",
    "    lambda cn: bool(search(r'narrative_narrativeSections\\d+_teleportPointsToActivate', cn))\n",
    ")]\n",
    "mask_series = False\n",
    "for cn in activate_columns:\n",
    "    mask_series |= eval_json_df[cn].isin(['Freeform'])\n",
    "teleport_columns = eval_json_df.columns[eval_json_df.columns.map(\n",
    "    lambda cn: bool(search(r'narrative_narrativeSections\\d+_playerTeleportation_teleportPosition_(x|y|z)', cn))\n",
    ")]\n",
    "columns_list = sorted(eval_json_df[mask_series][teleport_columns].dropna(axis='columns', how='all').columns)\n",
    "description_columns = [cn for cn in sorted(eval_json_df.columns[eval_json_df.columns.map(\n",
    "    lambda cn: bool(search(r'narrative_narrativeSections\\d+_sectionDescription', cn))\n",
    ")]) if cn.replace('_sectionDescription', '_playerTeleportation_teleportPosition_x') in columns_list]\n",
    "activate_columns = [cn for cn in sorted(eval_json_df.columns[eval_json_df.columns.map(\n",
    "    lambda cn: bool(search(r'narrative_narrativeSections\\d+_teleportPointsToActivate', cn))\n",
    ")]) if cn.replace('_teleportPointsToActivate', '_playerTeleportation_teleportPosition_x') in columns_list]\n",
    "columns_list = sorted(columns_list + description_columns + activate_columns) + ['json_file_name']\n",
    "eval_json_df[mask_series][columns_list].dropna(axis='index', how='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33038e-994c-4fd6-867c-540266f7421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_json_df[mask_series].narrative_narrativeSections14_sectionDescription.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb17f3-e4bc-4ad5-a9d0-3a0921208df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all the teleport point names\n",
    "for i in range(14):\n",
    "    column_name = f'configData_narrative_narrativeSections{i:02d}_teleportPointsToActivate'\n",
    "    if column_name in json_stats_df:\n",
    "        mask_series = ~json_stats_df[column_name].isnull()\n",
    "        print( column_name, sorted(json_stats_df[mask_series][column_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775e6c0-d4eb-470d-8418-2be06e9e8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get list of all start position x, y, and z coordinates\n",
    "prefix_str = 'configData_playerData_startPosition_'\n",
    "print(f\"\\nThese are the values I can see for {' '.join(prefix_str.split('_')).strip()}:\")\n",
    "xyz_list = ['x', 'y', 'z']\n",
    "for cn in [f'{prefix_str}{dim}' for dim in xyz_list]:\n",
    "    position_mask_series = ~json_stats_df[cn].isnull()\n",
    "    print(cn.split('_')[-1], set(json_stats_df[position_mask_series][cn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26015461-564d-4542-b6dc-5c3f51165b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['configData_teleportPointOverride']\n",
    "display(json_stats_df[columns_list].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d7dd4-be87-414c-97c8-aaad9d9f4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the narrativeConfig columns\n",
    "mask_series = json_stats_df.columns.map(lambda cn: 'narrative' in cn)\n",
    "config_columns = json_stats_df.columns[mask_series]\n",
    "if len(config_columns) > 2:\n",
    "    for column_name in sorted(config_columns):\n",
    "        print(column_name)\n",
    "elif len(config_columns):\n",
    "    display(json_stats_df[config_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436399d8-ee3e-4190-9085-36b06439eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get columns that contain an x or z coordinate\n",
    "xyz_list = ['x', 'y', 'z']\n",
    "mask_series = json_stats_df.columns.map(lambda cn: any(map(lambda dim: cn.endswith(f'_{dim}'), xyz_list)))\n",
    "xyz_columns = json_stats_df.columns[mask_series]\n",
    "# print(xyz_columns)\n",
    "location_regex = re.compile(r'-?\\d+\\.\\d*')\n",
    "location_columns = sorted(nu.get_regexed_columns(json_stats_df[xyz_columns], search_regex=location_regex))\n",
    "if len(location_columns) > 2:\n",
    "    for column_name in sorted(location_columns):\n",
    "        print(column_name)\n",
    "elif len(location_columns):\n",
    "    display(json_stats_df[location_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0308a-5574-4853-ba34-bebb7165918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "location_mask_series = ~csv_stats_df.player_location_location.isnull()\n",
    "location_columns = on_columns + ['player_location_location']\n",
    "assert set(location_columns).issubset(set(csv_stats_df.columns)), \"You've got the wrong location columns\"\n",
    "left_df = csv_stats_df[location_mask_series][location_columns]\n",
    "for i, d in enumerate(xyz_list):\n",
    "    left_df[f'location_{d}'] = left_df.player_location_location.map(lambda coord_str: eval(coord_str)[i])\n",
    "left_df = left_df.drop(columns=['player_location_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3922ee-75a0-458f-ade0-b3687da15011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "right_gb = right_df.groupby(on_columns)\n",
    "left_gb = left_df.groupby(on_columns)\n",
    "tuples_list = sorted(set(right_gb.groups.keys()).intersection(set(left_gb.groups.keys())))\n",
    "location_groupby_columns = [f'location_{d}' for d in xyz_list]\n",
    "rows_list = []\n",
    "for key_tuple in tuples_list:\n",
    "    position_mask_series = (right_df.participant_id == key_tuple[0]) & (right_df.session_uuid == key_tuple[1])\n",
    "    position_x = right_df[position_mask_series].position_x.squeeze()\n",
    "    position_y = right_df[position_mask_series].position_y.squeeze()\n",
    "    position_z = right_df[position_mask_series].position_z.squeeze()\n",
    "    # display(right_df[position_mask_series].drop_duplicates())\n",
    "    base_point = (position_x, position_y, position_z)\n",
    "    \n",
    "    location_mask_series = (left_df.participant_id == key_tuple[0]) & (left_df.session_uuid == key_tuple[1])\n",
    "    neighbors_list = [(x, y, z) for (x, y, z), _ in left_df[location_mask_series].groupby(location_groupby_columns)]\n",
    "    nearest_neighbor = nu.get_nearest_neighbor(base_point, neighbors_list)\n",
    "    euclidean_distance = nu.get_euclidean_distance(base_point, nearest_neighbor)\n",
    "    row_dict = {\n",
    "        'base_point': base_point,\n",
    "        'nearest_neighbor': nearest_neighbor,\n",
    "        'euclidean_distance': euclidean_distance,\n",
    "    }\n",
    "    base_point = (position_x, position_z)\n",
    "    neighbors_list = [(x, z) for (x, y, z), _ in left_df[location_mask_series].groupby(location_groupby_columns)]\n",
    "    nearest_neighbor = nu.get_nearest_neighbor(base_point, neighbors_list)\n",
    "    euclidean_distance = nu.get_euclidean_distance(base_point, nearest_neighbor)\n",
    "    row_dict['euclidean_distance_xz'] = euclidean_distance\n",
    "    rows_list.append(row_dict)\n",
    "euclidean_distance_df = DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e6692-8bf0-4981-ab19-8fb68910a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [cn for cn in df.columns if 'position' in cn.lower()]\n",
    "mask_series = (df.configData_narrative_narrativeSections00_sectionDescription == 'Initialization')\n",
    "# df.configData_scene.unique() == ['sim-urban-sanitized', 'sim-desert', 'sim-jungle']\n",
    "df = df[mask_series].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b60be-fa98-49dd-af29-1c2d39e48bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the standard deviation for each column\n",
    "std_dev = df.std()\n",
    "\n",
    "# Get the indices of columns with zero variance\n",
    "zero_variance_cols = std_dev[std_dev == 0].index\n",
    "\n",
    "# Remove columns with zero variance\n",
    "column_count = df.shape[1]\n",
    "df.drop(columns=zero_variance_cols, inplace=True)\n",
    "print(f\"Dropped {int(column_count - df.shape[1])} JSON columns with zero variance\")\n",
    "\n",
    "# Assess the number of unique values (excluding NaNs) in each column\n",
    "unique_values = df.nunique(dropna=True)\n",
    "\n",
    "# Isolate the indices of columns with fewer than two unique values\n",
    "few_unique_cols = unique_values[unique_values < 2].index\n",
    "\n",
    "# Remove columns with fewer than two unique values\n",
    "column_count = df.shape[1]\n",
    "df.drop(columns=few_unique_cols, inplace=True)\n",
    "print(f\"Dropped {int(column_count - df.shape[1])} JSON columns with fewer than two unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c21739-96ac-4520-a2cb-0dc269dfe332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468a729-233e-4987-b508-b5ca7cd71bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "free_regex = re.compile('free', re.IGNORECASE)\n",
    "free_columns = sorted(nu.get_regexed_columns(json_stats_df, search_regex=free_regex))\n",
    "if len(free_columns) > 2:\n",
    "    for column_name in sorted(free_columns):\n",
    "        print(column_name)\n",
    "else:\n",
    "    display(json_stats_df[free_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621535c-bd1b-4850-ab92-9421eaa266e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adept_regex = re.compile('adept', re.IGNORECASE)\n",
    "adept_columns = sorted(nu.get_regexed_columns(json_stats_df, search_regex=adept_regex))\n",
    "if len(adept_columns) > 2:\n",
    "    for column_name in sorted(adept_columns):\n",
    "        print(column_name)\n",
    "else:\n",
    "    display(json_stats_df[adept_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03446ff9-e84d-4ee2-bb84-081bfcd85a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soartech_regex = re.compile('soartech', re.IGNORECASE)\n",
    "soartech_columns = sorted(nu.get_regexed_columns(json_stats_df, search_regex=soartech_regex))\n",
    "if len(soartech_columns) > 2:\n",
    "    for column_name in sorted(soartech_columns):\n",
    "        print(column_name)\n",
    "else:\n",
    "    display(json_stats_df[soartech_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155c18c-b283-4d3e-866f-cc0b1e98a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in sorted(set(adept_columns).intersection(set(soartech_columns))):\n",
    "    print(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df0cbe-0b3d-4a19-a263-214f0ecd4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(14):\n",
    "    column_name = f'configData_narrative_narrativeSections{i:02d}_sectionDescription'\n",
    "    if column_name in json_stats_df:\n",
    "        mask_series = ~json_stats_df[column_name].isnull()\n",
    "        print(column_name, sorted(json_stats_df[mask_series][column_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336269d-60a0-43f3-b941-68d8f3d30db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in sorted([cn for cn in json_stats_df.columns if any(map(lambda x: x in cn.lower(), ['start', 'intro', 'free', 'form']))]):\n",
    "    print(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b273c68-c035-45a1-8c79-e230c8aaba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in sorted([cn for cn in json_stats_df.columns if any(map(lambda x: x in cn.lower(), ['position']))]):\n",
    "    print(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae7ebc-c03c-42d7-8b43-57a8158faa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted(fu.location_id_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3cf81-55a3-437c-91fe-1f010ff31e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    verbose=True, metrics_evaluation_open_world_csv_stats_df=''\n",
    ")\n",
    "csv_stats_df = data_frames_dict['metrics_evaluation_open_world_csv_stats_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb60c669-b278-491a-a2ab-0931c8409442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_regex = re.compile(r'\\((?:-?\\d{1,2}\\.\\d, ){2}-?\\d{1,2}\\.\\d\\)')\n",
    "location_columns = sorted(nu.get_regexed_columns(csv_stats_df, search_regex=location_regex))\n",
    "if len(location_columns) > 2:\n",
    "    for column_name in sorted(location_columns):\n",
    "        print(column_name)\n",
    "elif len(location_columns):\n",
    "    display(json_stats_df[location_columns].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae1ee4-5a99-404f-b020-40af27405997",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns to merge the JSON stats dataset with the CSV stats on\n",
    "on_columns = sorted(set(csv_stats_df.columns).intersection(set(json_stats_df.columns)))\n",
    "print(on_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c36063-6b97-4f1f-ad4b-55994d50158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted(right_df.position_y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c697e2-f641-47dc-911e-d4d08fc31aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted(left_df.location_y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b54117-692b-40e9-b746-3b8b7642b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "# Create a box plot of all the columns\n",
    "columns_list = ['euclidean_distance_xz']\n",
    "sns.boxplot(euclidean_distance_df[columns_list], ax=ax)\n",
    "\n",
    "# Label the y-axis\n",
    "ax.set_ylabel('Nearest Horizontal Distance (Euclidean)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca2478-9c30-4f02-a765-00ce983a6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure and subplots\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "# Create a box plot of all the columns\n",
    "mask_series = (euclidean_distance_df.euclidean_distance_xz < 20)\n",
    "columns_list = ['euclidean_distance_xz']\n",
    "sns.boxplot(euclidean_distance_df[mask_series][columns_list], ax=ax)\n",
    "\n",
    "# Label the y-axis\n",
    "ax.set_ylabel('Nearest Horizontal Distance (Euclidean)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ab37c-b909-4a2f-9e20-165a4ccbb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "euclidean_distance_df.sort_values('euclidean_distance_xz', ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
