{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d497083-b501-4f84-bca7-d691eded680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the notebook\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ef3c3-7c16-47d8-8e6a-c06108b7625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import (nu, fu, warnings, read_excel, re, isna, nan, display, osp)\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe874fd-4fdb-47b2-aec5-0c09e07cc1e4",
   "metadata": {},
   "source": [
    "\n",
    "# Data Fixes for Metrics Evaluation Open World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8efbc6-3281-42a4-8c8e-4fe8062b7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_csv_stats_df='', metrics_evaluation_open_world_json_stats_df='',\n",
    "    metrics_evaluation_open_world_scene_stats_df=''\n",
    ")\n",
    "csv_stats_df = data_frames_dict['metrics_evaluation_open_world_csv_stats_df']\n",
    "json_stats_df = data_frames_dict['metrics_evaluation_open_world_json_stats_df']\n",
    "scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c962f3e-2332-4398-8815-331f2c3ea1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix the encounter_layout column based on the set of patients in the scene\n",
    "fu.add_encounter_layout_column_to_json_stats(csv_stats_df, json_stats_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df161d2-7b15-40a4-b0dd-e07e4d7359ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene_columns_set = set(scene_stats_df.columns)\n",
    "logs_columns_set = set(csv_stats_df.columns)\n",
    "intersection_columns = set(['is_scene_aborted'])\n",
    "\n",
    "# Drop the logs columns already recorded in the scene stats data frames\n",
    "drop_columns = sorted(scene_columns_set.intersection(logs_columns_set).intersection(intersection_columns))\n",
    "print(drop_columns)\n",
    "if drop_columns:\n",
    "    csv_stats_df = csv_stats_df.drop(columns=drop_columns)\n",
    "    print(csv_stats_df.shape) # (171766, 107)\n",
    "    nu.store_objects(metrics_evaluation_open_world_csv_stats_df=csv_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_csv_stats_df=csv_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcd61f-86f0-4f26-a82d-5b78998ceb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs_columns_set = set(csv_stats_df.columns)\n",
    "file_columns_set = set(json_stats_df.columns)\n",
    "intersection_columns = set(['logger_version', 'is_scene_aborted'])\n",
    "\n",
    "# Drop the logs columns already recorded in the JSON and scene stats data frames\n",
    "drop_columns = list(logs_columns_set.intersection(file_columns_set).intersection(intersection_columns))\n",
    "print(drop_columns)\n",
    "if drop_columns:\n",
    "    csv_stats_df = csv_stats_df.drop(columns=drop_columns)\n",
    "    print(csv_stats_df.shape) # (171766, 124)\n",
    "    nu.store_objects(metrics_evaluation_open_world_csv_stats_df=csv_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_csv_stats_df=csv_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4385ef6-f73f-4ca5-a108-6c430acf3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs_columns_set = set(csv_stats_df.columns)\n",
    "file_columns_set = set(json_stats_df.columns)\n",
    "intersection_columns = set([\n",
    "    'injury_record_injury_treated', 'injury_record_injury_treated_with_wrong_treatment', 'patient_demoted_health_level',\n",
    "    'patient_demoted_health_time_remaining',\n",
    "    'patient_demoted_hearing', 'patient_hearing', 'patient_record_health_level', 'patient_record_hearing',\n",
    "    'player_location_left_hand_location',\n",
    "    'player_location_right_hand_location', 'bag_access_location', 'patient_engaged_health_level', 'voice_capture_command_description',\n",
    "    'csv_file_name',\n",
    "    'csv_file_subpath'\n",
    "])\n",
    "\n",
    "# Drop the JSON Stats columns that came with the process but are covered well enough in the logs data frame and add no value here\n",
    "drop_columns = sorted(logs_columns_set.intersection(file_columns_set).intersection(intersection_columns))\n",
    "print(drop_columns)\n",
    "if drop_columns:\n",
    "    json_stats_df = json_stats_df.drop(columns=drop_columns)\n",
    "    print(json_stats_df.shape) # (43, 3589)\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=json_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacb6c3-2baa-421c-b1c9-bb21fdb2b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_columns_set = set(json_stats_df.columns)\n",
    "scene_columns_set = set(scene_stats_df.columns)\n",
    "intersection_columns = set(['logger_version'])\n",
    "\n",
    "# Drop the scene columns already recorded in the JSON Stats data frames\n",
    "drop_columns = sorted(file_columns_set.intersection(scene_columns_set).intersection(intersection_columns))\n",
    "if drop_columns:\n",
    "    scene_stats_df = scene_stats_df.drop(columns=drop_columns)\n",
    "    print(scene_stats_df.shape) # (76, 48)\n",
    "    nu.store_objects(metrics_evaluation_open_world_scene_stats_df=scene_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=scene_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe582d-0a3f-40bf-8d7d-9448334c0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates from the JSON Stats data frame\n",
    "subset_columns = ['session_uuid']\n",
    "mask_series = json_stats_df.duplicated(subset=subset_columns)\n",
    "if mask_series.any():\n",
    "    json_stats_df = json_stats_df[~mask_series]\n",
    "    print(json_stats_df.shape)\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=json_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18b354-2d34-444e-aa76-eda3be7b52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates from the scene stats data frame\n",
    "subset_columns = ['session_uuid', 'scene_id']\n",
    "mask_series = scene_stats_df.duplicated(subset=subset_columns)\n",
    "if mask_series.any():\n",
    "    scene_stats_df = scene_stats_df[~mask_series]\n",
    "    print(scene_stats_df.shape)\n",
    "    nu.store_objects(metrics_evaluation_open_world_scene_stats_df=scene_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=scene_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a3770-1507-46e6-ac54-ef37067a915d",
   "metadata": {},
   "source": [
    "\n",
    "### Get column and value descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b58dc3-81a2-4234-bbd8-817c8b084e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attempt to manufacture some better column names\n",
    "file_path = '../data/xlsx/Metrics_Evaluation_Dataset_organization_for_BBAI.xlsx'\n",
    "dataset_organization_df = read_excel(file_path)\n",
    "\n",
    "# Fix the doubled up descriptions\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: ';' in str(x))\n",
    "for row_index, label in dataset_organization_df[mask_series].Labels.items():\n",
    "    labels_list = re.split(' *; *', str(label), 0)\n",
    "    dataset_organization_df.loc[row_index, 'Labels'] = labels_list[0]\n",
    "    \n",
    "    # Get a copy of the row\n",
    "    new_row = dataset_organization_df.loc[row_index].copy()\n",
    "    \n",
    "    # Modify the desired column value\n",
    "    new_row['Labels'] = labels_list[1]\n",
    "    \n",
    "    # Append the new row to the Data Frame\n",
    "    dataset_organization_df = dataset_organization_df.append(new_row, ignore_index=True)\n",
    "\n",
    "# Get a copy of the row\n",
    "mask_series = (dataset_organization_df.Variable == 'AD_Del_Omni')\n",
    "new_row = dataset_organization_df.loc[mask_series].copy()\n",
    "\n",
    "# Modify the desired column value\n",
    "new_row['Variable'] = 'AD_Del_Omni_Text'\n",
    "\n",
    "# Append the new row to the Data Frame\n",
    "dataset_organization_df = dataset_organization_df.append(new_row, ignore_index=True)\n",
    "\n",
    "# Turn the data frame into value description getter\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: '=' in str(x))\n",
    "value_descriptions_columns = dataset_organization_df[mask_series].Variable.unique().tolist()\n",
    "def get_value_description(column_name, column_value):\n",
    "    value_description = ''\n",
    "    if not isna(column_value):\n",
    "        mask_series = (dataset_organization_df.Variable == column_name) & ~dataset_organization_df.Labels.isnull()\n",
    "        if mask_series.any():\n",
    "            df = dataset_organization_df[mask_series]\n",
    "            mask_series = df.Labels.map(lambda label: re.split(' *= *', str(label), 0)[0] == str(int(float(column_value))))\n",
    "            if mask_series.any():\n",
    "                label = df[mask_series].Labels.squeeze()\n",
    "                value_description = re.split(' *= *', str(label), 0)[1]\n",
    "    \n",
    "    return value_description\n",
    "column_name = 'MedRole'\n",
    "column_value = nan\n",
    "get_value_description(column_name, column_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7a30-006e-480d-8531-9585d5526dde",
   "metadata": {},
   "source": [
    "\n",
    "## Provide Correctly Grouped Responder Type Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561ce57-9574-4507-a997-cb6504d12f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a column that correctly groups responder types\n",
    "new_column_name = 'responder_category'\n",
    "if (new_column_name in json_stats_df.columns):\n",
    "    json_stats_df = json_stats_df.drop(columns=[new_column_name])\n",
    "    print(json_stats_df.shape)\n",
    "if (new_column_name not in json_stats_df.columns):\n",
    "    json_stats_df[new_column_name] = json_stats_df.MedRole.map(\n",
    "        lambda x: ' '.join([r.title() for r in get_value_description('MedRole', x).split(' ')]).replace('Em ', 'EM ')\n",
    "    )\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=json_stats_df)\n",
    "    print(json_stats_df.shape) # (43, 3564)\n",
    "\n",
    "display(json_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4afdd-e65b-4785-97b4-50dfc25bdbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add responder types subgrouping columns\n",
    "groupby_columns = ['overall_category', 'global_category', 'global_description', 'sub_category', 'sub_description', 'responder_type']\n",
    "if any(map(lambda x: x not in json_stats_df.columns, groupby_columns)):\n",
    "    file_path = osp.join(fu.data_folder, 'xlsx', 'Responder_Categories_and_Counts_DPW.xlsx')\n",
    "    dpw_responder_categories_df = read_excel(file_path)\n",
    "\n",
    "    # Get description data frame\n",
    "    mask_series = dpw_responder_categories_df.isna().all(axis='columns')\n",
    "    idx = dpw_responder_categories_df[mask_series].index.min()\n",
    "    where_df = dpw_responder_categories_df.iloc[idx+1:]\n",
    "    \n",
    "    # Get categories data frame\n",
    "    dpw_responder_categories_df = dpw_responder_categories_df.iloc[:idx].dropna(axis='columns', how='all')\n",
    "    dpw_responder_categories_df.columns = ['overall_category', 'responder_type', 'global_category', 'sub_category', 'record_count']\n",
    "    \n",
    "    # Create global description column\n",
    "    columns_list = ['global_category', 'global_description', 'record_count']\n",
    "    df = where_df.iloc[:, 1:4].dropna(axis='index', how='all')\n",
    "    df.columns = columns_list\n",
    "    global_description_dict = df.set_index('global_category').global_description.to_dict()\n",
    "    dpw_responder_categories_df['global_description'] = dpw_responder_categories_df.global_category.map(global_description_dict)\n",
    "    \n",
    "    # Create sub description column\n",
    "    columns_list = ['sub_category', 'sub_description', 'record_count']\n",
    "    df = where_df.iloc[:, 5:8].dropna(axis='index', how='all')\n",
    "    df.columns = columns_list\n",
    "    sub_description_dict = df.set_index('sub_category').sub_description.to_dict()\n",
    "    dpw_responder_categories_df['sub_description'] = dpw_responder_categories_df.sub_category.map(sub_description_dict)\n",
    "    \n",
    "    # Add columns to JSON Stats data frame\n",
    "    df = dpw_responder_categories_df[groupby_columns].groupby(groupby_columns).size().reset_index(drop=False)\n",
    "    assert not (df[0] != 1).any(), \"You will have a problem with responder types\"\n",
    "    df = df.drop(columns=[0])\n",
    "    assert not (df.groupby('responder_type').size() != 1).any(), \"You have a problem with responder types\"\n",
    "    if 'responder_type' not in json_stats_df.columns:\n",
    "        json_stats_df['responder_type'] = json_stats_df.MedRole.map(\n",
    "            lambda x: re.sub('^Other$', 'Other HP', ' '.join(\n",
    "                [r.title() for r in get_value_description('MedRole', x).split(' ')]\n",
    "            ).replace('Em ', 'EM ').replace('EM Faculty', 'EM-Faculty'))\n",
    "        )\n",
    "    # print()\n",
    "    \n",
    "    overall_category_dict = dpw_responder_categories_df.set_index('responder_type').overall_category.to_dict()\n",
    "    # print(f'overall_category_dict = {overall_category_dict}')\n",
    "    json_stats_df['overall_category'] = json_stats_df.responder_type.map(overall_category_dict)\n",
    "\n",
    "    global_category_dict = dpw_responder_categories_df.set_index('responder_type').global_category.to_dict()\n",
    "    # print(f'global_category_dict = {global_category_dict}')\n",
    "    json_stats_df['global_category'] = json_stats_df.responder_type.map(global_category_dict)\n",
    "\n",
    "    global_description_dict = dpw_responder_categories_df.set_index('responder_type').global_description.to_dict()\n",
    "    # print(f'global_description_dict = {global_description_dict}')\n",
    "    json_stats_df['global_description'] = json_stats_df.responder_type.map(global_description_dict)\n",
    "\n",
    "    sub_category_dict = dpw_responder_categories_df.set_index('responder_type').sub_category.to_dict()\n",
    "    # print(f'sub_category_dict = {sub_category_dict}')\n",
    "    json_stats_df['sub_category'] = json_stats_df.responder_type.map(sub_category_dict)\n",
    "\n",
    "    sub_description_dict = dpw_responder_categories_df.set_index('responder_type').sub_description.to_dict()\n",
    "    # print(f'sub_description_dict = {sub_description_dict}')\n",
    "    json_stats_df['sub_description'] = json_stats_df.responder_type.map(sub_description_dict)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=json_stats_df)\n",
    "    print(json_stats_df.shape) # (43, 3570)\n",
    "\n",
    "if all(map(lambda x: x in json_stats_df.columns, groupby_columns)):\n",
    "    print(json_stats_df[groupby_columns].nunique()) \n",
    "    display(json_stats_df.groupby(groupby_columns).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "        'record_count', ascending=False\n",
    "    ).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac33c75e-f317-44e8-b0c6-d83635b47d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_scene_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_scene_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# [cn for cn in scene_stats_df.columns if ('action' in cn) and ('total' in cn)]\n",
    "scene_stats_df = scene_stats_df.rename(columns={'total_actions': 'total_actions_count'})\n",
    "nu.store_objects(metrics_evaluation_open_world_scene_stats_df=scene_stats_df)\n",
    "nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=scene_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67981ab1-67b5-43b7-b51e-8ecad0325690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
