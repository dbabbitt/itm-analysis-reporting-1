{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9ac92e-2aaf-4d2d-bc1a-98da11237bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151caed9-364f-4118-ac82-fd0e3a53a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load libraries\n",
    "from FRVRS import nu, fu\n",
    "from numpy import nan, isnan\n",
    "from os import listdir as listdir, makedirs as makedirs, path as osp, remove as remove, sep as sep, walk as walk\n",
    "from pandas import (\n",
    "    CategoricalDtype, DataFrame, Index, NaT, Series, concat, get_dummies, isna, notnull, read_csv, read_excel, to_datetime, to_numeric\n",
    ")\n",
    "from re import MULTILINE, search, split, sub\n",
    "from scipy.stats import f_oneway, ttest_ind, kruskal, norm\n",
    "import csv\n",
    "import inspect\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "IS_DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494d35c-1a37-4126-b52b-e7bd766c0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In the zip there are 51 folders, (51 JSON, 51 CSV).\n",
    "# All the files are named appropriated in the folder/csv/json UUID_ParticipantID.\n",
    "# Some of the internal Participants IDs might be off because the moderator forgot to enter a Participant ID or didn't enter\n",
    "# the Participant ID correctly so we needed to figure out which participant it was.\n",
    "# So only utilize the UUID and Participant ID that is on the file name to identify and ignore the internal Participant IDs.\n",
    "# Get all the Open World logs into one data frame\")\n",
    "csv_stats_df = DataFrame([])\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "directories_list = listdir(logs_path)\n",
    "for dir_name in directories_list:\n",
    "    \n",
    "    # Add the CSVs to the data frame\n",
    "    folder_path = osp.join(logs_path, dir_name)\n",
    "    df = fu.concatonate_logs(logs_folder=folder_path)\n",
    "    \n",
    "    session_uuid, participant_id = dir_name.split('_')\n",
    "    df['session_uuid'] = session_uuid\n",
    "    df['participant_id'] = int(participant_id)\n",
    "    \n",
    "    # Remove numerically-named columns\n",
    "    columns_list = [x for x in df.columns if not search(r'\\d+', str(x))]\n",
    "    df = df[columns_list]\n",
    "    \n",
    "    # Convert 'TRUE' and 'FALSE' to boolean values\n",
    "    for cn in fu.boolean_columns_list:\n",
    "        df[cn] = df[cn].map({'TRUE': True, 'FALSE': False, 'True': True, 'False': False})\n",
    "    \n",
    "    # Convert the nulls into NaNs\n",
    "    for cn in df.columns: df[cn] = df[cn].replace(['null', 'nan', 'n'], nan)\n",
    "    \n",
    "    # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "    csv_stats_df = concat([csv_stats_df, df], axis='index')\n",
    "\n",
    "csv_stats_df = csv_stats_df.reset_index(drop=True).drop_duplicates()\n",
    "csv_stats_df['csv_file_name'] = csv_stats_df.csv_file_subpath.map(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "# Check for proper ingestion (duplicate file ingestion, et al)\")\n",
    "assert len(csv_stats_df.columns) > 4, \"Nothing ingested\"\n",
    "assert csv_stats_df.participant_id.nunique() == 26, f\"Participant count should be 26, it's {csv_stats_df.participant_id.nunique()} instead\"\n",
    "\n",
    "if IS_DEBUG: print(csv_stats_df.groupby('logger_version').size().to_frame().rename(columns={0: 'record_count'})) # 276926\n",
    "\n",
    "# Filter all the rows that have more than one unique value in the file_name column for each value in the session_uuid column\")\n",
    "mask_series = (csv_stats_df.groupby('session_uuid').csv_file_subpath.transform(Series.nunique) > 1)\n",
    "assert not mask_series.any(), \"You have duplicate files\"\n",
    "\n",
    "# Check that all your junk scenes are the last scenes\")\n",
    "if IS_DEBUG: print(csv_stats_df.groupby('is_scene_aborted').size().to_frame().rename(columns={0: 'record_count'}))\n",
    "mask_series = csv_stats_df.is_scene_aborted\n",
    "for (session_uuid, scene_id), scene_df in csv_stats_df[mask_series].groupby(fu.scene_groupby_columns):\n",
    "    mask_series = (csv_stats_df.session_uuid == session_uuid)\n",
    "    max_scene_id = csv_stats_df[mask_series].scene_id.max()\n",
    "    assert max_scene_id == scene_id, \"You've got junk scenes in strange places\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbfd3e-8752-460d-935f-e0c4d1d704ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the Unity suffix from all patient_id columns\n",
    "# The one without \"Root\" is the ID that CACI sets for it. Unity\n",
    "# then takes the ID and adds \"Root\" to the end when it\n",
    "# creates the hierarchy, so there's less room for human\n",
    "# error. They're going to match perfectly.\n",
    "for cn in fu.patient_id_columns_list + ['patient_id']:\n",
    "    if cn in csv_stats_df.columns:\n",
    "        mask_series = ~csv_stats_df[cn].isnull()\n",
    "        csv_stats_df.loc[mask_series, cn] = csv_stats_df[mask_series][cn].map(lambda x: str(x).replace(' Root', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3ef6b-f9dd-407a-ae8e-38fbfdd802ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the patients not in our lists\n",
    "patients_set = set(fu.desert_patients_list + fu.jungle_patients_list + fu.submarine_patients_list + fu.urban_patients_list)\n",
    "mask_series = ~csv_stats_df.injury_record_patient_id.isnull()\n",
    "all_set = set(csv_stats_df[mask_series].injury_record_patient_id)\n",
    "assert patients_set.issubset(all_set), f\"You're missing {patients_set.difference(all_set)} from the patients in the CSVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51ce8d-7e46-47a9-8487-ecce0c3f2495",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Our patients lists are not in the CSVs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4619/534587065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mpatients_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesert_patients_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjungle_patients_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubmarine_patients_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murban_patients_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mmask_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mcsv_stats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpatients_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_stats_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_series\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Our patients lists are not in the CSVs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Our patients lists are not in the CSVs"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modalize separate columns into one\")\n",
    "csv_stats_df = fu.add_modal_column('patient_id', csv_stats_df, is_categorical=False, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('injury_id', csv_stats_df, is_categorical=False, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('location_id', csv_stats_df, is_categorical=False, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_sort', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_pulse', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_salt', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_hearing', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_breath', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_mood', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('patient_pose', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('injury_severity', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('injury_required_procedure', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('injury_body_region', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column('tool_type', csv_stats_df, verbose=IS_DEBUG)\n",
    "\n",
    "csv_stats_df = fu.convert_column_to_categorical(csv_stats_df, 'pulse_taken_pulse_name', verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.convert_column_to_categorical(csv_stats_df, 'tool_applied_data', verbose=IS_DEBUG)\n",
    "\n",
    "patients_set = set(fu.desert_patients_list + fu.jungle_patients_list + fu.submarine_patients_list + fu.urban_patients_list)\n",
    "mask_series = ~csv_stats_df.patient_id.isnull()\n",
    "all_set = set(csv_stats_df[mask_series].patient_id\n",
    "assert patients_set.issubset(all_set), f\"You're missing {patients_set.difference(all_set)} from the patients in the CSVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e5da9a-e80c-4bd4-8be0-e226467dcf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "csv_stats_df.patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92dd20-b089-4ce6-9426-60f99cec7c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
