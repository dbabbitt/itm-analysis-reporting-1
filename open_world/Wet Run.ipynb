{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9ac92e-2aaf-4d2d-bc1a-98da11237bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up notebook\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join('..', 'py') not in sys.path): sys.path.insert(1, osp.join('..', 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151caed9-364f-4118-ac82-fd0e3a53a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load libraries\n",
    "from FRVRS import (nu, fu, DataFrame, osp, listdir, nan, concat, Series)\n",
    "from pandas import get_dummies\n",
    "from re import MULTILINE, search, split, sub\n",
    "from scipy.stats import f_oneway, ttest_ind, kruskal, norm\n",
    "import inspect\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IS_DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494d35c-1a37-4126-b52b-e7bd766c0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In the zip there are 51 folders, (51 JSON, 51 CSV).\n",
    "# All the files are named appropriated in the folder/CSV/json UUID_ParticipantID.\n",
    "# Some of the internal Participants IDs might be off because the moderator forgot to enter a Participant ID or didn't enter\n",
    "# the Participant ID correctly so we needed to figure out which participant it was.\n",
    "# So only utilize the UUID and Participant ID that is on the file name to identify and ignore the internal Participant IDs.\n",
    "# Get all the Open World logs into one data frame\")\n",
    "csv_stats_df = DataFrame([])\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "directories_list = listdir(logs_path)\n",
    "for dir_name in directories_list:\n",
    "    \n",
    "    # Add the CSVs to the data frame\n",
    "    folder_path = osp.join(logs_path, dir_name)\n",
    "    df = fu.concatonate_logs(logs_folder=folder_path)\n",
    "    \n",
    "    session_uuid, participant_id = dir_name.split('_')\n",
    "    df['session_uuid'] = session_uuid\n",
    "    df['participant_id'] = int(participant_id)\n",
    "    \n",
    "    # Remove numerically-named columns\n",
    "    columns_list = [x for x in df.columns if not search(r'\\d+', str(x))]\n",
    "    df = df[columns_list]\n",
    "    \n",
    "    # Convert 'TRUE' and 'FALSE' to boolean values\n",
    "    for cn in fu.boolean_columns_list:\n",
    "        df[cn] = df[cn].map({'TRUE': True, 'FALSE': False, 'True': True, 'False': False})\n",
    "    \n",
    "    # Convert the nulls into NaNs\n",
    "    for cn in df.columns: df[cn] = df[cn].replace(['null', 'nan'], nan)\n",
    "    \n",
    "    # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "    csv_stats_df = concat([csv_stats_df, df], axis='index')\n",
    "\n",
    "csv_stats_df = csv_stats_df.reset_index(drop=True).drop_duplicates()\n",
    "csv_stats_df['csv_file_name'] = csv_stats_df.csv_file_subpath.map(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "# Check for proper ingestion (duplicate file ingestion, et al)\")\n",
    "assert len(csv_stats_df.columns) > 4, \"Nothing ingested\"\n",
    "assert csv_stats_df.participant_id.nunique() == 26, f\"Participant count should be 26, it's {csv_stats_df.participant_id.nunique()} instead\"\n",
    "\n",
    "if IS_DEBUG: print(csv_stats_df.groupby('logger_version').size().to_frame().rename(columns={0: 'record_count'})) # 276926\n",
    "\n",
    "# Filter all the rows that have more than one unique value in the file_name column for each value in the session_uuid column\")\n",
    "mask_series = (csv_stats_df.groupby('session_uuid').csv_file_subpath.transform(Series.nunique) > 1)\n",
    "assert not mask_series.any(), \"You have duplicate files\"\n",
    "\n",
    "# Check that all your junk scenes are the last scenes\")\n",
    "if IS_DEBUG: print(csv_stats_df.groupby('is_scene_aborted').size().to_frame().rename(columns={0: 'record_count'}))\n",
    "mask_series = csv_stats_df.is_scene_aborted\n",
    "for (session_uuid, scene_id), scene_df in csv_stats_df[mask_series].groupby(fu.scene_groupby_columns):\n",
    "    mask_series = (csv_stats_df.session_uuid == session_uuid)\n",
    "    max_scene_id = csv_stats_df[mask_series].scene_id.max()\n",
    "    assert max_scene_id == scene_id, \"You've got junk scenes in strange places\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbfd3e-8752-460d-935f-e0c4d1d704ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the Unity suffix from all patient_id columns\n",
    "# The one without \"Root\" is the ID that CACI sets for it. Unity\n",
    "# then takes the ID and adds \"Root\" to the end when it\n",
    "# creates the hierarchy, so there's less room for human\n",
    "# error. They're going to match perfectly.\n",
    "for cn in fu.patient_id_columns_list + ['patient_id']:\n",
    "    if cn in csv_stats_df.columns:\n",
    "        mask_series = ~csv_stats_df[cn].isnull()\n",
    "        csv_stats_df.loc[mask_series, cn] = csv_stats_df[mask_series][cn].map(lambda x: str(x).replace(' Root', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3ef6b-f9dd-407a-ae8e-38fbfdd802ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the patients not in our lists\n",
    "patients_set = set(fu.ow_patients_list)\n",
    "mask_series = ~csv_stats_df.injury_record_patient_id.isnull()\n",
    "all_set = set(csv_stats_df[mask_series].injury_record_patient_id)\n",
    "assert patients_set.issubset(all_set), f\"You're missing {patients_set.difference(all_set)} from the patients in the CSVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51ce8d-7e46-47a9-8487-ecce0c3f2495",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Our patients lists are not in the CSVs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4619/534587065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mpatients_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesert_patients_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjungle_patients_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubmarine_patients_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murban_patients_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mmask_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mcsv_stats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpatients_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_stats_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_series\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Our patients lists are not in the CSVs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Our patients lists are not in the CSVs"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modalize separate columns into one\")\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_id', csv_stats_df, is_categorical=False, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('injury_id', csv_stats_df, is_categorical=False, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('location_id', csv_stats_df, is_categorical=False, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_sort', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_pulse', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_salt', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_hearing', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_breath', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_mood', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('patient_pose', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('injury_severity', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('injury_required_procedure', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('injury_body_region', csv_stats_df, verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.add_modal_column_to_dataframe('tool_type', csv_stats_df, verbose=IS_DEBUG)\n",
    "\n",
    "csv_stats_df = fu.convert_column_to_categorical(csv_stats_df, 'pulse_taken_pulse_name', verbose=IS_DEBUG)\n",
    "csv_stats_df = fu.convert_column_to_categorical(csv_stats_df, 'tool_applied_data', verbose=IS_DEBUG)\n",
    "\n",
    "patients_set = set(fu.ow_patients_list)\n",
    "mask_series = ~csv_stats_df.patient_id.isnull()\n",
    "all_set = set(csv_stats_df[mask_series].patient_id\n",
    "assert patients_set.issubset(all_set), f\"You're missing {patients_set.difference(all_set)} from the patients in the CSVs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e5da9a-e80c-4bd4-8be0-e226467dcf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "csv_stats_df.patient_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92dd20-b089-4ce6-9426-60f99cec7c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
