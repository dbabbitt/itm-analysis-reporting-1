{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d497083-b501-4f84-bca7-d691eded680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the notebook\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join('..', 'py') not in sys.path): sys.path.insert(1, osp.join('..', 'py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175ef3c3-7c16-47d8-8e6a-c06108b7625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import (fu, nu, warnings, osp, read_excel, re, concat, isna)\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f527077-c52c-403c-9325-4d6f41c8f1bc",
   "metadata": {},
   "source": [
    "\n",
    "# Write up Steps to do ANOVA Stats columns Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51c8c79-023c-4b6b-bbb7-f26f16126fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_anova_df.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data frames to get a reliable representation\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_anova_df=''\n",
    ")\n",
    "anova_df = data_frames_dict['metrics_evaluation_open_world_anova_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89128bdd-c10c-4f8b-92f9-949fc25e916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get column and value descriptions\n",
    "file_path = osp.join(fu.data_folder, 'xlsx', 'Metrics_Evaluation_Dataset_organization_for_BBAI.xlsx')\n",
    "dataset_organization_df = read_excel(file_path)\n",
    "\n",
    "# Fix the doubled up descriptions\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: ';' in str(x))\n",
    "for row_index, label in dataset_organization_df[mask_series].Labels.items():\n",
    "    labels_list = re.split(' *; *', str(label), 0)\n",
    "    dataset_organization_df.loc[row_index, 'Labels'] = labels_list[0]\n",
    "    \n",
    "    # Get a copy of the row\n",
    "    new_row = dataset_organization_df.loc[row_index].copy()\n",
    "    \n",
    "    # Modify the desired column value\n",
    "    new_row['Labels'] = labels_list[1]\n",
    "    \n",
    "    # Append the new row to the Data Frame\n",
    "    dataset_organization_df = concat([dataset_organization_df, new_row], ignore_index=True)\n",
    "\n",
    "# Get a copy of the row\n",
    "mask_series = (dataset_organization_df.Variable == 'AD_Del_Omni')\n",
    "new_row = dataset_organization_df.loc[mask_series].copy()\n",
    "\n",
    "# Modify the desired column value\n",
    "new_row['Variable'] = 'AD_Del_Omni_Text'\n",
    "\n",
    "# Append the new row to the Data Frame\n",
    "dataset_organization_df = concat([dataset_organization_df, new_row], ignore_index=True)\n",
    "\n",
    "# Get the column value descriptions\n",
    "mask_series = ~dataset_organization_df.Description.isnull()\n",
    "df = dataset_organization_df[mask_series]\n",
    "COLUMN_DESCRIPTION_DICT = df.set_index('Variable').Description.to_dict()\n",
    "new_description_dict = COLUMN_DESCRIPTION_DICT.copy()\n",
    "for k, v in COLUMN_DESCRIPTION_DICT.items():\n",
    "    new_description_dict[k] = v\n",
    "    if (not k.endswith('_Text')):\n",
    "        new_key_name = f'{k}_Text'\n",
    "        new_description_dict[new_key_name] = new_description_dict.get(new_key_name, v)\n",
    "COLUMN_DESCRIPTION_DICT = new_description_dict.copy()\n",
    "\n",
    "# Create the value description function\n",
    "numeric_categories_mask_series = dataset_organization_df.Labels.map(lambda x: '=' in str(x))\n",
    "value_descriptions_columns = dataset_organization_df[numeric_categories_mask_series].Variable.unique().tolist()\n",
    "def get_value_description(column_name, column_value):\n",
    "    value_description = ''\n",
    "    if not isna(column_value):\n",
    "        mask_series = (dataset_organization_df.Variable == column_name) & ~dataset_organization_df.Labels.isnull()\n",
    "        if mask_series.any():\n",
    "            df = dataset_organization_df[mask_series]\n",
    "            mask_series = df.Labels.map(lambda label: re.split(' *= *', str(label), 0)[0] == str(int(float(column_value))))\n",
    "            if mask_series.any():\n",
    "                label = df[mask_series].Labels.squeeze()\n",
    "                value_description = re.split(' *= *', str(label), 0)[1]\n",
    "    \n",
    "    return value_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67981ab1-67b5-43b7-b51e-8ecad0325690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entitle_column_name(column_name):\n",
    "    if column_name.startswith('mean_') and (column_name[5:] in COLUMN_DESCRIPTION_DICT):\n",
    "        column_title = COLUMN_DESCRIPTION_DICT[column_name[5:]]\n",
    "        if not column_title.startswith('Average '):\n",
    "            column_title = 'Average ' + column_title\n",
    "    else:\n",
    "        new_parts_list = []\n",
    "        old_parts_list = [op for op in re.split('_', column_name, 0) if op]\n",
    "        for name_part in old_parts_list:\n",
    "            if re.search('[A-Z][a-z]+', name_part):\n",
    "                humps_list = [hp for hp in re.split('([A-Z][a-z]+)', name_part, 0) if hp]\n",
    "                for i, hump_part in enumerate(humps_list):\n",
    "                    if hump_part == hump_part.lower():\n",
    "                        humps_list[i] = hump_part.title()\n",
    "                    elif hump_part == 'Sim':\n",
    "                        humps_list[i] = 'Simulation'\n",
    "                    elif hump_part == 'Yrs':\n",
    "                        humps_list[i] = 'Years of'\n",
    "                    elif hump_part == 'Mil':\n",
    "                        humps_list[i] = 'Military'\n",
    "                    elif hump_part == 'Exp':\n",
    "                        humps_list[i] = 'Experience'\n",
    "                new_parts_list.extend(humps_list)\n",
    "            else:\n",
    "                if name_part == name_part.lower():\n",
    "                    if (len(name_part) > 2) and (name_part != 'uuid'):\n",
    "                        name_part = name_part.title()\n",
    "                    elif name_part not in ['to', 'of', 'per']:\n",
    "                        name_part = name_part.upper()\n",
    "                new_parts_list.append(name_part)\n",
    "        if new_parts_list[0] == 'Mean':\n",
    "            new_parts_list[0] = 'Average'\n",
    "        column_title = ' '.join(new_parts_list)\n",
    "\n",
    "    return column_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b9c0b9-0906-4765-b74d-cde15bfea3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect\n",
    "\n",
    "comment_regex = re.compile('^ *# ([^\\r\\n]+)', re.MULTILINE)\n",
    "function_call_dict = {'encounter_layout': 'fu.add_encounter_layout_column_to_json_stats', 'medical_role': 'fu.add_medical_role_column_to_anova_dataframe'}\n",
    "file_path = '../saves/txt/how_to_do_calculations.txt'\n",
    "with open(file_path, mode='w', encoding=nu.encoding_type) as f: print('', file=f)\n",
    "with open(file_path, mode='a', encoding=nu.encoding_type) as f:\n",
    "    for cn in anova_df.columns:\n",
    "        print('', file=f)\n",
    "        print(f'{cn} ({entitle_column_name(cn)})', file=f)\n",
    "        print('Steps Needed to do Calculations:', file=f)\n",
    "        if cn in ['participant_id', 'scene_id', 'session_uuid']:\n",
    "            if cn == 'scene_id':\n",
    "                print('1. The scene_id is derived from the CSV SESSION_START and SESSION_END entries.', file=f)\n",
    "            else:\n",
    "                print('1. The participant_id and session_uuid are found in both the CSV and the JSON data.', file=f)\n",
    "            comments_list = []\n",
    "        else:\n",
    "            print('1. Group your dataset by participant_id, session_uuid, and scene_id.', file=f)\n",
    "        try:\n",
    "            if cn in ['mean_AD_KDMA_Sim', 'mean_AD_KDMA_Text', 'mean_PropTrust', 'mean_ST_KDMA_Sim', 'mean_ST_KDMA_Text', 'mean_YrsMilExp']:\n",
    "                comments_list = [\n",
    "                    f'Find the {cn.replace(\"mean_\", \"\")} column in the participant_data_0420 spreadsheet'\n",
    "                    + f' provided by CACI for that participant',\n",
    "                    f'The {cn.replace(\"mean_\", \"\")} value is semi-continously numeric, and you can average'\n",
    "                    + f' it for whatever grouping you need'\n",
    "                ]\n",
    "            else:\n",
    "                if cn in function_call_dict:\n",
    "                    function_call = function_call_dict[cn]\n",
    "                else:\n",
    "                    function_call = cn.replace('mean_', 'fu.get_')\n",
    "                source_code = inspect.getsource(eval(function_call))\n",
    "                comments_list = [comment_str for comment_str in comment_regex.findall(\n",
    "                    source_code\n",
    "                ) if comment_str and ('verbose' not in comment_str)]\n",
    "            for i, comment_str in enumerate(comments_list):\n",
    "                print(f'{i+2}. {comment_str}.', file=f)\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50377bdc-8a49-4954-a948-6a24d4c6f5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
