{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d497083-b501-4f84-bca7-d691eded680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175ef3c3-7c16-47d8-8e6a-c06108b7625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import fu, nu\n",
    "from numpy import nan, isnan\n",
    "from os import listdir as listdir, makedirs as makedirs, path as osp, remove as remove, sep as sep, walk as walk\n",
    "from pandas import CategoricalDtype, DataFrame, Index, NaT, Series, concat, isna, notnull, read_csv, read_excel, read_pickle, to_datetime, to_numeric\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "try: import dill as pickle\n",
    "except:\n",
    "    try: import pickle5 as pickle\n",
    "    except: import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for presence of 'get_ipython' function (exists in Jupyter)\n",
    "try:\n",
    "    get_ipython()\n",
    "    from IPython.display import display\n",
    "except NameError:\n",
    "    display = lambda message: print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f527077-c52c-403c-9325-4d6f41c8f1bc",
   "metadata": {},
   "source": [
    "\n",
    "# Write up Steps to do ANOVA Stats columns Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51c8c79-023c-4b6b-bbb7-f26f16126fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_anova_df.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data frames to get a reliable representation\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_anova_df=''\n",
    ")\n",
    "anova_df = data_frames_dict['metrics_evaluation_open_world_anova_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89128bdd-c10c-4f8b-92f9-949fc25e916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get column and value descriptions\n",
    "file_path = osp.join(fu.data_folder, 'xlsx', 'Metrics_Evaluation_Dataset_organization_for_BBAI.xlsx')\n",
    "dataset_organization_df = read_excel(file_path)\n",
    "\n",
    "# Fix the doubled up descriptions\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: ';' in str(x))\n",
    "for row_index, label in dataset_organization_df[mask_series].Labels.items():\n",
    "    labels_list = re.split(' *; *', str(label), 0)\n",
    "    dataset_organization_df.loc[row_index, 'Labels'] = labels_list[0]\n",
    "    \n",
    "    # Get a copy of the row\n",
    "    new_row = dataset_organization_df.loc[row_index].copy()\n",
    "    \n",
    "    # Modify the desired column value\n",
    "    new_row['Labels'] = labels_list[1]\n",
    "    \n",
    "    # Append the new row to the DataFrame\n",
    "    dataset_organization_df = concat([dataset_organization_df, new_row], ignore_index=True)\n",
    "\n",
    "# Get a copy of the row\n",
    "mask_series = (dataset_organization_df.Variable == 'AD_Del_Omni')\n",
    "new_row = dataset_organization_df.loc[mask_series].copy()\n",
    "\n",
    "# Modify the desired column value\n",
    "new_row['Variable'] = 'AD_Del_Omni_Text'\n",
    "\n",
    "# Append the new row to the DataFrame\n",
    "dataset_organization_df = concat([dataset_organization_df, new_row], ignore_index=True)\n",
    "\n",
    "# Get the column value descriptions\n",
    "mask_series = ~dataset_organization_df.Description.isnull()\n",
    "df = dataset_organization_df[mask_series]\n",
    "value_description_dict = df.set_index('Variable').Description.to_dict()\n",
    "new_description_dict = value_description_dict.copy()\n",
    "for k, v in value_description_dict.items():\n",
    "    new_description_dict[k] = v\n",
    "    if (not k.endswith('_Text')):\n",
    "        new_key_name = f'{k}_Text'\n",
    "        new_description_dict[new_key_name] = new_description_dict.get(new_key_name, v)\n",
    "value_description_dict = new_description_dict.copy()\n",
    "\n",
    "# Create the value description function\n",
    "numeric_categories_mask_series = dataset_organization_df.Labels.map(lambda x: '=' in str(x))\n",
    "value_descriptions_columns = dataset_organization_df[numeric_categories_mask_series].Variable.unique().tolist()\n",
    "def get_value_description(column_name, column_value):\n",
    "    value_description = ''\n",
    "    if not isna(column_value):\n",
    "        mask_series = (dataset_organization_df.Variable == column_name) & ~dataset_organization_df.Labels.isnull()\n",
    "        if mask_series.any():\n",
    "            df = dataset_organization_df[mask_series]\n",
    "            mask_series = df.Labels.map(lambda label: re.split(' *= *', str(label), 0)[0] == str(int(float(column_value))))\n",
    "            if mask_series.any():\n",
    "                label = df[mask_series].Labels.squeeze()\n",
    "                value_description = re.split(' *= *', str(label), 0)[1]\n",
    "    \n",
    "    return value_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67981ab1-67b5-43b7-b51e-8ecad0325690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entitle_column_name(column_name):\n",
    "    if column_name.startswith('mean_') and (column_name[5:] in value_description_dict):\n",
    "        entitled_name = value_description_dict[column_name[5:]]\n",
    "        if not entitled_name.startswith('Average '):\n",
    "            entitled_name = 'Average ' + entitled_name\n",
    "    else:\n",
    "        new_parts_list = []\n",
    "        old_parts_list = [op for op in re.split('_', column_name, 0) if op]\n",
    "        for name_part in old_parts_list:\n",
    "            if re.search('[A-Z][a-z]+', name_part):\n",
    "                humps_list = [hp for hp in re.split('([A-Z][a-z]+)', name_part, 0) if hp]\n",
    "                for i, hump_part in enumerate(humps_list):\n",
    "                    if hump_part == hump_part.lower():\n",
    "                        humps_list[i] = hump_part.title()\n",
    "                    elif hump_part == 'Sim':\n",
    "                        humps_list[i] = 'Simulation'\n",
    "                    elif hump_part == 'Yrs':\n",
    "                        humps_list[i] = 'Years of'\n",
    "                    elif hump_part == 'Mil':\n",
    "                        humps_list[i] = 'Military'\n",
    "                    elif hump_part == 'Exp':\n",
    "                        humps_list[i] = 'Experience'\n",
    "                new_parts_list.extend(humps_list)\n",
    "            else:\n",
    "                if name_part == name_part.lower():\n",
    "                    if (len(name_part) > 2) and (name_part != 'uuid'):\n",
    "                        name_part = name_part.title()\n",
    "                    elif name_part not in ['to', 'of', 'per']:\n",
    "                        name_part = name_part.upper()\n",
    "                new_parts_list.append(name_part)\n",
    "        if new_parts_list[0] == 'Mean':\n",
    "            new_parts_list[0] = 'Average'\n",
    "        entitled_name = ' '.join(new_parts_list)\n",
    "\n",
    "    return entitled_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b9c0b9-0906-4765-b74d-cde15bfea3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import inspect\n",
    "\n",
    "comment_regex = re.compile('^ *# ([^\\r\\n]+)', re.MULTILINE)\n",
    "function_call_dict = {'encounter_layout': 'fu.add_encounter_layout_column', 'medical_role': 'fu.add_medical_role_column'}\n",
    "file_path = '../saves/txt/how_to_do_calculations.txt'\n",
    "with open(file_path, mode='w', encoding=nu.encoding_type) as f: print('', file=f)\n",
    "with open(file_path, mode='a', encoding=nu.encoding_type) as f:\n",
    "    for cn in anova_df.columns:\n",
    "        print('', file=f)\n",
    "        print(f'{cn} ({entitle_column_name(cn)})', file=f)\n",
    "        print('Steps Needed to do Calculations:', file=f)\n",
    "        if cn in ['participant_id', 'scene_id', 'session_uuid']:\n",
    "            if cn == 'scene_id':\n",
    "                print('1. The scene_id is derived from the CSV SESSION_START and SESSION_END entries.', file=f)\n",
    "            else:\n",
    "                print('1. The participant_id and session_uuid are found in both the CSV and the JSON data.', file=f)\n",
    "            comments_list = []\n",
    "        else:\n",
    "            print('1. Group your dataset by participant_id, session_uuid, and scene_id.', file=f)\n",
    "        try:\n",
    "            if cn in ['mean_AD_KDMA_Sim', 'mean_AD_KDMA_Text', 'mean_PropTrust', 'mean_ST_KDMA_Sim', 'mean_ST_KDMA_Text', 'mean_YrsMilExp']:\n",
    "                comments_list = [\n",
    "                    f'Find the {cn.replace(\"mean_\", \"\")} column in the participant_data_0420 spreadsheet provided by CACI for that participant',\n",
    "                    f'The {cn.replace(\"mean_\", \"\")} value is semi-continously numeric, and you can average it for whatever grouping you need'\n",
    "                ]\n",
    "            else:\n",
    "                if cn in function_call_dict:\n",
    "                    function_call = function_call_dict[cn]\n",
    "                else:\n",
    "                    function_call = cn.replace('mean_', 'fu.get_')\n",
    "                source_code = inspect.getsource(eval(function_call))\n",
    "                comments_list = [comment_str for comment_str in comment_regex.findall(source_code) if comment_str and ('verbose' not in comment_str)]\n",
    "            for i, comment_str in enumerate(comments_list):\n",
    "                print(f'{i+2}. {comment_str}.', file=f)\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50377bdc-8a49-4954-a948-6a24d4c6f5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
