{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476d4fdc-b4dd-4aa4-b68b-b2b07e571c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "if (osp.join(os.pardir, 'py') not in sys.path): sys.path.insert(1, osp.join(os.pardir, 'py'))\n",
    "from FRVRS import (nu, fu, DataFrame, np, nan, Series)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81d060-4e23-419a-8845-8ed2a3a84150",
   "metadata": {},
   "source": [
    "\n",
    "# Find the 389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d1f495-529c-48f7-af8d-d7d40941488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pickle exists for frvrs_logs_df - attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/frvrs_logs_df.csv.\n",
      "(829277, 113)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download the Oct 24, 2023 version of frvrs_logs_df.csv from the Data and Videos page on Confluence\n",
    "frvrs_logs_df = nu.load_data_frames(frvrs_logs_df='frvrs_logs_df')['frvrs_logs_df']\n",
    "print(frvrs_logs_df.shape) # (829277, 113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf548c1-e8cb-469c-83f8-cc110388f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scene_id column is not in the frvrs_logs_df DataFrame.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Review any missing columns\n",
    "needed_set = set(['session_uuid', 'scene_id', 'scene_type', 'is_scene_aborted', 'file_name'])\n",
    "for cn in needed_set:\n",
    "    if cn not in frvrs_logs_df.columns: print(f'The {cn} column is not in the frvrs_logs_df DataFrame.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95eb4090-84e5-404a-8bd2-13a7956ff6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scene index was changed to scene ID on December 14, 2023\n",
    "if 'scene_id' not in frvrs_logs_df.columns: frvrs_logs_df = frvrs_logs_df.rename(columns={'scene_index': 'scene_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f139ac7-79c7-4c45-8eec-d080f0bd950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Potentially add missing columns\n",
    "if not all(map(lambda cn: cn in frvrs_logs_df.columns, ['scene_type', 'is_scene_aborted'])):\n",
    "    for (session_uuid, scene_id), scene_df in frvrs_logs_df.groupby(fu.scene_groupby_columns):\n",
    "        mask_series = True\n",
    "        for cn in fu.scene_groupby_columns: mask_series &= (frvrs_logs_df[cn] == eval(cn))\n",
    "        \n",
    "        # Scene type added November 29, 2023\n",
    "        if 'scene_type' not in frvrs_logs_df.columns: frvrs_logs_df.loc[mask_series, 'scene_type'] = fu.get_scene_type(scene_df)\n",
    "        \n",
    "        # Is scene aborted added November 14, 2023\n",
    "        if 'is_scene_aborted' not in frvrs_logs_df.columns: frvrs_logs_df.loc[mask_series, 'is_scene_aborted'] = fu.get_is_scene_aborted(scene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30378f4d-4496-49ac-b505-ae9d03295953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verify that we found it\n",
    "path_prefix = 'Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/'\n",
    "original_files_list = [\n",
    "    file_name.replace(path_prefix, '') for file_name, file_name_df in frvrs_logs_df.groupby('file_name') if fu.get_is_a_one_triage_file(file_name_df)\n",
    "]\n",
    "original_files_count = len(original_files_list)\n",
    "assert 389 == original_files_count, \"This CSV doesn't contain the 389\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2145f8-fe3d-4b71-be22-8bdd2acba637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a session UUIDs list\n",
    "mask_series = frvrs_logs_df.file_name.isin([path_prefix + f for f in original_files_list]) & ~frvrs_logs_df.session_uuid.isnull()\n",
    "original_session_uuids_list = sorted(frvrs_logs_df[mask_series].session_uuid.unique())\n",
    "original_session_uuids_count = len(original_session_uuids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac4cd0-a8d7-4fdb-9f8b-f12e22bfe21b",
   "metadata": {},
   "source": [
    "\n",
    "# Identify any Anomalous Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a11181-7117-4f1f-8709-67bfa19a5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anomalous_files_set = set()\n",
    "anomalous_files_str = ''\n",
    "explanations_list = []\n",
    "\n",
    "# Get a dataset of the original one-triage files\n",
    "one_triage_files_df = frvrs_logs_df.groupby('file_name').filter(lambda file_name_df: fu.get_is_a_one_triage_file(file_name_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb39e28a-d48f-4c55-83e8-4936980b8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If all the patients in a file are all named Mike, that is a training simulation\n",
    "files_list = []\n",
    "\n",
    "# Group the Data Frame by 'file_name'\n",
    "for file_name, file_name_df in one_triage_files_df.groupby('file_name'):\n",
    "\n",
    "    # Get a list of the unique patient IDs in the file\n",
    "    patient_ids = file_name_df.patient_id.unique().tolist()\n",
    "\n",
    "    # Check if all the patient IDs in the file contain the string \"mike\" in lowercase\n",
    "    if all(map(lambda x: 'mike' in str(x).lower(), patient_ids)):\n",
    "\n",
    "        # Add the file name to the files_list list\n",
    "        files_list.append(file_name)\n",
    "\n",
    "# If there are files with all patients named \"Mike,\" print and update the results\n",
    "if files_list:\n",
    "\n",
    "    # Create a string with the list of files having \"Mike\" patients\n",
    "    print_str = f'\\n\\nThese {len(files_list)} files have patients that are all named \"Mike\":\\n\\t{nu.conjunctify_nouns(files_list)}'\n",
    "    explanations_list.append(f'{len(files_list)} files had patients that are all named \"Mike\"')\n",
    "\n",
    "    # Add carriage returns for better readability\n",
    "    print_str = print_str.replace(' and ', ', and\\n\\t')\n",
    "    \n",
    "    # Print the results\n",
    "    print(print_str)\n",
    "\n",
    "    # Update the anomalous files string\n",
    "    anomalous_files_str += print_str\n",
    "\n",
    "    # Update the anomalous files set\n",
    "    anomalous_files_set.update(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a5e86d-eaaa-41ea-9b2a-e590517025dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "These 2 files have no user action taken:\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/7c2549d4-97a4-4389-bd03-029396714f59.csv, and\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean e78faf41-7bbd-410b-8750-e4e72b951216.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize an empty list to store rows\n",
    "rows_list = []\n",
    "\n",
    "# Loop through sessions and scenes\n",
    "for (session_uuid, scene_id), scene_df in one_triage_files_df.groupby(fu.scene_groupby_columns):\n",
    "\n",
    "    # Create a dictionary to store the results for the current group\n",
    "    row_dict = {}\n",
    "\n",
    "    # Get the logger version for the current group\n",
    "    logger_version = fu.get_logger_version(scene_df)\n",
    "\n",
    "    # Add the logger version, session UUID, and scene to the dictionary\n",
    "    for cn in fu.scene_groupby_columns: row_dict[cn] = eval(cn)\n",
    "    row_dict['logger_version'] = logger_version\n",
    "\n",
    "    # Count the number of user actions for the current group\n",
    "    row_dict['total_actions'] = fu.get_total_actions_count(scene_df)\n",
    "\n",
    "    # Append the row to the list\n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "# Create a data frame from the list of rows\n",
    "total_actions_df = DataFrame(rows_list)\n",
    "\n",
    "# Group by session UUID and sum total actions\n",
    "df = total_actions_df.groupby('session_uuid').sum()\n",
    "\n",
    "# Create a mask for sessions with zero total actions\n",
    "mask_series = (df.total_actions == 0)\n",
    "\n",
    "# Get a list of session UUIDs with no user actions\n",
    "session_uuids_list = df[mask_series].index.tolist()\n",
    "\n",
    "# Create a mask to filter for UUIDs with no user actions\n",
    "mask_series = one_triage_files_df.session_uuid.isin(session_uuids_list)\n",
    "\n",
    "# Get unique file names associated with sessions with zero total actions\n",
    "files_list = one_triage_files_df[mask_series].file_name.unique().tolist()\n",
    "\n",
    "# Check if there are files with zero actions\n",
    "if files_list:\n",
    "    \n",
    "    # Create a formatted string of anomalous files\n",
    "    print_str = f'\\n\\nThese {len(files_list)} files have no user action taken:\\n\\t{nu.conjunctify_nouns(files_list)}'\n",
    "    explanations_list.append(f'{len(files_list)} files had no user action taken')\n",
    "    \n",
    "    # Add carriage returns for readability\n",
    "    print_str = print_str.replace(' and ', ', and\\n\\t')\n",
    "\n",
    "    # Print and update the anomalous files string and set\n",
    "    print(print_str); anomalous_files_str += print_str\n",
    "    anomalous_files_set.update(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a56567-3ebf-42dc-a30c-ce4ca3a3b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "These 5 files have no injury treatment being done:\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/All CSV files renamed by date/03.14.23.0919.csv, Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/All CSV files renamed by date/11.30.20.0828.csv, Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/1066671d-2a1d-4744-b66f-e4b48548701f.csv, Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/54aaf31a-22bc-46f2-a810-8564161bf8d0.csv,, and\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean c6a48228-d864-4b20-93dd-8ad0d78d59c0.csv\n",
      "\n",
      "\n",
      "These 6 files have no pulses being taken:\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/All CSV files renamed by date/03.15.23.0944.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/0786a1df-d010-4b1b-a99a-e00df486d479.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/Sarah S..csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/Disaster Day 2022/AS_0836.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean a6b7ff70-3b20-48c6-86e8-744bad19f7d7.csv, and\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean d90f2d85-e91c-4f12-b070-5929d95be1c5.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a mask to filter rows where action_type is PULSE_TAKEN or INJURY_TREATED\n",
    "mask_series = one_triage_files_df.action_type.isin(['PULSE_TAKEN', 'INJURY_TREATED'])\n",
    "\n",
    "# Define columns to group by and initialize lists\n",
    "\n",
    "\n",
    "rows_list = []\n",
    "indices_list = []\n",
    "\n",
    "# Iterate over groups based on the specified columns\n",
    "for (session_uuid, scene_id, patient_id), patient_df in one_triage_files_df[mask_series].groupby(fu.patient_groupby_columns):\n",
    "\n",
    "    # Create a tuple to store the index of the current row\n",
    "    index_tuple = (session_uuid, scene_id, patient_id)\n",
    "    indices_list.append(index_tuple)\n",
    "\n",
    "    # Create a dictionary to store the results for the current row\n",
    "    row_dict = {}\n",
    "\n",
    "    # Add the logger_version for the current row\n",
    "    row_dict['logger_version'] = fu.get_logger_version(patient_df)\n",
    "    \n",
    "    # Count the number of 'PULSE_TAKEN' actions in this group\n",
    "    row_dict['pulses_count'] = fu.get_pulse_taken_count(patient_df)\n",
    "    \n",
    "    # Count the number of 'INJURY_TREATED' actions in this group\n",
    "    row_dict['treated_count'] = fu.get_injury_treatments_count(patient_df)\n",
    "    \n",
    "    # Try to calculate the number of pulses taken per injury treated\n",
    "    try: row_dict['pulses_by_treated'] = row_dict['pulses_count'] / row_dict['treated_count']\n",
    "\n",
    "    # Handle the case where 'treated_count' is zero to avoid division by zero\n",
    "    except ZeroDivisionError: row_dict['pulses_by_treated'] = nan\n",
    "    \n",
    "    # Add the row_dict to the rows_list\n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "# Create a data frame from the rows and set a multi index based on the grouped columns\n",
    "pulses_count_df = DataFrame(rows_list, index=pd.MultiIndex.from_tuples(tuples=indices_list, names=fu.patient_groupby_columns))\n",
    "\n",
    "# Group the pulses count data frame by session_uuid and sum the values\n",
    "df = pulses_count_df.groupby('session_uuid').sum()\n",
    "\n",
    "# Check for sessions with 'treated_count' equal to zero\n",
    "mask_series = (df.treated_count == 0)\n",
    "session_uuids_list = df[mask_series].index.tolist()\n",
    "\n",
    "# Filter logs for sessions with no 'INJURY_TREATED' actions\n",
    "mask_series = one_triage_files_df.session_uuid.isin(session_uuids_list)\n",
    "files_list = one_triage_files_df[mask_series].file_name.unique().tolist()\n",
    "\n",
    "# Print files with no injury treatment being done\n",
    "if files_list:\n",
    "    print_str = f'\\n\\nThese {len(files_list)} files have no injury treatment being done:\\n\\t{nu.conjunctify_nouns(files_list)}'\n",
    "    explanations_list.append(f'{len(files_list)} files had no injury treatment being done')\n",
    "    print_str = print_str.replace(' and ', ', and\\n\\t')\n",
    "    print(print_str); anomalous_files_str += print_str\n",
    "    anomalous_files_set.update(files_list)\n",
    "\n",
    "# Check for sessions with 'pulses_count' equal to zero\n",
    "mask_series = (df.pulses_count == 0)\n",
    "session_uuids_list = df[mask_series].index.tolist()\n",
    "\n",
    "# Filter logs for sessions with no 'PULSE_TAKEN' actions\n",
    "mask_series = one_triage_files_df.session_uuid.isin(session_uuids_list)\n",
    "files_list = one_triage_files_df[mask_series].file_name.unique().tolist()\n",
    "\n",
    "# Print files with no pulses being taken\n",
    "if files_list:\n",
    "    print_str = f'\\n\\nThese {len(files_list)} files have no pulses being taken:\\n\\t{nu.conjunctify_nouns(files_list)}'\n",
    "    explanations_list.append(f'{len(files_list)} files had no pulses being taken')\n",
    "    print_str = print_str.replace(', ', ',\\n\\t').replace(',\\n\\tand ', ', and\\n\\t')\n",
    "    print(print_str); anomalous_files_str += print_str\n",
    "    anomalous_files_set.update(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f81cfa03-5dcd-4380-9c1a-5c9f6116687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "These 13 files have no patient accuracy rate above zero:\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/All CSV files renamed by date/03.14.23.0919.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/All CSV files renamed by date/11.30.20.0828.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/All CSV files renamed by date/12.06.22.1331.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/1066671d-2a1d-4744-b66f-e4b48548701f.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/54aaf31a-22bc-46f2-a810-8564161bf8d0.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/7c2549d4-97a4-4389-bd03-029396714f59.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/8ec8afba-8533-4915-898f-5769c1258c61.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/91f31664-43ad-4405-a763-0d58a8afc36a.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/ccfb5502-64b5-4d1c-9ca3-63f522330041.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean 158e6365-673b-4030-8b36-6704be5996a2.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean 2310f107-d9d2-418e-a2d7-dd7a17924544.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean c6a48228-d864-4b20-93dd-8ad0d78d59c0.csv, and\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean e78faf41-7bbd-410b-8750-e4e72b951216.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Patient accuracy rate (how many patients correct / number of patients treated)\n",
    "\n",
    "# Initialize an empty list to store dictionaries\n",
    "rows_list = []\n",
    "\n",
    "# Iterate over the scenes\n",
    "for (session_uuid, scene_id), scene_df in one_triage_files_df.groupby(fu.scene_groupby_columns):\n",
    "\n",
    "    # Get the logger version for the group\n",
    "    logger_version = fu.get_logger_version(scene_df)\n",
    "    \n",
    "    # Create a dictionary to store the results for the group\n",
    "    row_dict = {}\n",
    "    for cn in fu.scene_groupby_columns: row_dict[cn] = eval(cn)\n",
    "    row_dict['logger_version'] = logger_version\n",
    "\n",
    "    # Get the total number of patients treated\n",
    "    total_treated = fu.get_injury_treatments_count(scene_df)\n",
    "\n",
    "    # If there were any patients treated, calculate the patient accuracy rate\n",
    "    if total_treated:\n",
    "        \n",
    "        # Filter the dataframe to only include rows where the injury was treated correctly\n",
    "        correctly_treated = fu.get_injury_correctly_treated_count(scene_df)\n",
    "\n",
    "        # Calculate the patient accuracy rate\n",
    "        row_dict['injury_treated_total_treated'] = total_treated\n",
    "        row_dict['injury_treated_correctly_treated'] = correctly_treated\n",
    "        row_dict['injury_treated_patient_accuracy_rate'] = correctly_treated / total_treated\n",
    "    \n",
    "    # Filter the data frame to only include rows where the injury record was treated.\n",
    "    total_mask = (scene_df.injury_record_injury_treated == True)\n",
    "    df2 = scene_df[total_mask]\n",
    "\n",
    "    # Get the total number of patients treated\n",
    "    total_treated = df2.shape[0]\n",
    "\n",
    "    # If there were any patients treated, calculate the patient accuracy rate\n",
    "    if total_treated:\n",
    "        \n",
    "        # Filter the dataframe to only include rows where the injury record was treated correctly\n",
    "        correct_mask = (df2.injury_record_injury_treated_with_wrong_treatment == False)\n",
    "        correctly_treated = df2[correct_mask].shape[0]\n",
    "\n",
    "        # Calculate the patient accuracy rate\n",
    "        row_dict['injury_record_total_treated'] = total_treated\n",
    "        row_dict['injury_record_correctly_treated'] = correctly_treated\n",
    "        row_dict['injury_record_patient_accuracy_rate'] = correctly_treated / total_treated\n",
    "\n",
    "    # Add the row dictionary to the list of results\n",
    "    rows_list.append(row_dict)\n",
    "\n",
    "# Create a data frame from the list of dictionaries\n",
    "patient_accuracy_rate_df = DataFrame(rows_list)\n",
    "\n",
    "# Modalize into one patient accuracy rate column if possible\n",
    "if 'injury_record_patient_accuracy_rate' in patient_accuracy_rate_df.columns:\n",
    "\n",
    "    # Get a list of columns that contain the patient accuracy rate\n",
    "    columns_list = [\n",
    "        'injury_treated_patient_accuracy_rate', 'injury_record_patient_accuracy_rate'\n",
    "    ]\n",
    "    \n",
    "    # Check if there's only one unique value across the specified columns\n",
    "    mask_series = (patient_accuracy_rate_df[columns_list].apply(Series.nunique, axis='columns') == 1)\n",
    "    \n",
    "    # Set the patient accuracy rate column for the rows identified by the mask series to the non-null value in one of the patient accuracy rate columns\n",
    "    patient_accuracy_rate_df.loc[~mask_series, 'patient_accuracy_rate'] = nan\n",
    "    \n",
    "    # Define a function to select the first valid value\n",
    "    def f(srs):\n",
    "        cn = srs.first_valid_index()\n",
    "        \n",
    "        return srs[cn]\n",
    "    \n",
    "    # Modalize the patient accuracy rate columns to get a single column\n",
    "    patient_accuracy_rate = patient_accuracy_rate_df[mask_series][columns_list].apply(f, axis='columns')\n",
    "    \n",
    "    # Set the patient accuracy rate column for the rows identified by the mask series to the single patient accuracy rate column\n",
    "    patient_accuracy_rate_df.loc[mask_series, 'patient_accuracy_rate'] = patient_accuracy_rate\n",
    "    \n",
    "    # Group by 'session_uuid' and sum the patient accuracy rates\n",
    "    df = patient_accuracy_rate_df.groupby('session_uuid').sum()\n",
    "    mask_series = (df.patient_accuracy_rate == 0)\n",
    "else:\n",
    "    \n",
    "    # Group by 'session_uuid' and sum the patient accuracy rates for 'injury_treated' data\n",
    "    df = patient_accuracy_rate_df.groupby('session_uuid').sum()\n",
    "    mask_series = (df.injury_treated_patient_accuracy_rate == 0)\n",
    "\n",
    "# Get a list of session_uuids with no patient accuracy rate above zero\n",
    "session_uuids_list = df[mask_series].index.tolist()\n",
    "\n",
    "# Create a mask to filter rows in 'one_triage_files_df' based on session_uuids\n",
    "mask_series = one_triage_files_df.session_uuid.isin(session_uuids_list)\n",
    "\n",
    "# Get a list of unique file names from the filtered rows\n",
    "files_list = one_triage_files_df[mask_series].file_name.unique().tolist()\n",
    "\n",
    "# Print the list of files with no patient accuracy rate above zero\n",
    "if files_list:\n",
    "    print_str = f'\\n\\nThese {len(files_list)} files have no patient accuracy rate above zero:\\n\\t{nu.conjunctify_nouns(files_list)}'\n",
    "    explanations_list.append(f'{len(files_list)} files had no patient accuracy rate above zero')\n",
    "    print_str = print_str.replace(', ', ',\\n\\t').replace(',\\n\\tand ', ', and\\n\\t')\n",
    "    print(print_str); anomalous_files_str += print_str\n",
    "    anomalous_files_set.update(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7273314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "These 8 files have no patients being engaged:\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/1066671d-2a1d-4744-b66f-e4b48548701f.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/54aaf31a-22bc-46f2-a810-8564161bf8d0.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/7c2549d4-97a4-4389-bd03-029396714f59.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/DCEMS Round 2 only triage sessions/ccfb5502-64b5-4d1c-9ca3-63f522330041.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean 158e6365-673b-4030-8b36-6704be5996a2.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean 2310f107-d9d2-418e-a2d7-dd7a17924544.csv,\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean c6a48228-d864-4b20-93dd-8ad0d78d59c0.csv, and\n",
      "\tUsers/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/data/logs/v.1.0/Clean e78faf41-7bbd-410b-8750-e4e72b951216.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of patients engaged\n",
    "\n",
    "# Initialize an empty list to store rows\n",
    "rows_list = []\n",
    "\n",
    "# Iterate over the sessions, grouped by scene\n",
    "for (session_uuid, scene_id), scene_df in one_triage_files_df.groupby(fu.scene_groupby_columns):\n",
    "\n",
    "    # Get the logger version\n",
    "    logger_version = fu.get_logger_version(scene_df)\n",
    "\n",
    "    # Get the number of patients in the session\n",
    "    patients_count = fu.get_patient_count(scene_df)\n",
    "\n",
    "    # Initialize the number of patients engaged\n",
    "    patients_engaged = 0\n",
    "    \n",
    "    # Loop over patients within this scene\n",
    "    for patient_id, patient_df in scene_df.groupby('patient_id'):\n",
    "        \n",
    "        # Create a mask to filter rows where action_type is 'PATIENT_ENGAGED'\n",
    "        mask_series = (patient_df.action_type == 'PATIENT_ENGAGED')\n",
    "        \n",
    "        # If there are any rows that match the mask, increment the number of patients engaged\n",
    "        if mask_series.any(): patients_engaged += 1\n",
    "\n",
    "    # Check if there are patients in this scene\n",
    "    if patients_count:\n",
    "        # Create a dictionary to store row data\n",
    "        row_dict = {}\n",
    "\n",
    "        # Add the session UUID and the scene to the dictionary\n",
    "        for cn in fu.scene_groupby_columns: row_dict[cn] = eval(cn)\n",
    "\n",
    "        # Add the logger version to the dictionary\n",
    "        row_dict['logger_version'] = logger_version\n",
    "\n",
    "        # Add the number of patients to the dictionary\n",
    "        row_dict['patients_count'] = patients_count\n",
    "\n",
    "        # Add the number of patients engaged to the dictionary\n",
    "        row_dict['patients_engaged'] = patients_engaged\n",
    "\n",
    "        # Calculate the percentage of patients engaged\n",
    "        row_dict['percentage_engaged'] = patients_engaged / patients_count\n",
    "\n",
    "        # Add the row dictionary to the list of rows\n",
    "        rows_list.append(row_dict)\n",
    "\n",
    "# Create a data frame from the list of rows\n",
    "percentage_engaged_df = DataFrame(rows_list)\n",
    "\n",
    "# Group the Data Frame by UUID and sum the number of patients engaged\n",
    "df = percentage_engaged_df.groupby('session_uuid').sum()\n",
    "\n",
    "# Create a mask to identify UUIDs with no engaged patients\n",
    "mask_series = (df.patients_engaged == 0)\n",
    "\n",
    "# List the UUIDs that meet the condition\n",
    "session_uuids_list = df[mask_series].index.tolist()\n",
    "\n",
    "# Create a mask to filter rows in the main data frame based on UUID\n",
    "mask_series = one_triage_files_df.session_uuid.isin(session_uuids_list)\n",
    "\n",
    "# Get unique file_names that match the UUIDs\n",
    "files_list = one_triage_files_df[mask_series].file_name.unique().tolist()\n",
    "\n",
    "# Check if there are any files with no patients engaged\n",
    "if files_list:\n",
    "\n",
    "    # Create a formatted string to list files with no engaged patients\n",
    "    print_str = f'\\n\\nThese {len(files_list)} files have no patients being engaged:\\n\\t{nu.conjunctify_nouns(files_list)}'\n",
    "    explanations_list.append(f'{len(files_list)} files had no patients being engaged')\n",
    "    \n",
    "    # Format the string to have line breaks after commas\n",
    "    print_str = print_str.replace(', ', ',\\n\\t').replace(',\\n\\tand ', ', and\\n\\t')\n",
    "\n",
    "    # Print the results and add the results to the anomalous_files_str string\n",
    "    print(print_str); anomalous_files_str += print_str\n",
    "\n",
    "    # Add the files to the anomalous_files_set set\n",
    "    anomalous_files_set.update(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a37c02f6-7848-40e4-8aff-158bda03bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anomalous_files_list = [f.replace(path_prefix, '') for f in anomalous_files_set]\n",
    "anomalous_files_count = len(anomalous_files_list)\n",
    "# print(f\"\\nDoug,\\n\\nHere is the set of {anomalous_files_count} anomalous files I'm concerned about:\")\n",
    "# print('\\t' + '\\n\\t'.join(sorted(anomalous_files_list)))\n",
    "# print(anomalous_files_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a49474f5-f875-4048-968b-dfafa8e51bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a session UUIDs list\n",
    "mask_series = one_triage_files_df.file_name.isin([path_prefix + f for f in anomalous_files_list]) & ~one_triage_files_df.session_uuid.isnull()\n",
    "anomalous_session_uuids_list = sorted(one_triage_files_df[mask_series].session_uuid.unique())\n",
    "anomalous_session_uuids_count = len(anomalous_session_uuids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0716553e-e83b-41f3-a8b5-58490e4f828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load triage paper data frame and get the maximum number of files to compare\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    first_responder_master_registry_df='', first_responder_master_registry_file_stats_df='', first_responder_master_registry_scene_stats_df='',\n",
    "    verbose=False\n",
    ")\n",
    "triage_paper_df = data_frames_dict['first_responder_master_registry_df']\n",
    "file_stats_df = data_frames_dict['first_responder_master_registry_file_stats_df']\n",
    "scene_stats_df = data_frames_dict['first_responder_master_registry_scene_stats_df']\n",
    "\n",
    "# Merge the registry data frames to get the original columns\n",
    "patient_count_filter_fn = lambda scene_df: True\n",
    "merge_df = fu.get_elevens_dataframe(\n",
    "    triage_paper_df, file_stats_df, scene_stats_df,\n",
    "    needed_columns=needed_set,\n",
    "    patient_count_filter_fn=patient_count_filter_fn\n",
    ")\n",
    "\n",
    "# Show how many one-triage files there are\n",
    "registry_files_list = [file_name for file_name, file_name_df in merge_df.groupby('file_name') if fu.get_is_a_one_triage_file(file_name_df)]\n",
    "registry_files_count = len(registry_files_list)\n",
    "# assert 389 == registry_files_count, \"This dataset doesn't contain the 389\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ea60ed6-c0a9-4866-a4b3-7fac877b219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a session UUIDs list\n",
    "mask_series = merge_df.file_name.isin(registry_files_list) & ~merge_df.session_uuid.isnull()\n",
    "registry_session_uuids_list = sorted(merge_df[mask_series].session_uuid.unique())\n",
    "registry_session_uuids_count = len(registry_session_uuids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea8931b6-f652-4883-adad-81df22788131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show what we still have to account for\n",
    "original_session_uuids_count - registry_session_uuids_count - anomalous_session_uuids_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee4aaae8-62ee-4cfc-a601-1538b414bd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(set(original_session_uuids_list) - set(registry_session_uuids_list) - set(anomalous_session_uuids_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82515b1f-1a14-4823-94c6-97fd5f95cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('009b848c-ea64-4f22-bd40-711213a3d327', '009b848c-ea64-4f22-bd40-711213a3d327', '0786a1df-d010-4b1b-a99a-e00df486d479')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "original_session_uuids_list[0], registry_session_uuids_list[0], anomalous_session_uuids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a0d46f8-979b-4df8-8b7d-522a09f2d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assert that the anomalous sessions were taken from the original sessions\n",
    "assert original_session_uuids_count - anomalous_session_uuids_count == len(set(original_session_uuids_list) - set(anomalous_session_uuids_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b88d4c15-09b1-42db-93ad-3153a55513e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show what we still have to account for\n",
    "anomalous_session_uuids_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6df3902-2db6-4272-9848-392a4fb7b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1df10bfd-0f85-42ff-a873-36dfe05df77b', '2930a371-1187-4b98-adfc-19e095637e48'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show the session UUIDs that were not part of the original\n",
    "set(registry_session_uuids_list) - set(original_session_uuids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b4560e-b4d8-42c6-bacd-91c110653c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right away, we took out 19 anomalous files because 2 files had no user action taken, 5 files had no injury treatment being done, 6 files had no pulses being taken, 13 files had no patient accuracy rate above zero, and 8 files had no patients being engaged and repaired some multiple-triage files to add 2 more sessions to the list.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Put the explanation in a summary sentance\n",
    "print(\n",
    "    f\"Right away, we took out {anomalous_files_count} anomalous files because {nu.conjunctify_nouns(explanations_list)}\"\n",
    "    f\" and repaired some multiple-triage files to add {len(set(registry_session_uuids_list) - set(original_session_uuids_list))} more sessions to the list.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4840a4fd-0509-4f6d-bb40-1b4262ee388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "registry_session_uuids_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5238ab-884e-4b46-8a51-c4a3c9bf79f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
